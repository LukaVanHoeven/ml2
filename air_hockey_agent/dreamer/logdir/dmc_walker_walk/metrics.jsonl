{"step": 0, "dataset_size": 10.0, "train_return": -9.80847978591919, "train_length": 10.0, "train_episodes": 1.0}
{"step": 0, "dataset_size": 20.0, "train_return": -9.356647968292236, "train_length": 10.0, "train_episodes": 2.0}
{"step": 40}
{"step": 40, "eval_return": -10.014086508750916, "eval_length": 10.0, "eval_episodes": 10.0}
{"step": 40, "model_loss": 26.96601104736328, "model_grad_norm": 101.30139923095703, "player_loss": 16.659217834472656, "reward_loss": 5.541262626647949, "cont_loss": 0.5612697005271912, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.1, "dyn_loss": 7.0071024894714355, "rep_loss": 7.0071024894714355, "kl": 7.007102012634277, "prior_ent": 107.40826416015625, "post_ent": 107.32576751708984, "normed_target_mean": -0.0002656473370734602, "normed_target_std": 9.291797323385254e-05, "normed_target_min": -0.0004584426642395556, "normed_target_max": -0.000118343647045549, "EMA_005": -4.1911193875421304e-06, "EMA_095": -1.3404408036876703e-06, "value_mean": -1.1920928955078125e-07, "value_std": 0.0, "value_min": -1.1920928955078125e-07, "value_max": -1.1920928955078125e-07, "target_mean": -0.0002698384632822126, "target_std": 9.291797323385254e-05, "target_min": -0.000462633790448308, "target_max": -0.00012253476597834378, "imag_reward_mean": -0.0001417849271092564, "imag_reward_std": 7.890681445132941e-06, "imag_reward_min": -0.00016415119171142578, "imag_reward_max": -0.00011169910430908203, "imag_action_mean": 0.09324092417955399, "imag_action_std": 0.730926513671875, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 7.604339599609375, "actor_loss": -0.002079753205180168, "actor_grad_norm": 0.0013992789899930358, "value_loss": 7.571747779846191, "value_grad_norm": 10.393754959106445, "update_count": 1.0, "fps": 0}
{"step": 60, "dataset_size": 30.0, "train_return": -11.564987659454346, "train_length": 10.0, "train_episodes": 3.0}
{"step": 80, "dataset_size": 40.0, "train_return": -11.98969304561615, "train_length": 10.0, "train_episodes": 4.0}
{"step": 80}
{"step": 80}
{"step": 80, "eval_return": -10.119618231058121, "eval_length": 10.0, "eval_episodes": 10.0}
{"step": 80, "model_loss": 27.85209846496582, "model_grad_norm": 89.00126647949219, "player_loss": 17.08837890625, "reward_loss": 5.541262626647949, "cont_loss": 0.8410611152648926, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.1, "dyn_loss": 7.30232048034668, "rep_loss": 7.30232048034668, "kl": 7.3023200035095215, "prior_ent": 107.32582092285156, "post_ent": 107.32315063476562, "normed_target_mean": -0.00036437189555726945, "normed_target_std": 0.0001025846868287772, "normed_target_min": -0.0006536284927278757, "normed_target_max": -0.0001884916564449668, "EMA_005": -5.299864824337419e-06, "EMA_095": -2.201641791543807e-06, "value_mean": -1.1920928955078125e-07, "value_std": 0.0, "value_min": -1.1920928955078125e-07, "value_max": -1.1920928955078125e-07, "target_mean": -0.00036967179039493203, "target_std": 0.0001025846868287772, "target_min": -0.0006589283584617078, "target_max": -0.00019379152217879891, "imag_reward_mean": -0.00023288186639547348, "imag_reward_std": 1.2557514310174156e-05, "imag_reward_min": -0.00026345252990722656, "imag_reward_max": -0.00019299983978271484, "imag_action_mean": 0.07009124755859375, "imag_action_std": 0.7290160655975342, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 7.572746276855469, "actor_loss": -0.002046404406428337, "actor_grad_norm": 0.0015486314659938216, "value_loss": 6.015206336975098, "value_grad_norm": 8.41214656829834, "update_count": 1.0, "fps": 0}
{"step": 100, "dataset_size": 50.0, "train_return": -8.122398674488068, "train_length": 10.0, "train_episodes": 5.0}
{"step": 120, "dataset_size": 60.0, "train_return": -10.30464518070221, "train_length": 10.0, "train_episodes": 6.0}
{"step": 140, "dataset_size": 70.0, "train_return": -11.948935627937317, "train_length": 10.0, "train_episodes": 7.0}
{"step": 160, "dataset_size": 80.0, "train_return": -11.397158145904541, "train_length": 10.0, "train_episodes": 8.0}
