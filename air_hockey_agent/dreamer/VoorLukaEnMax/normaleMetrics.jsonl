{"step": 0, "dataset_size": 500.0, "train_return": -884.269265294075, "train_length": 500.0, "train_episodes": 1.0}
{"step": 0, "dataset_size": 1000.0, "train_return": -760.4985072612762, "train_length": 500.0, "train_episodes": 2.0}
{"step": 0, "dataset_size": 1500.0, "train_return": -910.4454216957092, "train_length": 500.0, "train_episodes": 3.0}
{"step": 0, "dataset_size": 2000.0, "train_return": -895.7636613845825, "train_length": 500.0, "train_episodes": 4.0}
{"step": 0, "dataset_size": 2166.0, "train_return": -103.28951543569565, "train_length": 166.0, "train_episodes": 5.0}
{"step": 5000}
{"step": 5000, "eval_return": -650.3522017478942, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 5000, "model_loss": 10.743896484375, "model_grad_norm": Infinity, "player_loss": 4.902971267700195, "reward_loss": 3.4542336463928223, "cont_loss": 0.028624171391129494, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999998, "dyn_loss": 3.9301116466522217, "rep_loss": 3.9301116466522217, "kl": 3.927461624145508, "prior_ent": 106.37218475341797, "post_ent": 103.32767486572266, "normed_target_mean": -0.35648712515830994, "normed_target_std": 0.20800411701202393, "normed_target_min": -0.6328371167182922, "normed_target_max": -0.06930658966302872, "EMA_005": -0.1379510909318924, "EMA_095": -0.03756401687860489, "value_mean": -0.0031840503215789795, "value_std": 5.9490925195859745e-05, "value_min": -0.0032417047768831253, "value_max": -0.002527396660298109, "target_mean": -0.4944382607936859, "target_std": 0.20800411701202393, "target_min": -0.7707881927490234, "target_max": -0.20725765824317932, "imag_reward_mean": -0.2070552408695221, "imag_reward_std": 0.00113814661744982, "imag_reward_min": -0.20813702046871185, "imag_reward_max": -0.19293704628944397, "imag_action_mean": -0.1983642578125, "imag_action_std": 0.734375, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 8.173644065856934, "actor_loss": 0.4873095750808716, "actor_grad_norm": 0.0015658123884350061, "value_loss": 9.858572006225586, "value_grad_norm": Infinity, "update_count": 100.0, "fps": 0}
{"step": 5332, "dataset_size": 2666.0, "train_return": -812.4468768239021, "train_length": 500.0, "train_episodes": 6.0}
{"step": 6024}
{"step": 6024, "eval_return": -312.56882508397103, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 6332, "dataset_size": 3166.0, "train_return": -576.3580750823021, "train_length": 500.0, "train_episodes": 7.0}
{"step": 7048}
{"step": 7048, "eval_return": -242.84558849334718, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 7332, "dataset_size": 3666.0, "train_return": -439.66286730766296, "train_length": 500.0, "train_episodes": 8.0}
{"step": 8072}
{"step": 8072, "eval_return": -305.3713659882545, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 8332, "dataset_size": 4166.0, "train_return": -375.0975142121315, "train_length": 500.0, "train_episodes": 9.0}
{"step": 9096}
{"step": 9096, "eval_return": -305.42397612929346, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 9332, "dataset_size": 4666.0, "train_return": -281.32849138975143, "train_length": 500.0, "train_episodes": 10.0}
{"step": 10120}
{"step": 10120, "eval_return": -329.2336025118828, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 10332, "dataset_size": 5166.0, "train_return": -267.28290140628815, "train_length": 500.0, "train_episodes": 11.0}
{"step": 11144}
{"step": 11144, "eval_return": -267.23585267663003, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 11332, "dataset_size": 5666.0, "train_return": -410.7648568749428, "train_length": 500.0, "train_episodes": 12.0}
{"step": 12168}
{"step": 12168, "eval_return": -269.4306761562824, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 12332, "dataset_size": 6166.0, "train_return": -338.9680893421173, "train_length": 500.0, "train_episodes": 13.0}
{"step": 13192}
{"step": 13192, "eval_return": -314.3330879509449, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 13332, "dataset_size": 6666.0, "train_return": -348.3392385542393, "train_length": 500.0, "train_episodes": 14.0}
{"step": 14216}
{"step": 14216, "eval_return": -431.4433207631111, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 14332, "dataset_size": 7166.0, "train_return": -363.64085417985916, "train_length": 500.0, "train_episodes": 15.0}
{"step": 15000, "model_loss": 3.6544876098632812, "model_grad_norm": 6.785306453704834, "player_loss": 0.7324581146240234, "reward_loss": 1.0362694263458252, "cont_loss": 2.3661979867029004e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 3.142892599105835, "rep_loss": 3.142892599105835, "kl": 3.104447603225708, "prior_ent": 50.417720794677734, "post_ent": 46.86200714111328, "normed_target_mean": 0.36380988359451294, "normed_target_std": 0.3824024796485901, "normed_target_min": -0.3397082984447479, "normed_target_max": 0.9334114193916321, "EMA_005": -7.645992279052734, "EMA_095": -2.8386809825897217, "value_mean": -2.6229045391082764, "value_std": 0.11643901467323303, "value_min": -2.7493515014648438, "value_max": -2.2692923545837402, "target_mean": -5.439144134521484, "target_std": 1.649133563041687, "target_min": -8.716060638427734, "target_max": -2.9403655529022217, "imag_reward_mean": -1.2005925178527832, "imag_reward_std": 0.3517444431781769, "imag_reward_min": -1.6334681510925293, "imag_reward_max": -0.537165105342865, "imag_action_mean": -0.485107421875, "imag_action_std": 0.708984375, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 4.320806980133057, "actor_loss": 0.7066650390625, "actor_grad_norm": 0.0034579490311443806, "value_loss": 4.921082973480225, "value_grad_norm": 8.736693382263184, "update_count": 1350.0, "fps": 4.559488924642035}
{"step": 15240}
{"step": 15240, "eval_return": -262.0467711627483, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 15332, "dataset_size": 7666.0, "train_return": -369.03922814130783, "train_length": 500.0, "train_episodes": 16.0}
{"step": 16264}
{"step": 16264, "eval_return": -254.7719978839159, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 16332, "dataset_size": 8166.0, "train_return": -376.5727884173393, "train_length": 500.0, "train_episodes": 17.0}
{"step": 17288}
{"step": 17288, "eval_return": -393.3533128976822, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 17332, "dataset_size": 8666.0, "train_return": -298.0310171544552, "train_length": 500.0, "train_episodes": 18.0}
{"step": 18312}
{"step": 18312, "eval_return": -285.8599125623703, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 18332, "dataset_size": 9166.0, "train_return": -276.0238176882267, "train_length": 500.0, "train_episodes": 19.0}
{"step": 19332, "dataset_size": 9666.0, "train_return": -214.93527793884277, "train_length": 500.0, "train_episodes": 20.0}
{"step": 19336}
{"step": 19336, "eval_return": -289.95822407603265, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 20332, "dataset_size": 10166.0, "train_return": -318.8610171377659, "train_length": 500.0, "train_episodes": 21.0}
{"step": 20360}
{"step": 20360, "eval_return": -226.902151478827, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 21332, "dataset_size": 10666.0, "train_return": -192.33309222757816, "train_length": 500.0, "train_episodes": 22.0}
{"step": 21384}
{"step": 21384, "eval_return": -305.64302803874017, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 22332, "dataset_size": 11166.0, "train_return": -172.13789611682296, "train_length": 500.0, "train_episodes": 23.0}
{"step": 22408}
{"step": 22408, "eval_return": -219.39474638849498, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 23332, "dataset_size": 11666.0, "train_return": -189.26839944720268, "train_length": 500.0, "train_episodes": 24.0}
{"step": 23432}
{"step": 23432, "eval_return": -245.70129331350327, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 24332, "dataset_size": 12166.0, "train_return": -255.39653307199478, "train_length": 500.0, "train_episodes": 25.0}
{"step": 24456}
{"step": 24456, "eval_return": -220.86975888609885, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 25000, "model_loss": 2.8493692874908447, "model_grad_norm": 6.368495941162109, "player_loss": 0.31219518184661865, "reward_loss": 0.7345398664474487, "cont_loss": 4.855906809098087e-06, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 3.0043821334838867, "rep_loss": 3.0043821334838867, "kl": 2.952523708343506, "prior_ent": 37.89973449707031, "post_ent": 34.69146728515625, "normed_target_mean": 0.5038766860961914, "normed_target_std": 0.31294554471969604, "normed_target_min": -0.27254945039749146, "normed_target_max": 1.1641325950622559, "EMA_005": -15.946698188781738, "EMA_095": -7.866145133972168, "value_mean": -10.089975357055664, "value_std": 1.2831811904907227, "value_min": -11.588493347167969, "value_max": -6.095724105834961, "target_mean": -12.002243995666504, "target_std": 2.5547823905944824, "target_min": -18.08213996887207, "target_max": -6.474854469299316, "imag_reward_mean": -0.9384359121322632, "imag_reward_std": 0.4960307478904724, "imag_reward_min": -1.8742938041687012, "imag_reward_max": -0.06932258605957031, "imag_action_mean": -0.0276336669921875, "imag_action_std": 0.86279296875, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 0.8460808396339417, "actor_loss": 0.27105337381362915, "actor_grad_norm": 0.022842688485980034, "value_loss": 2.323378324508667, "value_grad_norm": 1.8540207147598267, "update_count": 2600.0, "fps": 4.885088763966327}
{"step": 25332, "dataset_size": 12666.0, "train_return": -215.60899182222784, "train_length": 500.0, "train_episodes": 26.0}
{"step": 25480}
{"step": 25480, "eval_return": -224.6542009741068, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 26332, "dataset_size": 13166.0, "train_return": -163.4808525722474, "train_length": 500.0, "train_episodes": 27.0}
{"step": 26504}
{"step": 26504, "eval_return": -230.9555444650352, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 27332, "dataset_size": 13666.0, "train_return": -150.00861651450396, "train_length": 500.0, "train_episodes": 28.0}
{"step": 27528}
{"step": 27528, "eval_return": -277.23303327709436, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 28332, "dataset_size": 14166.0, "train_return": -248.99281587451696, "train_length": 500.0, "train_episodes": 29.0}
{"step": 28552}
{"step": 28552, "eval_return": -211.71975506320595, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 29332, "dataset_size": 14666.0, "train_return": -297.149276252836, "train_length": 500.0, "train_episodes": 30.0}
{"step": 29576}
{"step": 29576, "eval_return": -451.8849361434579, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 30332, "dataset_size": 15166.0, "train_return": -553.4219653606415, "train_length": 500.0, "train_episodes": 31.0}
{"step": 30600}
{"step": 30600, "eval_return": -530.7078585471958, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 31332, "dataset_size": 15666.0, "train_return": -587.5406055822968, "train_length": 500.0, "train_episodes": 32.0}
{"step": 31624}
{"step": 31624, "eval_return": 1852.9328996479512, "eval_length": 204.0, "eval_episodes": 5.0}
{"step": 32332, "dataset_size": 16166.0, "train_return": -476.57405932992697, "train_length": 500.0, "train_episodes": 33.0}
{"step": 32648}
{"step": 32648, "eval_return": -346.7437216103077, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 33332, "dataset_size": 16666.0, "train_return": -505.0523707270622, "train_length": 500.0, "train_episodes": 34.0}
{"step": 33672}
{"step": 33672, "eval_return": -335.12263973355294, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 34332, "dataset_size": 17166.0, "train_return": -366.97337770462036, "train_length": 500.0, "train_episodes": 35.0}
{"step": 34696}
{"step": 34696, "eval_return": -351.7917854428291, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 35000, "model_loss": 2.786121368408203, "model_grad_norm": 6.3083906173706055, "player_loss": 0.2752479612827301, "reward_loss": 0.7230889201164246, "cont_loss": 1.7080720908779767e-06, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.979637861251831, "rep_loss": 2.979637861251831, "kl": 2.9211666584014893, "prior_ent": 37.29684829711914, "post_ent": 34.20435333251953, "normed_target_mean": 0.48379892110824585, "normed_target_std": 0.3405463695526123, "normed_target_min": -0.23058916628360748, "normed_target_max": 1.0885547399520874, "EMA_005": -23.87376594543457, "EMA_095": -6.406401634216309, "value_mean": -14.192925453186035, "value_std": 5.141036510467529, "value_min": -21.7561092376709, "value_max": -4.355413913726807, "target_mean": -15.380056381225586, "target_std": 5.931396961212158, "target_min": -27.837568283081055, "target_max": -4.895153522491455, "imag_reward_mean": -0.804193913936615, "imag_reward_std": 0.4821970760822296, "imag_reward_min": -1.8747888803482056, "imag_reward_max": -0.020566212013363838, "imag_action_mean": 0.05877685546875, "imag_action_std": 0.85009765625, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.3269288539886475, "actor_loss": 0.0694098025560379, "actor_grad_norm": 0.02914966456592083, "value_loss": 1.762939453125, "value_grad_norm": 1.028817057609558, "update_count": 3850.0, "fps": 13.079270709254702}
{"step": 35332, "dataset_size": 17666.0, "train_return": -452.4101398587227, "train_length": 500.0, "train_episodes": 36.0}
{"step": 35720}
{"step": 35720, "eval_return": -360.1053017258644, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 36332, "dataset_size": 18166.0, "train_return": -357.5185696184635, "train_length": 500.0, "train_episodes": 37.0}
{"step": 36744}
{"step": 36744, "eval_return": -384.5886932194233, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 37332, "dataset_size": 18666.0, "train_return": -400.5974340736866, "train_length": 500.0, "train_episodes": 38.0}
{"step": 37768}
{"step": 37768, "eval_return": -400.01490822434425, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 38332, "dataset_size": 19166.0, "train_return": -421.3938053846359, "train_length": 500.0, "train_episodes": 39.0}
{"step": 38792}
{"step": 38792, "eval_return": -402.76020417809485, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 39332, "dataset_size": 19666.0, "train_return": -339.2502750605345, "train_length": 500.0, "train_episodes": 40.0}
{"step": 39816}
{"step": 39816, "eval_return": 1604.7925484240054, "eval_length": 473.2, "eval_episodes": 5.0}
{"step": 40332, "dataset_size": 20166.0, "train_return": -454.51327204704285, "train_length": 500.0, "train_episodes": 41.0}
{"step": 40840}
{"step": 40840, "eval_return": -296.7757491186261, "eval_length": 420.2, "eval_episodes": 5.0}
{"step": 41332, "dataset_size": 20666.0, "train_return": -390.86874306201935, "train_length": 500.0, "train_episodes": 42.0}
{"step": 41864}
{"step": 41864, "eval_return": 1689.5660707741977, "eval_length": 429.4, "eval_episodes": 5.0}
{"step": 42332, "dataset_size": 21166.0, "train_return": -387.7771677672863, "train_length": 500.0, "train_episodes": 43.0}
{"step": 42888}
{"step": 42888, "eval_return": -428.6880524337292, "eval_length": 455.0, "eval_episodes": 5.0}
{"step": 43332, "dataset_size": 21666.0, "train_return": -234.8024017214775, "train_length": 500.0, "train_episodes": 44.0}
{"step": 43912}
{"step": 43912, "eval_return": -449.1787504196167, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 44332, "dataset_size": 22166.0, "train_return": -539.7700222730637, "train_length": 500.0, "train_episodes": 45.0}
{"step": 44936}
{"step": 44936, "eval_return": -461.1580436259508, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 45000, "model_loss": 2.753232717514038, "model_grad_norm": 6.015403747558594, "player_loss": 0.2684251368045807, "reward_loss": 0.6843982934951782, "cont_loss": 6.922315947122115e-07, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 3.0006814002990723, "rep_loss": 3.0006814002990723, "kl": 2.938429117202759, "prior_ent": 37.314857482910156, "post_ent": 34.25046157836914, "normed_target_mean": 0.4932429790496826, "normed_target_std": 0.30999597907066345, "normed_target_min": -0.23383662104606628, "normed_target_max": 1.0742511749267578, "EMA_005": -29.411006927490234, "EMA_095": -6.548232078552246, "value_mean": -17.387481689453125, "value_std": 6.598161697387695, "value_min": -29.616987228393555, "value_max": -4.274073600769043, "target_mean": -18.125476837158203, "target_std": 7.094034194946289, "target_min": -34.739906311035156, "target_max": -4.856945514678955, "imag_reward_mean": -0.8134375214576721, "imag_reward_std": 0.450762540102005, "imag_reward_min": -1.87442147731781, "imag_reward_max": -0.011629133485257626, "imag_action_mean": -0.0017175674438476562, "imag_action_std": 0.85498046875, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 0.536172091960907, "actor_loss": 0.03179353103041649, "actor_grad_norm": 0.030540667474269867, "value_loss": 1.6202900409698486, "value_grad_norm": 1.1867575645446777, "update_count": 5100.0, "fps": 12.988108920281368}
{"step": 45332, "dataset_size": 22666.0, "train_return": -567.9173218011856, "train_length": 500.0, "train_episodes": 46.0}
{"step": 45960}
{"step": 45960, "eval_return": -427.49566022753714, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 46332, "dataset_size": 23166.0, "train_return": -513.7039969563484, "train_length": 500.0, "train_episodes": 47.0}
{"step": 46984}
{"step": 46984, "eval_return": -442.80324894785883, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 47332, "dataset_size": 23666.0, "train_return": -490.23739586398005, "train_length": 500.0, "train_episodes": 48.0}
{"step": 48008}
{"step": 48008, "eval_return": 1580.7113989800214, "eval_length": 456.6, "eval_episodes": 5.0}
{"step": 48332, "dataset_size": 24166.0, "train_return": -370.47370643913746, "train_length": 500.0, "train_episodes": 49.0}
{"step": 49032}
{"step": 49032, "eval_return": 1739.215395605564, "eval_length": 390.4, "eval_episodes": 5.0}
{"step": 49332, "dataset_size": 24666.0, "train_return": -575.019673705101, "train_length": 500.0, "train_episodes": 50.0}
{"step": 49948, "dataset_size": 24974.0, "train_return": -116.00695845484734, "train_length": 308.0, "train_episodes": 51.0}
{"step": 50056}
{"step": 50056, "eval_return": -392.1964799329638, "eval_length": 390.0, "eval_episodes": 5.0}
{"step": 50448, "dataset_size": 25224.0, "train_return": -225.18086993694305, "train_length": 250.0, "train_episodes": 52.0}
{"step": 51080}
{"step": 51080, "eval_return": -402.8767152838409, "eval_length": 431.6, "eval_episodes": 5.0}
{"step": 51448, "dataset_size": 25724.0, "train_return": -446.90299700573087, "train_length": 500.0, "train_episodes": 53.0}
{"step": 51726, "dataset_size": 25863.0, "train_return": -127.83964276313782, "train_length": 139.0, "train_episodes": 54.0}
{"step": 52104}
{"step": 52104, "eval_return": -432.33600387722254, "eval_length": 455.2, "eval_episodes": 5.0}
{"step": 52554, "dataset_size": 26277.0, "train_return": 9583.936843544245, "train_length": 414.0, "train_episodes": 55.0}
{"step": 53128}
{"step": 53128, "eval_return": -400.6814976334572, "eval_length": 407.6, "eval_episodes": 5.0}
{"step": 53386, "dataset_size": 26693.0, "train_return": -315.35338097810745, "train_length": 416.0, "train_episodes": 56.0}
{"step": 53948, "dataset_size": 26974.0, "train_return": -313.66071367263794, "train_length": 281.0, "train_episodes": 57.0}
{"step": 54152}
{"step": 54152, "eval_return": -493.6510482788086, "eval_length": 426.8, "eval_episodes": 5.0}
{"step": 54948, "dataset_size": 27474.0, "train_return": -541.6657880246639, "train_length": 500.0, "train_episodes": 58.0}
{"step": 55000, "model_loss": 2.7830071449279785, "model_grad_norm": Infinity, "player_loss": 0.29174578189849854, "reward_loss": 0.664289653301239, "cont_loss": 7.714792445767671e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 3.0448241233825684, "rep_loss": 3.0448241233825684, "kl": 2.982642650604248, "prior_ent": 37.664894104003906, "post_ent": 34.57819747924805, "normed_target_mean": 0.46386727690696716, "normed_target_std": 0.3069814443588257, "normed_target_min": -0.21182781457901, "normed_target_max": 1.0795350074768066, "EMA_005": -32.133392333984375, "EMA_095": -7.012527942657471, "value_mean": -19.879169464111328, "value_std": 7.32058572769165, "value_min": -33.07344055175781, "value_max": -4.652202129364014, "target_mean": -20.48053741455078, "target_std": 7.708695411682129, "target_min": -37.3961181640625, "target_max": -5.009191513061523, "imag_reward_mean": -0.8260343670845032, "imag_reward_std": 0.4387699365615845, "imag_reward_min": -1.862312912940979, "imag_reward_max": -0.008868856355547905, "imag_action_mean": -0.09271240234375, "imag_action_std": 0.85205078125, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 0.18854744732379913, "actor_loss": 0.023937994614243507, "actor_grad_norm": 0.028877826407551765, "value_loss": 1.5346508026123047, "value_grad_norm": 1.2088078260421753, "update_count": 6350.0, "fps": 13.817161050578813}
{"step": 55176}
{"step": 55176, "eval_return": 1578.7606951355933, "eval_length": 390.4, "eval_episodes": 5.0}
{"step": 55394, "dataset_size": 27697.0, "train_return": 9788.678344249725, "train_length": 223.0, "train_episodes": 59.0}
{"step": 56200}
{"step": 56200, "eval_return": -271.9351819127798, "eval_length": 275.2, "eval_episodes": 5.0}
{"step": 56394, "dataset_size": 28197.0, "train_return": -528.2214016914368, "train_length": 500.0, "train_episodes": 60.0}
{"step": 57224}
{"step": 57224, "eval_return": -472.5610874891281, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 57394, "dataset_size": 28697.0, "train_return": -552.1225467920303, "train_length": 500.0, "train_episodes": 61.0}
{"step": 58248}
{"step": 58248, "eval_return": -377.5381554365158, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 58394, "dataset_size": 29197.0, "train_return": -493.43396377563477, "train_length": 500.0, "train_episodes": 62.0}
{"step": 59272}
{"step": 59272, "eval_return": -334.76456056684253, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 59394, "dataset_size": 29697.0, "train_return": -462.5720616579056, "train_length": 500.0, "train_episodes": 63.0}
{"step": 60296}
{"step": 60296, "eval_return": -401.92860406041143, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 60394, "dataset_size": 30197.0, "train_return": -392.5085325539112, "train_length": 500.0, "train_episodes": 64.0}
{"step": 61320}
{"step": 61320, "eval_return": -424.9697503685951, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 61394, "dataset_size": 30697.0, "train_return": -432.2609148323536, "train_length": 500.0, "train_episodes": 65.0}
{"step": 62344}
{"step": 62344, "eval_return": -410.754631857574, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 62394, "dataset_size": 31197.0, "train_return": -436.21094366908073, "train_length": 500.0, "train_episodes": 66.0}
{"step": 63368}
{"step": 63368, "eval_return": -377.64487609863284, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 63394, "dataset_size": 31697.0, "train_return": -389.0932107269764, "train_length": 500.0, "train_episodes": 67.0}
{"step": 64392}
{"step": 64392, "eval_return": -389.24845197200773, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 64394, "dataset_size": 32197.0, "train_return": -385.4654759466648, "train_length": 500.0, "train_episodes": 68.0}
{"step": 65000, "model_loss": 2.7331061363220215, "model_grad_norm": 6.1250505447387695, "player_loss": 0.28026217222213745, "reward_loss": 0.647498369216919, "cont_loss": 0.00017257023137062788, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 3.0086216926574707, "rep_loss": 3.0086216926574707, "kl": 2.944714069366455, "prior_ent": 37.780784606933594, "post_ent": 34.74055099487305, "normed_target_mean": 0.44622012972831726, "normed_target_std": 0.29957976937294006, "normed_target_min": -0.16032111644744873, "normed_target_max": 1.1019705533981323, "EMA_005": -36.617218017578125, "EMA_095": -7.61370325088501, "value_mean": -23.146886825561523, "value_std": 8.262770652770996, "value_min": -37.11457443237305, "value_max": -4.650318622589111, "target_mean": -23.674739837646484, "target_std": 8.688384056091309, "target_min": -41.2619514465332, "target_max": -4.652310371398926, "imag_reward_mean": -0.8462017774581909, "imag_reward_std": 0.42888301610946655, "imag_reward_min": -1.8636101484298706, "imag_reward_max": 0.013312220573425293, "imag_action_mean": -0.167236328125, "imag_action_std": 0.841796875, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": -0.3733760118484497, "actor_loss": 0.018268823623657227, "actor_grad_norm": 0.038450200110673904, "value_loss": 1.5915818214416504, "value_grad_norm": 1.475511074066162, "update_count": 7600.0, "fps": 13.222204357637889}
{"step": 65394, "dataset_size": 32697.0, "train_return": -369.0948045104742, "train_length": 500.0, "train_episodes": 69.0}
{"step": 65416}
{"step": 65416, "eval_return": -406.1426490738988, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 66394, "dataset_size": 33197.0, "train_return": -308.0409383252263, "train_length": 500.0, "train_episodes": 70.0}
{"step": 66440}
{"step": 66440, "eval_return": -335.51418088153, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 67394, "dataset_size": 33697.0, "train_return": -303.07035963237286, "train_length": 500.0, "train_episodes": 71.0}
{"step": 67464}
{"step": 67464, "eval_return": -353.11957453489305, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 68394, "dataset_size": 34197.0, "train_return": -335.4995099455118, "train_length": 500.0, "train_episodes": 72.0}
{"step": 68488}
{"step": 68488, "eval_return": -349.69786117374895, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 69394, "dataset_size": 34697.0, "train_return": -376.3893465101719, "train_length": 500.0, "train_episodes": 73.0}
{"step": 69512}
{"step": 69512, "eval_return": -288.55576237887146, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 70394, "dataset_size": 35197.0, "train_return": -383.5893085002899, "train_length": 500.0, "train_episodes": 74.0}
{"step": 70536}
{"step": 70536, "eval_return": -368.41819305121896, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 71394, "dataset_size": 35697.0, "train_return": -289.7911431789398, "train_length": 500.0, "train_episodes": 75.0}
{"step": 71560}
{"step": 71560, "eval_return": -311.05841706991197, "eval_length": 448.2, "eval_episodes": 5.0}
{"step": 72394, "dataset_size": 36197.0, "train_return": -126.32841527462006, "train_length": 500.0, "train_episodes": 76.0}
{"step": 72584}
{"step": 72584, "eval_return": -296.8435122042894, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 73394, "dataset_size": 36697.0, "train_return": -413.7341545820236, "train_length": 500.0, "train_episodes": 77.0}
{"step": 73608}
{"step": 73608, "eval_return": -394.4076362013817, "eval_length": 429.0, "eval_episodes": 5.0}
{"step": 74394, "dataset_size": 37197.0, "train_return": -39.434629797935486, "train_length": 500.0, "train_episodes": 78.0}
{"step": 74632}
{"step": 74632, "eval_return": -438.9272906839848, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 75000, "model_loss": 2.6887922286987305, "model_grad_norm": Infinity, "player_loss": 0.26036977767944336, "reward_loss": 0.6541434526443481, "cont_loss": 6.159724580356851e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.95702862739563, "rep_loss": 2.95702862739563, "kl": 2.890749454498291, "prior_ent": 37.92903137207031, "post_ent": 34.959312438964844, "normed_target_mean": 0.4244074821472168, "normed_target_std": 0.2958725690841675, "normed_target_min": -0.2019379436969757, "normed_target_max": 1.1221904754638672, "EMA_005": -37.77406692504883, "EMA_095": -7.872828006744385, "value_mean": -24.6563777923584, "value_std": 8.507190704345703, "value_min": -39.908592224121094, "value_max": -4.267971515655518, "target_mean": -25.079286575317383, "target_std": 8.848548889160156, "target_min": -43.80470657348633, "target_max": -4.220608711242676, "imag_reward_mean": -0.8263933658599854, "imag_reward_std": 0.4101443290710449, "imag_reward_min": -1.846613883972168, "imag_reward_max": 0.03991074860095978, "imag_action_mean": -0.1536865234375, "imag_action_std": 0.84765625, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": -0.3876475691795349, "actor_loss": 0.014237609691917896, "actor_grad_norm": 0.04523821920156479, "value_loss": 1.5679993629455566, "value_grad_norm": 1.5833840370178223, "update_count": 8850.0, "fps": 12.996856714920945}
{"step": 75394, "dataset_size": 37697.0, "train_return": -653.3550453782082, "train_length": 500.0, "train_episodes": 79.0}
{"step": 75656}
{"step": 75656, "eval_return": -377.060850661993, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 76394, "dataset_size": 38197.0, "train_return": -423.8771276175976, "train_length": 500.0, "train_episodes": 80.0}
{"step": 76680}
{"step": 76680, "eval_return": -264.44854966066777, "eval_length": 412.0, "eval_episodes": 5.0}
{"step": 77394, "dataset_size": 38697.0, "train_return": -462.9087215065956, "train_length": 500.0, "train_episodes": 81.0}
{"step": 77460, "dataset_size": 38730.0, "train_return": -17.993420362472534, "train_length": 33.0, "train_episodes": 82.0}
{"step": 77704}
{"step": 77704, "eval_return": -252.0897776514292, "eval_length": 440.0, "eval_episodes": 5.0}
{"step": 78460, "dataset_size": 39230.0, "train_return": -470.3987430818379, "train_length": 500.0, "train_episodes": 83.0}
{"step": 78728}
{"step": 78728, "eval_return": -279.2728746384382, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 79460, "dataset_size": 39730.0, "train_return": -16.429279804229736, "train_length": 500.0, "train_episodes": 84.0}
{"step": 79752}
{"step": 79752, "eval_return": -396.4448626816273, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 80460, "dataset_size": 40230.0, "train_return": -638.5411706566811, "train_length": 500.0, "train_episodes": 85.0}
{"step": 80776}
{"step": 80776, "eval_return": 1796.3390305846929, "eval_length": 428.0, "eval_episodes": 5.0}
{"step": 81460, "dataset_size": 40730.0, "train_return": -439.2785443365574, "train_length": 500.0, "train_episodes": 86.0}
{"step": 81800}
{"step": 81800, "eval_return": -307.20067278146746, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 82460, "dataset_size": 41230.0, "train_return": -309.49751914292574, "train_length": 500.0, "train_episodes": 87.0}
{"step": 82824}
{"step": 82824, "eval_return": -309.9486805029213, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 83460, "dataset_size": 41730.0, "train_return": -421.908481746912, "train_length": 500.0, "train_episodes": 88.0}
{"step": 83848}
{"step": 83848, "eval_return": -299.92459375858306, "eval_length": 343.0, "eval_episodes": 5.0}
{"step": 84460, "dataset_size": 42230.0, "train_return": -408.24398323893547, "train_length": 500.0, "train_episodes": 89.0}
{"step": 84872}
{"step": 84872, "eval_return": -292.5380017608404, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 85000, "model_loss": 2.665700674057007, "model_grad_norm": 6.466659069061279, "player_loss": 0.2558065950870514, "reward_loss": 0.6412280797958374, "cont_loss": 1.1098883078375366e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.947758674621582, "rep_loss": 2.947758674621582, "kl": 2.88142466545105, "prior_ent": 38.404354095458984, "post_ent": 35.44915008544922, "normed_target_mean": 0.476322203874588, "normed_target_std": 0.29747918248176575, "normed_target_min": -0.1655503213405609, "normed_target_max": 1.1002652645111084, "EMA_005": -42.00907516479492, "EMA_095": -7.782407760620117, "value_mean": -25.354969024658203, "value_std": 9.746537208557129, "value_min": -43.752899169921875, "value_max": -4.424874782562256, "target_mean": -25.66802406311035, "target_std": 10.179949760437012, "target_min": -47.65285873413086, "target_max": -4.368735313415527, "imag_reward_mean": -0.8105679750442505, "imag_reward_std": 0.41991689801216125, "imag_reward_min": -1.8446522951126099, "imag_reward_max": 0.04342978075146675, "imag_action_mean": -0.07733154296875, "imag_action_std": 0.8525390625, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": -0.27164366841316223, "actor_loss": 0.009196896106004715, "actor_grad_norm": 0.039606768637895584, "value_loss": 1.626395344734192, "value_grad_norm": 1.6664273738861084, "update_count": 10100.0, "fps": 13.22641513134177}
{"step": 85460, "dataset_size": 42730.0, "train_return": -426.91617184877396, "train_length": 500.0, "train_episodes": 90.0}
{"step": 85648, "dataset_size": 42824.0, "train_return": -73.61942660808563, "train_length": 94.0, "train_episodes": 91.0}
{"step": 85896}
{"step": 85896, "eval_return": -402.5914577446878, "eval_length": 441.2, "eval_episodes": 5.0}
{"step": 86648, "dataset_size": 43324.0, "train_return": -29.680882453918457, "train_length": 500.0, "train_episodes": 92.0}
{"step": 86920}
{"step": 86920, "eval_return": -485.3856820642948, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 87648, "dataset_size": 43824.0, "train_return": -483.10643795132637, "train_length": 500.0, "train_episodes": 93.0}
{"step": 87944}
{"step": 87944, "eval_return": -239.80921942144633, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 88648, "dataset_size": 44324.0, "train_return": -224.61059544607997, "train_length": 500.0, "train_episodes": 94.0}
{"step": 88968}
{"step": 88968, "eval_return": -366.58357810676097, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 89648, "dataset_size": 44824.0, "train_return": -495.31412839889526, "train_length": 500.0, "train_episodes": 95.0}
{"step": 89760, "dataset_size": 44880.0, "train_return": -52.208109855651855, "train_length": 56.0, "train_episodes": 96.0}
{"step": 89992}
{"step": 89992, "eval_return": -336.93506449460983, "eval_length": 406.4, "eval_episodes": 5.0}
{"step": 90254, "dataset_size": 45127.0, "train_return": -21.330560326576233, "train_length": 247.0, "train_episodes": 97.0}
{"step": 91016}
{"step": 91016, "eval_return": -307.9133210219443, "eval_length": 427.8, "eval_episodes": 5.0}
{"step": 91254, "dataset_size": 45627.0, "train_return": -223.90318567305803, "train_length": 500.0, "train_episodes": 98.0}
{"step": 92040}
{"step": 92040, "eval_return": 1856.7889183446764, "eval_length": 430.8, "eval_episodes": 5.0}
{"step": 92254, "dataset_size": 46127.0, "train_return": -20.2832670211792, "train_length": 500.0, "train_episodes": 99.0}
{"step": 93064}
{"step": 93064, "eval_return": 1751.2016672968864, "eval_length": 406.0, "eval_episodes": 5.0}
{"step": 93254, "dataset_size": 46627.0, "train_return": -274.46875536441803, "train_length": 500.0, "train_episodes": 100.0}
{"step": 94088}
{"step": 94088, "eval_return": -391.1251609303057, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 94254, "dataset_size": 47127.0, "train_return": -500.8174830675125, "train_length": 500.0, "train_episodes": 101.0}
{"step": 95000, "model_loss": 2.6363632678985596, "model_grad_norm": Infinity, "player_loss": 0.25265488028526306, "reward_loss": 0.627993643283844, "cont_loss": 3.3337204513372853e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.9261345863342285, "rep_loss": 2.9261345863342285, "kl": 2.8585524559020996, "prior_ent": 38.861244201660156, "post_ent": 35.935935974121094, "normed_target_mean": 0.4743228554725647, "normed_target_std": 0.29795828461647034, "normed_target_min": -0.17876426875591278, "normed_target_max": 1.0838911533355713, "EMA_005": -44.82265090942383, "EMA_095": -7.1955718994140625, "value_mean": -26.62738800048828, "value_std": 10.808257102966309, "value_min": -48.202354431152344, "value_max": -4.122605323791504, "target_mean": -26.98039436340332, "target_std": 11.216120719909668, "target_min": -51.542076110839844, "target_max": -4.048549175262451, "imag_reward_mean": -0.7996613383293152, "imag_reward_std": 0.4202452003955841, "imag_reward_min": -1.8307892084121704, "imag_reward_max": 0.05881871283054352, "imag_action_mean": -0.1746826171875, "imag_action_std": 0.83544921875, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": -0.0619085431098938, "actor_loss": 0.0093581173568964, "actor_grad_norm": 0.040399499237537384, "value_loss": 1.622313141822815, "value_grad_norm": Infinity, "update_count": 11350.0, "fps": 13.583343401059851}
{"step": 95112}
{"step": 95112, "eval_return": -226.70300403237343, "eval_length": 441.6, "eval_episodes": 5.0}
{"step": 95254, "dataset_size": 47627.0, "train_return": -455.26515409350395, "train_length": 500.0, "train_episodes": 102.0}
{"step": 96136}
{"step": 96136, "eval_return": -161.68890840411186, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 96254, "dataset_size": 48127.0, "train_return": -479.453655898571, "train_length": 500.0, "train_episodes": 103.0}
{"step": 97160}
{"step": 97160, "eval_return": -228.01262214630842, "eval_length": 369.6, "eval_episodes": 5.0}
{"step": 97254, "dataset_size": 48627.0, "train_return": -306.23256066441536, "train_length": 500.0, "train_episodes": 104.0}
{"step": 98184}
{"step": 98184, "eval_return": -243.79674497768283, "eval_length": 408.4, "eval_episodes": 5.0}
{"step": 98254, "dataset_size": 49127.0, "train_return": -510.572546929121, "train_length": 500.0, "train_episodes": 105.0}
{"step": 99208}
{"step": 99208, "eval_return": 1770.3102558040991, "eval_length": 413.4, "eval_episodes": 5.0}
{"step": 99254, "dataset_size": 49627.0, "train_return": -207.35070615634322, "train_length": 500.0, "train_episodes": 106.0}
{"step": 100232}
{"step": 100232, "eval_return": -176.07345900163054, "eval_length": 331.6, "eval_episodes": 5.0}
{"step": 100254, "dataset_size": 50127.0, "train_return": -471.136680200696, "train_length": 500.0, "train_episodes": 107.0}
{"step": 100318, "dataset_size": 50159.0, "train_return": -23.97517740726471, "train_length": 32.0, "train_episodes": 108.0}
{"step": 101256}
{"step": 101256, "eval_return": -227.94478695429862, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 101318, "dataset_size": 50659.0, "train_return": -538.5137035418302, "train_length": 500.0, "train_episodes": 109.0}
{"step": 101540, "dataset_size": 50770.0, "train_return": -90.66238582134247, "train_length": 111.0, "train_episodes": 110.0}
{"step": 102280}
{"step": 102280, "eval_return": 1815.3542620778085, "eval_length": 412.6, "eval_episodes": 5.0}
{"step": 102540, "dataset_size": 51270.0, "train_return": -481.22806456685066, "train_length": 500.0, "train_episodes": 111.0}
{"step": 103304}
{"step": 103304, "eval_return": -295.0116243008524, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 103540, "dataset_size": 51770.0, "train_return": -361.6971066747792, "train_length": 500.0, "train_episodes": 112.0}
{"step": 103948, "dataset_size": 51974.0, "train_return": -17.400123476982117, "train_length": 204.0, "train_episodes": 113.0}
{"step": 104328}
{"step": 104328, "eval_return": 1764.1242083381862, "eval_length": 461.4, "eval_episodes": 5.0}
{"step": 104948, "dataset_size": 52474.0, "train_return": -169.88950857601594, "train_length": 500.0, "train_episodes": 114.0}
{"step": 105000, "model_loss": 2.619407892227173, "model_grad_norm": 6.483952522277832, "player_loss": 0.24597133696079254, "reward_loss": 0.6275379657745361, "cont_loss": 1.5579473256366327e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.909804582595825, "rep_loss": 2.909804582595825, "kl": 2.8412680625915527, "prior_ent": 39.11409378051758, "post_ent": 36.21080017089844, "normed_target_mean": 0.4632551372051239, "normed_target_std": 0.2999284267425537, "normed_target_min": -0.13985158503055573, "normed_target_max": 1.0723148584365845, "EMA_005": -50.41078567504883, "EMA_095": -6.783702373504639, "value_mean": -29.738475799560547, "value_std": 12.662965774536133, "value_min": -53.01578140258789, "value_max": -3.6478195190429688, "target_mean": -30.194040298461914, "target_std": 13.084444999694824, "target_min": -56.505367279052734, "target_max": -3.63073992729187, "imag_reward_mean": -0.7872152328491211, "imag_reward_std": 0.41880321502685547, "imag_reward_min": -1.8218543529510498, "imag_reward_max": 0.07285287231206894, "imag_action_mean": -0.09320068359375, "imag_action_std": 0.84228515625, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 0.41842079162597656, "actor_loss": 0.010306947864592075, "actor_grad_norm": 0.03949829563498497, "value_loss": 1.619964599609375, "value_grad_norm": 1.804059386253357, "update_count": 12600.0, "fps": 13.380774765523018}
{"step": 105134, "dataset_size": 52567.0, "train_return": -19.76183331012726, "train_length": 93.0, "train_episodes": 115.0}
{"step": 105352}
{"step": 105352, "eval_return": -263.32001617252826, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 106134, "dataset_size": 53067.0, "train_return": -271.4979458581656, "train_length": 500.0, "train_episodes": 116.0}
{"step": 106376}
{"step": 106376, "eval_return": -276.0405623923987, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 107134, "dataset_size": 53567.0, "train_return": -493.53113105893135, "train_length": 500.0, "train_episodes": 117.0}
{"step": 107400}
{"step": 107400, "eval_return": -182.9978175356984, "eval_length": 326.6, "eval_episodes": 5.0}
{"step": 108134, "dataset_size": 54067.0, "train_return": -266.02529618889093, "train_length": 500.0, "train_episodes": 118.0}
{"step": 108424}
{"step": 108424, "eval_return": -282.5732415157836, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 109134, "dataset_size": 54567.0, "train_return": -176.93417240493, "train_length": 500.0, "train_episodes": 119.0}
{"step": 109448}
{"step": 109448, "eval_return": -240.56415237896144, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 110134, "dataset_size": 55067.0, "train_return": -193.32549401000142, "train_length": 500.0, "train_episodes": 120.0}
{"step": 110472}
{"step": 110472, "eval_return": -195.4334290297702, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 111134, "dataset_size": 55567.0, "train_return": -237.6386093646288, "train_length": 500.0, "train_episodes": 121.0}
{"step": 111496}
{"step": 111496, "eval_return": -127.54260265212505, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 112134, "dataset_size": 56067.0, "train_return": -144.61244448274374, "train_length": 500.0, "train_episodes": 122.0}
{"step": 112520}
{"step": 112520, "eval_return": -214.95980546837671, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 113134, "dataset_size": 56567.0, "train_return": -246.53725856542587, "train_length": 500.0, "train_episodes": 123.0}
{"step": 113214, "dataset_size": 56607.0, "train_return": -30.980337023735046, "train_length": 40.0, "train_episodes": 124.0}
{"step": 113544}
{"step": 113544, "eval_return": -150.06973765864967, "eval_length": 415.8, "eval_episodes": 5.0}
{"step": 114214, "dataset_size": 57107.0, "train_return": -478.99104166030884, "train_length": 500.0, "train_episodes": 125.0}
{"step": 114568}
{"step": 114568, "eval_return": -173.90453399047254, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 115000, "model_loss": 2.5617735385894775, "model_grad_norm": Infinity, "player_loss": 0.2362765371799469, "reward_loss": 0.6203634738922119, "cont_loss": 9.416240573045798e-06, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.841874122619629, "rep_loss": 2.841874122619629, "kl": 2.7693254947662354, "prior_ent": 39.20359420776367, "post_ent": 36.37131118774414, "normed_target_mean": 0.3985675275325775, "normed_target_std": 0.3081355094909668, "normed_target_min": -0.14566609263420105, "normed_target_max": 1.0752695798873901, "EMA_005": -48.285858154296875, "EMA_095": -6.84883975982666, "value_mean": -31.36574363708496, "value_std": 12.447854995727539, "value_min": -51.61731719970703, "value_max": -3.8167471885681152, "target_mean": -31.733592987060547, "target_std": 12.774678230285645, "target_min": -54.30048751831055, "target_max": -3.7242085933685303, "imag_reward_mean": -0.7704877257347107, "imag_reward_std": 0.41904979944229126, "imag_reward_min": -1.811248779296875, "imag_reward_max": 0.06694328784942627, "imag_action_mean": 0.027557373046875, "imag_action_std": 0.849609375, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 0.3717261254787445, "actor_loss": 0.008767164312303066, "actor_grad_norm": 0.04014648497104645, "value_loss": 1.5008351802825928, "value_grad_norm": Infinity, "update_count": 13850.0, "fps": 12.956303364217833}
{"step": 115214, "dataset_size": 57607.0, "train_return": -499.70977123081684, "train_length": 500.0, "train_episodes": 126.0}
{"step": 115592}
{"step": 115592, "eval_return": -243.20008938619867, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 116214, "dataset_size": 58107.0, "train_return": -471.0460310727358, "train_length": 500.0, "train_episodes": 127.0}
{"step": 116616}
{"step": 116616, "eval_return": -177.21102317348124, "eval_length": 421.0, "eval_episodes": 5.0}
{"step": 117214, "dataset_size": 58607.0, "train_return": -159.92814487870783, "train_length": 500.0, "train_episodes": 128.0}
{"step": 117300, "dataset_size": 58650.0, "train_return": -23.76129698753357, "train_length": 43.0, "train_episodes": 129.0}
{"step": 117640}
{"step": 117640, "eval_return": 1832.1997383821756, "eval_length": 409.8, "eval_episodes": 5.0}
{"step": 118300, "dataset_size": 59150.0, "train_return": -179.84293973445892, "train_length": 500.0, "train_episodes": 130.0}
{"step": 118664}
{"step": 118664, "eval_return": -208.9970362432301, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 119300, "dataset_size": 59650.0, "train_return": -142.68786351848394, "train_length": 500.0, "train_episodes": 131.0}
{"step": 119688}
{"step": 119688, "eval_return": -277.1525795646012, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 120300, "dataset_size": 60150.0, "train_return": -63.67544150352478, "train_length": 500.0, "train_episodes": 132.0}
{"step": 120712}
{"step": 120712, "eval_return": -233.13619235903025, "eval_length": 409.0, "eval_episodes": 5.0}
{"step": 121072, "dataset_size": 60536.0, "train_return": -342.03157633543015, "train_length": 386.0, "train_episodes": 133.0}
{"step": 121736}
{"step": 121736, "eval_return": -163.12940191105008, "eval_length": 424.8, "eval_episodes": 5.0}
{"step": 122072, "dataset_size": 61036.0, "train_return": -158.08912057057023, "train_length": 500.0, "train_episodes": 134.0}
{"step": 122760}
{"step": 122760, "eval_return": -288.63528114333747, "eval_length": 420.4, "eval_episodes": 5.0}
{"step": 123072, "dataset_size": 61536.0, "train_return": -187.0756179355085, "train_length": 500.0, "train_episodes": 135.0}
{"step": 123136, "dataset_size": 61568.0, "train_return": -31.263129591941833, "train_length": 32.0, "train_episodes": 136.0}
{"step": 123322, "dataset_size": 61661.0, "train_return": -21.722922563552856, "train_length": 93.0, "train_episodes": 137.0}
{"step": 123432, "dataset_size": 61716.0, "train_return": -16.418456077575684, "train_length": 55.0, "train_episodes": 138.0}
{"step": 123784}
{"step": 123784, "eval_return": -353.55373127684, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 124432, "dataset_size": 62216.0, "train_return": -157.43077368172817, "train_length": 500.0, "train_episodes": 139.0}
{"step": 124808}
{"step": 124808, "eval_return": -176.70109546855093, "eval_length": 420.0, "eval_episodes": 5.0}
{"step": 125000, "model_loss": 2.5323452949523926, "model_grad_norm": Infinity, "player_loss": 0.23011718690395355, "reward_loss": 0.617709755897522, "cont_loss": 3.512645707814954e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.807471990585327, "rep_loss": 2.807471990585327, "kl": 2.732055187225342, "prior_ent": 39.290924072265625, "post_ent": 36.50592041015625, "normed_target_mean": 0.42881685495376587, "normed_target_std": 0.2994461953639984, "normed_target_min": -0.12285483628511429, "normed_target_max": 1.0988726615905762, "EMA_005": -51.13790512084961, "EMA_095": -8.109944343566895, "value_mean": -32.42409896850586, "value_std": 12.61652946472168, "value_min": -54.265625, "value_max": -3.9423811435699463, "target_mean": -32.680999755859375, "target_std": 12.88435173034668, "target_min": -56.41622543334961, "target_max": -3.8705477714538574, "imag_reward_mean": -0.7490864396095276, "imag_reward_std": 0.42075908184051514, "imag_reward_min": -1.8076471090316772, "imag_reward_max": 0.09485995769500732, "imag_action_mean": 0.02392578125, "imag_action_std": 0.84228515625, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 0.7008047699928284, "actor_loss": 0.005727941170334816, "actor_grad_norm": 0.047369591891765594, "value_loss": 1.5221855640411377, "value_grad_norm": 1.7775108814239502, "update_count": 15100.0, "fps": 13.20232693253334}
{"step": 125432, "dataset_size": 62716.0, "train_return": -142.7266780277714, "train_length": 500.0, "train_episodes": 140.0}
{"step": 125832}
{"step": 125832, "eval_return": -288.84179627280685, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 126432, "dataset_size": 63216.0, "train_return": -213.93800234794617, "train_length": 500.0, "train_episodes": 141.0}
{"step": 126856}
{"step": 126856, "eval_return": -370.8900931559503, "eval_length": 482.4, "eval_episodes": 5.0}
{"step": 127432, "dataset_size": 63716.0, "train_return": -671.5803331434727, "train_length": 500.0, "train_episodes": 142.0}
{"step": 127782, "dataset_size": 63891.0, "train_return": -201.4345282316208, "train_length": 175.0, "train_episodes": 143.0}
{"step": 127880}
{"step": 127880, "eval_return": -148.0180716916919, "eval_length": 404.4, "eval_episodes": 5.0}
{"step": 128736, "dataset_size": 64368.0, "train_return": 9620.778290063143, "train_length": 477.0, "train_episodes": 144.0}
{"step": 128904}
{"step": 128904, "eval_return": -181.88117755055427, "eval_length": 348.8, "eval_episodes": 5.0}
{"step": 129430, "dataset_size": 64715.0, "train_return": -375.3360687494278, "train_length": 347.0, "train_episodes": 145.0}
{"step": 129928}
{"step": 129928, "eval_return": -249.4049350774847, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 130430, "dataset_size": 65215.0, "train_return": -189.43144318647683, "train_length": 500.0, "train_episodes": 146.0}
{"step": 130574, "dataset_size": 65287.0, "train_return": -53.83056044578552, "train_length": 72.0, "train_episodes": 147.0}
{"step": 130952}
{"step": 130952, "eval_return": -199.33747445456683, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 131574, "dataset_size": 65787.0, "train_return": -497.0317615419626, "train_length": 500.0, "train_episodes": 148.0}
{"step": 131976}
{"step": 131976, "eval_return": -224.77048260718584, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 132574, "dataset_size": 66287.0, "train_return": -560.5989434719086, "train_length": 500.0, "train_episodes": 149.0}
{"step": 133000}
{"step": 133000, "eval_return": -377.2461121689063, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 133574, "dataset_size": 66787.0, "train_return": -502.1003263294697, "train_length": 500.0, "train_episodes": 150.0}
{"step": 134024}
{"step": 134024, "eval_return": -204.82860687300564, "eval_length": 378.4, "eval_episodes": 5.0}
{"step": 134574, "dataset_size": 67287.0, "train_return": -416.1903751939535, "train_length": 500.0, "train_episodes": 151.0}
{"step": 135000, "model_loss": 2.510685920715332, "model_grad_norm": 6.192986488342285, "player_loss": 0.22617395222187042, "reward_loss": 0.6115357279777527, "cont_loss": 6.227727135410532e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.7881903648376465, "rep_loss": 2.7881903648376465, "kl": 2.709864377975464, "prior_ent": 39.444129943847656, "post_ent": 36.684112548828125, "normed_target_mean": 0.41979873180389404, "normed_target_std": 0.29291948676109314, "normed_target_min": -0.1619839072227478, "normed_target_max": 1.116796612739563, "EMA_005": -51.8901252746582, "EMA_095": -9.174487113952637, "value_mean": -33.664554595947266, "value_std": 12.218046188354492, "value_min": -56.143611907958984, "value_max": -4.242022514343262, "target_mean": -33.95683670043945, "target_std": 12.513077735900879, "target_min": -58.81287384033203, "target_max": -4.180787563323975, "imag_reward_mean": -0.7444027066230774, "imag_reward_std": 0.4286641478538513, "imag_reward_min": -1.8183777332305908, "imag_reward_max": 0.07454599440097809, "imag_action_mean": 0.05340576171875, "imag_action_std": 0.830078125, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.6010488271713257, "actor_loss": 0.006312922108918428, "actor_grad_norm": NaN, "value_loss": 1.419313669204712, "value_grad_norm": 1.5357933044433594, "update_count": 16350.0, "fps": 13.554491523509856}
{"step": 135048}
{"step": 135048, "eval_return": -304.28389941193166, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 135574, "dataset_size": 67787.0, "train_return": -15.927085995674133, "train_length": 500.0, "train_episodes": 152.0}
{"step": 136072}
{"step": 136072, "eval_return": -180.27009382937104, "eval_length": 417.0, "eval_episodes": 5.0}
{"step": 136574, "dataset_size": 68287.0, "train_return": -27.1783527135849, "train_length": 500.0, "train_episodes": 153.0}
{"step": 137096}
{"step": 137096, "eval_return": 1788.3837340660393, "eval_length": 381.0, "eval_episodes": 5.0}
{"step": 137118, "dataset_size": 68559.0, "train_return": -30.71997106075287, "train_length": 272.0, "train_episodes": 154.0}
{"step": 137552, "dataset_size": 68776.0, "train_return": -166.90422841906548, "train_length": 217.0, "train_episodes": 155.0}
{"step": 138120}
{"step": 138120, "eval_return": -239.85715658143164, "eval_length": 448.0, "eval_episodes": 5.0}
{"step": 138496, "dataset_size": 69248.0, "train_return": -427.8843341767788, "train_length": 472.0, "train_episodes": 156.0}
{"step": 138584, "dataset_size": 69292.0, "train_return": -24.400036811828613, "train_length": 44.0, "train_episodes": 157.0}
{"step": 139144}
{"step": 139144, "eval_return": -248.26567221879958, "eval_length": 491.4, "eval_episodes": 5.0}
{"step": 139584, "dataset_size": 69792.0, "train_return": -132.0021613780409, "train_length": 500.0, "train_episodes": 158.0}
{"step": 140168}
{"step": 140168, "eval_return": 1774.864457545243, "eval_length": 310.8, "eval_episodes": 5.0}
{"step": 140398, "dataset_size": 70199.0, "train_return": -207.95047435164452, "train_length": 407.0, "train_episodes": 159.0}
{"step": 141192}
{"step": 141192, "eval_return": -231.78903875946997, "eval_length": 381.8, "eval_episodes": 5.0}
{"step": 141398, "dataset_size": 70699.0, "train_return": -502.36778604611754, "train_length": 500.0, "train_episodes": 160.0}
{"step": 142216}
{"step": 142216, "eval_return": -253.74616341516375, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 142398, "dataset_size": 71199.0, "train_return": -560.1128368079662, "train_length": 500.0, "train_episodes": 161.0}
{"step": 143240}
{"step": 143240, "eval_return": -347.34678043434394, "eval_length": 412.0, "eval_episodes": 5.0}
{"step": 143398, "dataset_size": 71699.0, "train_return": -561.6110079735518, "train_length": 500.0, "train_episodes": 162.0}
{"step": 144264}
{"step": 144264, "eval_return": -205.30040974877775, "eval_length": 398.0, "eval_episodes": 5.0}
{"step": 144398, "dataset_size": 72199.0, "train_return": -306.7559271987993, "train_length": 500.0, "train_episodes": 163.0}
{"step": 144772, "dataset_size": 72386.0, "train_return": -202.42665112018585, "train_length": 187.0, "train_episodes": 164.0}
{"step": 145000, "model_loss": 2.5509722232818604, "model_grad_norm": Infinity, "player_loss": 0.23693139851093292, "reward_loss": 0.6144028902053833, "cont_loss": 4.7013199946377426e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.8326528072357178, "rep_loss": 2.8326528072357178, "kl": 2.7555863857269287, "prior_ent": 39.88327407836914, "post_ent": 37.08612060546875, "normed_target_mean": 0.41457879543304443, "normed_target_std": 0.29229721426963806, "normed_target_min": -0.16376237571239471, "normed_target_max": 1.127131462097168, "EMA_005": -53.221832275390625, "EMA_095": -9.14908218383789, "value_mean": -34.72831344604492, "value_std": 12.543837547302246, "value_min": -57.481788635253906, "value_max": -3.9560325145721436, "target_mean": -34.95066452026367, "target_std": 12.883323669433594, "target_min": -60.44013595581055, "target_max": -3.5497941970825195, "imag_reward_mean": -0.7286399602890015, "imag_reward_std": 0.4320193827152252, "imag_reward_min": -1.8083208799362183, "imag_reward_max": 0.36957982182502747, "imag_action_mean": 0.0450439453125, "imag_action_std": 0.828125, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.5437644720077515, "actor_loss": 0.004543147049844265, "actor_grad_norm": Infinity, "value_loss": 1.4246768951416016, "value_grad_norm": Infinity, "update_count": 17600.0, "fps": 13.440762623407661}
{"step": 145288}
{"step": 145288, "eval_return": -385.6254959627986, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 145772, "dataset_size": 72886.0, "train_return": -483.8416278362274, "train_length": 500.0, "train_episodes": 165.0}
{"step": 146312}
{"step": 146312, "eval_return": -326.3959238458425, "eval_length": 410.4, "eval_episodes": 5.0}
{"step": 146772, "dataset_size": 73386.0, "train_return": -425.44674924062565, "train_length": 500.0, "train_episodes": 166.0}
{"step": 147336}
{"step": 147336, "eval_return": -286.87515788003805, "eval_length": 443.0, "eval_episodes": 5.0}
{"step": 147772, "dataset_size": 73886.0, "train_return": -533.333861708641, "train_length": 500.0, "train_episodes": 167.0}
{"step": 148360}
{"step": 148360, "eval_return": 1909.6796502009033, "eval_length": 192.0, "eval_episodes": 5.0}
{"step": 148772, "dataset_size": 74386.0, "train_return": -474.3435317873955, "train_length": 500.0, "train_episodes": 168.0}
{"step": 149384}
{"step": 149384, "eval_return": -297.66567475683985, "eval_length": 443.8, "eval_episodes": 5.0}
{"step": 149772, "dataset_size": 74886.0, "train_return": -388.4244341403246, "train_length": 500.0, "train_episodes": 169.0}
{"step": 149884, "dataset_size": 74942.0, "train_return": -24.44206702709198, "train_length": 56.0, "train_episodes": 170.0}
{"step": 150408}
{"step": 150408, "eval_return": -237.3899010106921, "eval_length": 423.8, "eval_episodes": 5.0}
{"step": 150884, "dataset_size": 75442.0, "train_return": -500.1635263264179, "train_length": 500.0, "train_episodes": 171.0}
{"step": 151432}
{"step": 151432, "eval_return": -392.98230783436446, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 151884, "dataset_size": 75942.0, "train_return": -508.0118167549372, "train_length": 500.0, "train_episodes": 172.0}
{"step": 152104, "dataset_size": 76052.0, "train_return": -27.59401822090149, "train_length": 110.0, "train_episodes": 173.0}
{"step": 152206, "dataset_size": 76103.0, "train_return": -37.10284698009491, "train_length": 51.0, "train_episodes": 174.0}
{"step": 152456}
{"step": 152456, "eval_return": 1814.0570455975364, "eval_length": 379.2, "eval_episodes": 5.0}
{"step": 153206, "dataset_size": 76603.0, "train_return": -242.33817714452744, "train_length": 500.0, "train_episodes": 175.0}
{"step": 153480}
{"step": 153480, "eval_return": -269.20704479389826, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 154206, "dataset_size": 77103.0, "train_return": -256.19657776877284, "train_length": 500.0, "train_episodes": 176.0}
{"step": 154504}
{"step": 154504, "eval_return": -162.42555713113398, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 155000, "model_loss": 2.5494253635406494, "model_grad_norm": Infinity, "player_loss": 0.23668356239795685, "reward_loss": 0.6077568531036377, "cont_loss": 3.366023884154856e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.8415849208831787, "rep_loss": 2.8415849208831787, "kl": 2.764812469482422, "prior_ent": 40.19596862792969, "post_ent": 37.394168853759766, "normed_target_mean": 0.4285508692264557, "normed_target_std": 0.28940919041633606, "normed_target_min": -0.15668193995952606, "normed_target_max": 1.115281581878662, "EMA_005": -56.891300201416016, "EMA_095": -8.921181678771973, "value_mean": -36.01216125488281, "value_std": 13.481474876403809, "value_min": -60.901187896728516, "value_max": -3.549543857574463, "target_mean": -36.32334899902344, "target_std": 13.883715629577637, "target_min": -64.40491485595703, "target_max": -3.3888354301452637, "imag_reward_mean": -0.7379488348960876, "imag_reward_std": 0.4374642074108124, "imag_reward_min": -1.8112832307815552, "imag_reward_max": 0.15483646094799042, "imag_action_mean": -0.009185791015625, "imag_action_std": 0.8330078125, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.495692253112793, "actor_loss": 0.00597893912345171, "actor_grad_norm": 0.048799898475408554, "value_loss": 1.4098186492919922, "value_grad_norm": Infinity, "update_count": 18850.0, "fps": 13.393854961598496}
{"step": 155206, "dataset_size": 77603.0, "train_return": -376.99278198182583, "train_length": 500.0, "train_episodes": 177.0}
{"step": 155528}
{"step": 155528, "eval_return": -269.7713755816221, "eval_length": 450.0, "eval_episodes": 5.0}
{"step": 156206, "dataset_size": 78103.0, "train_return": -160.3896667957306, "train_length": 500.0, "train_episodes": 178.0}
{"step": 156552}
{"step": 156552, "eval_return": -261.1067005231977, "eval_length": 314.4, "eval_episodes": 5.0}
{"step": 157206, "dataset_size": 78603.0, "train_return": -169.94185348786414, "train_length": 500.0, "train_episodes": 179.0}
{"step": 157576}
{"step": 157576, "eval_return": -78.69840090870858, "eval_length": 325.4, "eval_episodes": 5.0}
{"step": 158206, "dataset_size": 79103.0, "train_return": -355.8531726002693, "train_length": 500.0, "train_episodes": 180.0}
{"step": 158600}
{"step": 158600, "eval_return": -249.63104180246592, "eval_length": 410.6, "eval_episodes": 5.0}
{"step": 159206, "dataset_size": 79603.0, "train_return": -363.28491355478764, "train_length": 500.0, "train_episodes": 181.0}
{"step": 159428, "dataset_size": 79714.0, "train_return": -90.43691027164459, "train_length": 111.0, "train_episodes": 182.0}
{"step": 159526, "dataset_size": 79763.0, "train_return": -35.425517439842224, "train_length": 49.0, "train_episodes": 183.0}
{"step": 159624}
{"step": 159624, "eval_return": -108.90354303289205, "eval_length": 325.0, "eval_episodes": 5.0}
{"step": 160526, "dataset_size": 80263.0, "train_return": -342.80298455804586, "train_length": 500.0, "train_episodes": 184.0}
{"step": 160648}
{"step": 160648, "eval_return": -141.1007516056299, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 161168, "dataset_size": 80584.0, "train_return": -315.16928470134735, "train_length": 321.0, "train_episodes": 185.0}
{"step": 161672}
{"step": 161672, "eval_return": -145.64011749224738, "eval_length": 410.0, "eval_episodes": 5.0}
{"step": 162168, "dataset_size": 81084.0, "train_return": -192.00064777955413, "train_length": 500.0, "train_episodes": 186.0}
{"step": 162450, "dataset_size": 81225.0, "train_return": -124.894765406847, "train_length": 141.0, "train_episodes": 187.0}
{"step": 162696}
{"step": 162696, "eval_return": 1865.7888168632053, "eval_length": 419.2, "eval_episodes": 5.0}
{"step": 163450, "dataset_size": 81725.0, "train_return": -339.33604366891086, "train_length": 500.0, "train_episodes": 188.0}
{"step": 163720}
{"step": 163720, "eval_return": -279.4803305976093, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 164450, "dataset_size": 82225.0, "train_return": -295.14973783120513, "train_length": 500.0, "train_episodes": 189.0}
{"step": 164744}
{"step": 164744, "eval_return": -203.41781604290009, "eval_length": 238.2, "eval_episodes": 5.0}
{"step": 165000, "model_loss": 2.5304644107818604, "model_grad_norm": 6.237549304962158, "player_loss": 0.2315627485513687, "reward_loss": 0.6072008013725281, "cont_loss": 2.2528465706272982e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.819465160369873, "rep_loss": 2.819465160369873, "kl": 2.74129581451416, "prior_ent": 40.29298782348633, "post_ent": 37.5148811340332, "normed_target_mean": 0.42250683903694153, "normed_target_std": 0.2826758921146393, "normed_target_min": -0.15223881602287292, "normed_target_max": 1.1272282600402832, "EMA_005": -59.075714111328125, "EMA_095": -9.717780113220215, "value_mean": -37.94325256347656, "value_std": 13.563889503479004, "value_min": -63.427555084228516, "value_max": -3.7441015243530273, "target_mean": -38.20758056640625, "target_std": 13.952593803405762, "target_min": -66.59198760986328, "target_max": -3.451122760772705, "imag_reward_mean": -0.7353861331939697, "imag_reward_std": 0.4430411159992218, "imag_reward_min": -1.8297302722930908, "imag_reward_max": 0.3085753321647644, "imag_action_mean": 0.0081329345703125, "imag_action_std": 0.8408203125, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 0.918222188949585, "actor_loss": 0.0050523788668215275, "actor_grad_norm": Infinity, "value_loss": 1.4143648147583008, "value_grad_norm": 1.6527644395828247, "update_count": 20100.0, "fps": 13.788389182551105}
{"step": 165450, "dataset_size": 82725.0, "train_return": -116.98486392106861, "train_length": 500.0, "train_episodes": 190.0}
{"step": 165768}
{"step": 165768, "eval_return": -319.1832843773067, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 166450, "dataset_size": 83225.0, "train_return": -370.80748738348484, "train_length": 500.0, "train_episodes": 191.0}
{"step": 166792}
{"step": 166792, "eval_return": -349.7394202530384, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 167450, "dataset_size": 83725.0, "train_return": -506.8468330204487, "train_length": 500.0, "train_episodes": 192.0}
{"step": 167816}
{"step": 167816, "eval_return": -96.0679663900286, "eval_length": 244.0, "eval_episodes": 5.0}
{"step": 168450, "dataset_size": 84225.0, "train_return": -518.2597182095051, "train_length": 500.0, "train_episodes": 193.0}
{"step": 168840}
{"step": 168840, "eval_return": -229.20448147500866, "eval_length": 460.0, "eval_episodes": 5.0}
{"step": 169224, "dataset_size": 84612.0, "train_return": -476.7123931348324, "train_length": 387.0, "train_episodes": 194.0}
{"step": 169864}
{"step": 169864, "eval_return": -305.7404378163628, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 170224, "dataset_size": 85112.0, "train_return": -332.2171103358269, "train_length": 500.0, "train_episodes": 195.0}
{"step": 170888}
{"step": 170888, "eval_return": -84.32789182662964, "eval_length": 155.0, "eval_episodes": 5.0}
{"step": 171224, "dataset_size": 85612.0, "train_return": -232.96698305010796, "train_length": 500.0, "train_episodes": 196.0}
{"step": 171912}
{"step": 171912, "eval_return": -303.0658381909132, "eval_length": 389.4, "eval_episodes": 5.0}
{"step": 172224, "dataset_size": 86112.0, "train_return": -439.0905084311962, "train_length": 500.0, "train_episodes": 197.0}
{"step": 172936}
{"step": 172936, "eval_return": -237.08942854218185, "eval_length": 407.6, "eval_episodes": 5.0}
{"step": 173224, "dataset_size": 86612.0, "train_return": -347.43638881482184, "train_length": 500.0, "train_episodes": 198.0}
{"step": 173960}
{"step": 173960, "eval_return": 1612.8077106120065, "eval_length": 453.0, "eval_episodes": 5.0}
{"step": 174224, "dataset_size": 87112.0, "train_return": -146.86326113995165, "train_length": 500.0, "train_episodes": 199.0}
{"step": 174984}
{"step": 174984, "eval_return": -390.5500548377633, "eval_length": 477.4, "eval_episodes": 5.0}
{"step": 175000, "model_loss": 2.500753164291382, "model_grad_norm": 6.103527545928955, "player_loss": 0.22507230937480927, "reward_loss": 0.6013153791427612, "cont_loss": 1.8934351828647777e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.7905778884887695, "rep_loss": 2.7905778884887695, "kl": 2.709657907485962, "prior_ent": 40.41535568237305, "post_ent": 37.67640686035156, "normed_target_mean": 0.41278162598609924, "normed_target_std": 0.2832185924053192, "normed_target_min": -0.15511822700500488, "normed_target_max": 1.1575547456741333, "EMA_005": -59.758811950683594, "EMA_095": -10.624561309814453, "value_mean": -39.24372100830078, "value_std": 13.556897163391113, "value_min": -64.43965148925781, "value_max": -3.784332752227783, "target_mean": -39.47618103027344, "target_std": 13.918289184570312, "target_min": -67.38311004638672, "target_max": -2.89031720161438, "imag_reward_mean": -0.7342596650123596, "imag_reward_std": 0.4534514546394348, "imag_reward_min": -1.8340167999267578, "imag_reward_max": 1.1200926303863525, "imag_action_mean": 0.0093536376953125, "imag_action_std": 0.83544921875, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 0.9033603668212891, "actor_loss": 0.004434405360370874, "actor_grad_norm": 0.053814854472875595, "value_loss": 1.4032148122787476, "value_grad_norm": Infinity, "update_count": 21350.0, "fps": 4.8222062871774325}
{"step": 175224, "dataset_size": 87612.0, "train_return": -495.52776607871056, "train_length": 500.0, "train_episodes": 200.0}
{"step": 176008}
{"step": 176008, "eval_return": -372.9188237991184, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 176224, "dataset_size": 88112.0, "train_return": -586.0322119295597, "train_length": 500.0, "train_episodes": 201.0}
{"step": 176576, "dataset_size": 88288.0, "train_return": -92.4929088652134, "train_length": 176.0, "train_episodes": 202.0}
{"step": 177032}
{"step": 177032, "eval_return": -338.7299480178393, "eval_length": 438.2, "eval_episodes": 5.0}
{"step": 177576, "dataset_size": 88788.0, "train_return": -202.32631546258926, "train_length": 500.0, "train_episodes": 203.0}
{"step": 178056}
{"step": 178056, "eval_return": -323.78621050603687, "eval_length": 367.4, "eval_episodes": 5.0}
{"step": 178576, "dataset_size": 89288.0, "train_return": -452.5888721346855, "train_length": 500.0, "train_episodes": 204.0}
{"step": 179080}
{"step": 179080, "eval_return": 1705.6080693827942, "eval_length": 433.6, "eval_episodes": 5.0}
{"step": 179120, "dataset_size": 89560.0, "train_return": -363.9840341806412, "train_length": 272.0, "train_episodes": 205.0}
{"step": 180104}
{"step": 180104, "eval_return": -347.7793810479343, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 180120, "dataset_size": 90060.0, "train_return": -496.17421693354845, "train_length": 500.0, "train_episodes": 206.0}
{"step": 181120, "dataset_size": 90560.0, "train_return": -343.34144543111324, "train_length": 500.0, "train_episodes": 207.0}
{"step": 181128}
{"step": 181128, "eval_return": 1645.2040191531182, "eval_length": 476.4, "eval_episodes": 5.0}
{"step": 181336, "dataset_size": 90668.0, "train_return": 9941.369574368, "train_length": 108.0, "train_episodes": 208.0}
{"step": 182152}
{"step": 182152, "eval_return": -69.7601657256484, "eval_length": 265.2, "eval_episodes": 5.0}
{"step": 182248, "dataset_size": 91124.0, "train_return": -357.36264405958354, "train_length": 456.0, "train_episodes": 209.0}
{"step": 183176}
{"step": 183176, "eval_return": -181.67426004111766, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 183248, "dataset_size": 91624.0, "train_return": -186.96328209433705, "train_length": 500.0, "train_episodes": 210.0}
{"step": 184200}
{"step": 184200, "eval_return": 1801.948988233134, "eval_length": 465.8, "eval_episodes": 5.0}
{"step": 184248, "dataset_size": 92124.0, "train_return": -289.04583632946014, "train_length": 500.0, "train_episodes": 211.0}
{"step": 184416, "dataset_size": 92208.0, "train_return": -61.21583390235901, "train_length": 84.0, "train_episodes": 212.0}
{"step": 185000, "model_loss": 2.5096378326416016, "model_grad_norm": Infinity, "player_loss": 0.22442016005516052, "reward_loss": 0.6026880145072937, "cont_loss": 3.5501412639860064e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.804156541824341, "rep_loss": 2.804156541824341, "kl": 2.7236530780792236, "prior_ent": 40.53424835205078, "post_ent": 37.78922653198242, "normed_target_mean": 0.3868459463119507, "normed_target_std": 0.28781700134277344, "normed_target_min": -0.15847733616828918, "normed_target_max": 1.1706414222717285, "EMA_005": -59.580101013183594, "EMA_095": -10.55140495300293, "value_mean": -40.36025619506836, "value_std": 13.752309799194336, "value_min": -64.52837371826172, "value_max": -3.544544219970703, "target_mean": -40.6097412109375, "target_std": 14.114005088806152, "target_min": -67.34735870361328, "target_max": -2.1690750122070312, "imag_reward_mean": -0.7317310571670532, "imag_reward_std": 0.4584445357322693, "imag_reward_min": -1.8345812559127808, "imag_reward_max": 1.2834861278533936, "imag_action_mean": -0.004734039306640625, "imag_action_std": 0.82958984375, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 0.9991164803504944, "actor_loss": 0.004784639924764633, "actor_grad_norm": NaN, "value_loss": 1.3849691152572632, "value_grad_norm": 1.7307976484298706, "update_count": 22600.0, "fps": 4.673948817365798}
{"step": 185224}
{"step": 185224, "eval_return": -253.28089450914413, "eval_length": 432.8, "eval_episodes": 5.0}
{"step": 185416, "dataset_size": 92708.0, "train_return": -587.1209920197725, "train_length": 500.0, "train_episodes": 213.0}
{"step": 186248}
{"step": 186248, "eval_return": -248.9953069047071, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 186416, "dataset_size": 93208.0, "train_return": -477.310185700655, "train_length": 500.0, "train_episodes": 214.0}
{"step": 187272}
{"step": 187272, "eval_return": 1786.420849649608, "eval_length": 351.4, "eval_episodes": 5.0}
{"step": 187416, "dataset_size": 93708.0, "train_return": -472.8309958279133, "train_length": 500.0, "train_episodes": 215.0}
{"step": 188296}
{"step": 188296, "eval_return": -310.0915103210602, "eval_length": 424.8, "eval_episodes": 5.0}
{"step": 188416, "dataset_size": 94208.0, "train_return": -408.7791630551219, "train_length": 500.0, "train_episodes": 216.0}
{"step": 189320}
{"step": 189320, "eval_return": -365.3755922928452, "eval_length": 439.2, "eval_episodes": 5.0}
{"step": 189416, "dataset_size": 94708.0, "train_return": -620.4065331369638, "train_length": 500.0, "train_episodes": 217.0}
{"step": 190268, "dataset_size": 95134.0, "train_return": -410.0834064781666, "train_length": 426.0, "train_episodes": 218.0}
{"step": 190344}
{"step": 190344, "eval_return": -227.5004870824865, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 191268, "dataset_size": 95634.0, "train_return": -348.86703395843506, "train_length": 500.0, "train_episodes": 219.0}
{"step": 191368}
{"step": 191368, "eval_return": -373.1794780923054, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 192186, "dataset_size": 96093.0, "train_return": -460.1562867835164, "train_length": 459.0, "train_episodes": 220.0}
{"step": 192392}
{"step": 192392, "eval_return": -476.77451276630165, "eval_length": 433.4, "eval_episodes": 5.0}
{"step": 193186, "dataset_size": 96593.0, "train_return": -92.58609187602997, "train_length": 500.0, "train_episodes": 221.0}
{"step": 193416}
{"step": 193416, "eval_return": -357.9766490942799, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 193660, "dataset_size": 96830.0, "train_return": -195.4820494055748, "train_length": 237.0, "train_episodes": 222.0}
{"step": 194440}
{"step": 194440, "eval_return": 1440.135609062016, "eval_length": 468.4, "eval_episodes": 5.0}
{"step": 194660, "dataset_size": 97330.0, "train_return": -590.3198251277208, "train_length": 500.0, "train_episodes": 223.0}
{"step": 195000, "model_loss": 2.526301622390747, "model_grad_norm": 6.156257629394531, "player_loss": 0.2294897735118866, "reward_loss": 0.5999435186386108, "cont_loss": 3.419328550080536e-06, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.828108310699463, "rep_loss": 2.828108310699463, "kl": 2.748133420944214, "prior_ent": 40.6953125, "post_ent": 37.93048858642578, "normed_target_mean": 0.38709864020347595, "normed_target_std": 0.28855225443840027, "normed_target_min": -0.17506767809391022, "normed_target_max": 1.1557374000549316, "EMA_005": -61.13752365112305, "EMA_095": -10.052122116088867, "value_mean": -41.10745620727539, "value_std": 14.351253509521484, "value_min": -66.47090911865234, "value_max": -3.1935219764709473, "target_mean": -41.34892272949219, "target_std": 14.740577697753906, "target_min": -70.08010864257812, "target_max": -2.0789291858673096, "imag_reward_mean": -0.7429749369621277, "imag_reward_std": 0.47883695363998413, "imag_reward_min": -1.858290672302246, "imag_reward_max": 1.6617859601974487, "imag_action_mean": 0.0133514404296875, "imag_action_std": 0.82568359375, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 0.970923900604248, "actor_loss": 0.004428592976182699, "actor_grad_norm": 0.05836695432662964, "value_loss": 1.3852323293685913, "value_grad_norm": 1.7174501419067383, "update_count": 23850.0, "fps": 12.015548520343332}
{"step": 195464}
{"step": 195464, "eval_return": -399.90785402208564, "eval_length": 462.0, "eval_episodes": 5.0}
{"step": 195660, "dataset_size": 97830.0, "train_return": -500.94774040579796, "train_length": 500.0, "train_episodes": 224.0}
{"step": 196488}
{"step": 196488, "eval_return": 1588.199848908186, "eval_length": 436.2, "eval_episodes": 5.0}
{"step": 196660, "dataset_size": 98330.0, "train_return": -288.7390194479376, "train_length": 500.0, "train_episodes": 225.0}
{"step": 197512}
{"step": 197512, "eval_return": -288.7624734506011, "eval_length": 428.6, "eval_episodes": 5.0}
{"step": 197660, "dataset_size": 98830.0, "train_return": -464.5254203826189, "train_length": 500.0, "train_episodes": 226.0}
{"step": 198536}
{"step": 198536, "eval_return": -218.66209350526333, "eval_length": 348.8, "eval_episodes": 5.0}
{"step": 198660, "dataset_size": 99330.0, "train_return": -28.873557090759277, "train_length": 500.0, "train_episodes": 227.0}
{"step": 199560}
{"step": 199560, "eval_return": -234.21349262800067, "eval_length": 338.0, "eval_episodes": 5.0}
{"step": 199660, "dataset_size": 99830.0, "train_return": -261.3031205609441, "train_length": 500.0, "train_episodes": 228.0}
{"step": 200584}
{"step": 200584, "eval_return": -289.0295375317335, "eval_length": 406.8, "eval_episodes": 5.0}
{"step": 200660, "dataset_size": 100330.0, "train_return": -114.25240873219445, "train_length": 500.0, "train_episodes": 229.0}
{"step": 200814, "dataset_size": 100407.0, "train_return": -21.477391481399536, "train_length": 77.0, "train_episodes": 230.0}
{"step": 201608}
{"step": 201608, "eval_return": -370.5581548381131, "eval_length": 457.6, "eval_episodes": 5.0}
{"step": 201814, "dataset_size": 100907.0, "train_return": -460.4315317571163, "train_length": 500.0, "train_episodes": 231.0}
{"step": 202148, "dataset_size": 101074.0, "train_return": -182.082334369421, "train_length": 167.0, "train_episodes": 232.0}
{"step": 202478, "dataset_size": 101239.0, "train_return": 9985.408788084984, "train_length": 165.0, "train_episodes": 233.0}
{"step": 202632}
{"step": 202632, "eval_return": -142.05901549868287, "eval_length": 373.0, "eval_episodes": 5.0}
{"step": 203478, "dataset_size": 101739.0, "train_return": -672.1685550510883, "train_length": 500.0, "train_episodes": 234.0}
{"step": 203656}
{"step": 203656, "eval_return": 1673.7886767454445, "eval_length": 423.2, "eval_episodes": 5.0}
{"step": 204478, "dataset_size": 102239.0, "train_return": -285.9799248576164, "train_length": 500.0, "train_episodes": 235.0}
{"step": 204680}
{"step": 204680, "eval_return": -281.2212550640106, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 205000, "model_loss": 2.5138847827911377, "model_grad_norm": Infinity, "player_loss": 0.2274138480424881, "reward_loss": 0.5974579453468323, "cont_loss": 5.536054231924936e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.8149287700653076, "rep_loss": 2.8149287700653076, "kl": 2.734652042388916, "prior_ent": 40.96307373046875, "post_ent": 38.21623611450195, "normed_target_mean": 0.4000360071659088, "normed_target_std": 0.2842976450920105, "normed_target_min": -0.17371860146522522, "normed_target_max": 1.1699939966201782, "EMA_005": -63.4431266784668, "EMA_095": -9.539417266845703, "value_mean": -41.63131332397461, "value_std": 14.875082969665527, "value_min": -68.6067886352539, "value_max": -3.1683387756347656, "target_mean": -41.879764556884766, "target_std": 15.328496932983398, "target_min": -72.79644012451172, "target_max": -0.389862596988678, "imag_reward_mean": -0.7359386682510376, "imag_reward_std": 0.4968635141849518, "imag_reward_min": -1.8734883069992065, "imag_reward_max": 2.985339403152466, "imag_action_mean": 0.036102294921875, "imag_action_std": 0.82666015625, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.0958691835403442, "actor_loss": 0.004267184063792229, "actor_grad_norm": NaN, "value_loss": 1.3516640663146973, "value_grad_norm": Infinity, "update_count": 25100.0, "fps": 4.276090224469964}
{"step": 205478, "dataset_size": 102739.0, "train_return": -565.5262584090233, "train_length": 500.0, "train_episodes": 236.0}
{"step": 205704}
{"step": 205704, "eval_return": 1827.9894826922566, "eval_length": 294.0, "eval_episodes": 5.0}
{"step": 206478, "dataset_size": 103239.0, "train_return": -298.5315805673599, "train_length": 500.0, "train_episodes": 237.0}
{"step": 206728}
{"step": 206728, "eval_return": 1810.974432309717, "eval_length": 343.4, "eval_episodes": 5.0}
{"step": 207478, "dataset_size": 103739.0, "train_return": -419.0592295974493, "train_length": 500.0, "train_episodes": 238.0}
{"step": 207752}
{"step": 207752, "eval_return": -344.900209954381, "eval_length": 453.8, "eval_episodes": 5.0}
{"step": 208478, "dataset_size": 104239.0, "train_return": -413.52160596847534, "train_length": 500.0, "train_episodes": 239.0}
{"step": 208776}
{"step": 208776, "eval_return": -182.38981858347543, "eval_length": 393.6, "eval_episodes": 5.0}
{"step": 209478, "dataset_size": 104739.0, "train_return": -382.61188489198685, "train_length": 500.0, "train_episodes": 240.0}
{"step": 209610, "dataset_size": 104805.0, "train_return": -7.827896952629089, "train_length": 66.0, "train_episodes": 241.0}
{"step": 209800}
{"step": 209800, "eval_return": -282.3073086202145, "eval_length": 331.6, "eval_episodes": 5.0}
{"step": 210610, "dataset_size": 105305.0, "train_return": -117.58631764352322, "train_length": 500.0, "train_episodes": 242.0}
{"step": 210824}
{"step": 210824, "eval_return": -267.22359647005794, "eval_length": 418.8, "eval_episodes": 5.0}
{"step": 211610, "dataset_size": 105805.0, "train_return": -705.0325031280518, "train_length": 500.0, "train_episodes": 243.0}
{"step": 211848}
{"step": 211848, "eval_return": -293.46814147159455, "eval_length": 413.6, "eval_episodes": 5.0}
{"step": 212610, "dataset_size": 106305.0, "train_return": -153.5027077891864, "train_length": 500.0, "train_episodes": 244.0}
{"step": 212872}
{"step": 212872, "eval_return": 1754.809190063132, "eval_length": 372.4, "eval_episodes": 5.0}
{"step": 213610, "dataset_size": 106805.0, "train_return": -618.3592146337032, "train_length": 500.0, "train_episodes": 245.0}
{"step": 213736, "dataset_size": 106868.0, "train_return": -16.684234023094177, "train_length": 63.0, "train_episodes": 246.0}
{"step": 213896}
{"step": 213896, "eval_return": -430.95245572067796, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 214736, "dataset_size": 107368.0, "train_return": -116.12646839395165, "train_length": 500.0, "train_episodes": 247.0}
{"step": 214920}
{"step": 214920, "eval_return": -478.01262384951116, "eval_length": 441.4, "eval_episodes": 5.0}
{"step": 215000, "model_loss": 2.5067086219787598, "model_grad_norm": Infinity, "player_loss": 0.22670391201972961, "reward_loss": 0.5893229246139526, "cont_loss": 4.271165016689338e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.8177316188812256, "rep_loss": 2.8177316188812256, "kl": 2.7370784282684326, "prior_ent": 41.16646194458008, "post_ent": 38.417205810546875, "normed_target_mean": 0.41710957884788513, "normed_target_std": 0.28509950637817383, "normed_target_min": -0.15155768394470215, "normed_target_max": 1.2025197744369507, "EMA_005": -68.10790252685547, "EMA_095": -9.478829383850098, "value_mean": -43.40184020996094, "value_std": 16.192703247070312, "value_min": -72.77792358398438, "value_max": -2.9662375450134277, "target_mean": -43.64714431762695, "target_std": 16.71649932861328, "target_min": -76.99488067626953, "target_max": 2.3937582969665527, "imag_reward_mean": -0.7408947944641113, "imag_reward_std": 0.5585910081863403, "imag_reward_min": -1.8775423765182495, "imag_reward_max": 6.358560085296631, "imag_action_mean": 0.02349853515625, "imag_action_std": 0.8291015625, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.2489988803863525, "actor_loss": 0.0038157340604811907, "actor_grad_norm": NaN, "value_loss": 1.3584558963775635, "value_grad_norm": 1.6790412664413452, "update_count": 26350.0, "fps": 3.855793366695871}
{"step": 215736, "dataset_size": 107868.0, "train_return": -190.06637365650386, "train_length": 500.0, "train_episodes": 248.0}
{"step": 215944}
{"step": 215944, "eval_return": 1624.9260037533938, "eval_length": 449.8, "eval_episodes": 5.0}
{"step": 216736, "dataset_size": 108368.0, "train_return": -560.1125531047583, "train_length": 500.0, "train_episodes": 249.0}
{"step": 216968}
{"step": 216968, "eval_return": -142.13400969803334, "eval_length": 286.8, "eval_episodes": 5.0}
{"step": 217736, "dataset_size": 108868.0, "train_return": -463.4585142955184, "train_length": 500.0, "train_episodes": 250.0}
{"step": 217992}
{"step": 217992, "eval_return": -501.8328135482967, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 218736, "dataset_size": 109368.0, "train_return": -622.0714977681637, "train_length": 500.0, "train_episodes": 251.0}
{"step": 219016}
{"step": 219016, "eval_return": -441.3073008123785, "eval_length": 423.6, "eval_episodes": 5.0}
{"step": 219736, "dataset_size": 109868.0, "train_return": -581.7274682074785, "train_length": 500.0, "train_episodes": 252.0}
{"step": 220040}
{"step": 220040, "eval_return": -330.91011122241616, "eval_length": 444.0, "eval_episodes": 5.0}
{"step": 220736, "dataset_size": 110368.0, "train_return": -575.1919142901897, "train_length": 500.0, "train_episodes": 253.0}
{"step": 221064}
{"step": 221064, "eval_return": 1863.165682722372, "eval_length": 351.6, "eval_episodes": 5.0}
{"step": 221736, "dataset_size": 110868.0, "train_return": -594.9560246765614, "train_length": 500.0, "train_episodes": 254.0}
{"step": 222088}
{"step": 222088, "eval_return": -401.5482429783791, "eval_length": 433.2, "eval_episodes": 5.0}
{"step": 222736, "dataset_size": 111368.0, "train_return": -524.1055083572865, "train_length": 500.0, "train_episodes": 255.0}
{"step": 223112}
{"step": 223112, "eval_return": -193.17216639965773, "eval_length": 364.0, "eval_episodes": 5.0}
{"step": 223736, "dataset_size": 111868.0, "train_return": -457.71655666828156, "train_length": 500.0, "train_episodes": 256.0}
{"step": 224136}
{"step": 224136, "eval_return": 1851.9948984722141, "eval_length": 460.6, "eval_episodes": 5.0}
{"step": 224736, "dataset_size": 112368.0, "train_return": -511.58670714497566, "train_length": 500.0, "train_episodes": 257.0}
{"step": 225000, "model_loss": 2.487875461578369, "model_grad_norm": 6.041200160980225, "player_loss": 0.2207767516374588, "reward_loss": 0.5908374190330505, "cont_loss": 2.428824154776521e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.793728828430176, "rep_loss": 2.793728828430176, "kl": 2.7123687267303467, "prior_ent": 41.408287048339844, "post_ent": 38.68766403198242, "normed_target_mean": 0.4245131313800812, "normed_target_std": 0.2789747714996338, "normed_target_min": -0.181597039103508, "normed_target_max": 1.143872618675232, "EMA_005": -70.08644104003906, "EMA_095": -9.635095596313477, "value_mean": -44.145755767822266, "value_std": 16.399293899536133, "value_min": -76.98529052734375, "value_max": -2.8931894302368164, "target_mean": -44.41966247558594, "target_std": 16.86443519592285, "target_min": -81.0549087524414, "target_max": -0.9571607708930969, "imag_reward_mean": -0.7471111416816711, "imag_reward_std": 0.5181229710578918, "imag_reward_min": -1.88217031955719, "imag_reward_max": 3.491276502609253, "imag_action_mean": 0.0195465087890625, "imag_action_std": 0.83203125, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.1636239290237427, "actor_loss": 0.0041688536293804646, "actor_grad_norm": NaN, "value_loss": 1.3450976610183716, "value_grad_norm": Infinity, "update_count": 27600.0, "fps": 3.866701881550534}
{"step": 225160}
{"step": 225160, "eval_return": -163.39203472081573, "eval_length": 332.2, "eval_episodes": 5.0}
{"step": 225736, "dataset_size": 112868.0, "train_return": -433.9207608550787, "train_length": 500.0, "train_episodes": 258.0}
{"step": 226184}
{"step": 226184, "eval_return": -401.8595638871193, "eval_length": 413.8, "eval_episodes": 5.0}
{"step": 226736, "dataset_size": 113368.0, "train_return": -402.483121778816, "train_length": 500.0, "train_episodes": 259.0}
{"step": 227208}
{"step": 227208, "eval_return": -261.97316130101683, "eval_length": 413.4, "eval_episodes": 5.0}
{"step": 227736, "dataset_size": 113868.0, "train_return": -58.83886903524399, "train_length": 500.0, "train_episodes": 260.0}
{"step": 227946, "dataset_size": 113973.0, "train_return": -67.83367812633514, "train_length": 105.0, "train_episodes": 261.0}
{"step": 228232}
{"step": 228232, "eval_return": -145.38012194894253, "eval_length": 309.6, "eval_episodes": 5.0}
{"step": 228946, "dataset_size": 114473.0, "train_return": -433.66433742269874, "train_length": 500.0, "train_episodes": 262.0}
{"step": 229256}
{"step": 229256, "eval_return": -245.31547843869777, "eval_length": 462.6, "eval_episodes": 5.0}
{"step": 229600, "dataset_size": 114800.0, "train_return": 9815.184477806091, "train_length": 327.0, "train_episodes": 263.0}
{"step": 230280}
{"step": 230280, "eval_return": -330.0548182010651, "eval_length": 418.8, "eval_episodes": 5.0}
{"step": 230600, "dataset_size": 115300.0, "train_return": -541.0786836743355, "train_length": 500.0, "train_episodes": 264.0}
{"step": 230700, "dataset_size": 115350.0, "train_return": 9985.620871424675, "train_length": 50.0, "train_episodes": 265.0}
{"step": 231304}
{"step": 231304, "eval_return": -280.58309583477677, "eval_length": 294.0, "eval_episodes": 5.0}
{"step": 231700, "dataset_size": 115850.0, "train_return": -464.59325981140137, "train_length": 500.0, "train_episodes": 266.0}
{"step": 232328}
{"step": 232328, "eval_return": -236.21334951177704, "eval_length": 415.4, "eval_episodes": 5.0}
{"step": 232700, "dataset_size": 116350.0, "train_return": -139.76741993241012, "train_length": 500.0, "train_episodes": 267.0}
{"step": 233352}
{"step": 233352, "eval_return": -416.78710085451604, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 233700, "dataset_size": 116850.0, "train_return": -488.2928567826748, "train_length": 500.0, "train_episodes": 268.0}
{"step": 234376}
{"step": 234376, "eval_return": -202.51943368911742, "eval_length": 354.4, "eval_episodes": 5.0}
{"step": 234700, "dataset_size": 117350.0, "train_return": -168.21658772230148, "train_length": 500.0, "train_episodes": 269.0}
{"step": 235000, "model_loss": 2.4910991191864014, "model_grad_norm": 5.978072643280029, "player_loss": 0.22113920748233795, "reward_loss": 0.5887125730514526, "cont_loss": 0.00010634914360707626, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.8019020557403564, "rep_loss": 2.8019020557403564, "kl": 2.719200849533081, "prior_ent": 41.63700485229492, "post_ent": 38.91083908081055, "normed_target_mean": 0.39744678139686584, "normed_target_std": 0.2878016233444214, "normed_target_min": -0.19383156299591064, "normed_target_max": 1.1954078674316406, "EMA_005": -68.94098663330078, "EMA_095": -9.538556098937988, "value_mean": -45.0721549987793, "value_std": 16.658676147460938, "value_min": -76.57967376708984, "value_max": -2.7256672382354736, "target_mean": -45.33417510986328, "target_std": 17.09758949279785, "target_min": -80.45293426513672, "target_max": 2.0497350692749023, "imag_reward_mean": -0.7420831322669983, "imag_reward_std": 0.5572850108146667, "imag_reward_min": -1.8789640665054321, "imag_reward_max": 6.131646156311035, "imag_action_mean": -0.008941650390625, "imag_action_std": 0.8349609375, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 0.8969150185585022, "actor_loss": 0.004132560919970274, "actor_grad_norm": 0.05497293174266815, "value_loss": 1.3431999683380127, "value_grad_norm": Infinity, "update_count": 28850.0, "fps": 5.145147470383936}
{"step": 235400}
{"step": 235400, "eval_return": -267.48240088522437, "eval_length": 298.6, "eval_episodes": 5.0}
{"step": 235700, "dataset_size": 117850.0, "train_return": -543.4937500059605, "train_length": 500.0, "train_episodes": 270.0}
{"step": 236424}
{"step": 236424, "eval_return": 1742.0708148757462, "eval_length": 382.2, "eval_episodes": 5.0}
{"step": 236700, "dataset_size": 118350.0, "train_return": -291.15548503398895, "train_length": 500.0, "train_episodes": 271.0}
{"step": 237448}
{"step": 237448, "eval_return": -374.5610575980507, "eval_length": 417.4, "eval_episodes": 5.0}
{"step": 237700, "dataset_size": 118850.0, "train_return": -567.1004410386086, "train_length": 500.0, "train_episodes": 272.0}
{"step": 238066, "dataset_size": 119033.0, "train_return": -144.47011768817902, "train_length": 183.0, "train_episodes": 273.0}
{"step": 238472}
{"step": 238472, "eval_return": 1694.3720643401145, "eval_length": 350.4, "eval_episodes": 5.0}
{"step": 239066, "dataset_size": 119533.0, "train_return": -13.076117157936096, "train_length": 500.0, "train_episodes": 274.0}
{"step": 239496}
{"step": 239496, "eval_return": -329.04284461811187, "eval_length": 397.2, "eval_episodes": 5.0}
{"step": 240066, "dataset_size": 120033.0, "train_return": -392.8370458185673, "train_length": 500.0, "train_episodes": 275.0}
{"step": 240520}
{"step": 240520, "eval_return": -373.76232359781864, "eval_length": 439.0, "eval_episodes": 5.0}
{"step": 241066, "dataset_size": 120533.0, "train_return": -472.5572601556778, "train_length": 500.0, "train_episodes": 276.0}
{"step": 241544}
{"step": 241544, "eval_return": -316.7891949415207, "eval_length": 414.2, "eval_episodes": 5.0}
{"step": 242066, "dataset_size": 121033.0, "train_return": -26.406894087791443, "train_length": 500.0, "train_episodes": 277.0}
{"step": 242568}
{"step": 242568, "eval_return": -349.227304649353, "eval_length": 409.0, "eval_episodes": 5.0}
{"step": 243066, "dataset_size": 121533.0, "train_return": -449.0174029767513, "train_length": 500.0, "train_episodes": 278.0}
{"step": 243502, "dataset_size": 121751.0, "train_return": -219.54119592905045, "train_length": 218.0, "train_episodes": 279.0}
{"step": 243592}
{"step": 243592, "eval_return": 1854.5047231285366, "eval_length": 345.8, "eval_episodes": 5.0}
{"step": 244502, "dataset_size": 122251.0, "train_return": -578.9668473750353, "train_length": 500.0, "train_episodes": 280.0}
{"step": 244616}
{"step": 244616, "eval_return": -83.61528041115962, "eval_length": 295.6, "eval_episodes": 5.0}
{"step": 244822, "dataset_size": 122411.0, "train_return": 9933.91248100996, "train_length": 160.0, "train_episodes": 281.0}
{"step": 245000, "model_loss": 2.49676513671875, "model_grad_norm": Infinity, "player_loss": 0.22169265151023865, "reward_loss": 0.5850731730461121, "cont_loss": 4.499592614592984e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.8165910243988037, "rep_loss": 2.8165910243988037, "kl": 2.7355823516845703, "prior_ent": 41.986907958984375, "post_ent": 39.25094223022461, "normed_target_mean": 0.39881670475006104, "normed_target_std": 0.291189044713974, "normed_target_min": -0.17533466219902039, "normed_target_max": 1.2849273681640625, "EMA_005": -72.17071533203125, "EMA_095": -8.922713279724121, "value_mean": -46.66831970214844, "value_std": 17.803224563598633, "value_min": -79.172119140625, "value_max": -2.337772846221924, "target_mean": -46.941795349121094, "target_std": 18.416589736938477, "target_min": -83.24578857421875, "target_max": 8.933049201965332, "imag_reward_mean": -0.7429328560829163, "imag_reward_std": 0.6872963309288025, "imag_reward_min": -1.8810794353485107, "imag_reward_max": 13.147955894470215, "imag_action_mean": -9.149312973022461e-05, "imag_action_std": 0.83251953125, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.106893539428711, "actor_loss": 0.004005334340035915, "actor_grad_norm": NaN, "value_loss": 1.3165093660354614, "value_grad_norm": Infinity, "update_count": 30100.0, "fps": 14.074938536901369}
{"step": 245640}
{"step": 245640, "eval_return": 1801.5034205019474, "eval_length": 352.0, "eval_episodes": 5.0}
{"step": 245822, "dataset_size": 122911.0, "train_return": -168.3666386208497, "train_length": 500.0, "train_episodes": 282.0}
{"step": 246664}
{"step": 246664, "eval_return": -175.3551699474454, "eval_length": 279.6, "eval_episodes": 5.0}
{"step": 246754, "dataset_size": 123377.0, "train_return": -468.45212811231613, "train_length": 466.0, "train_episodes": 283.0}
{"step": 247688}
{"step": 247688, "eval_return": -165.12597496807575, "eval_length": 498.0, "eval_episodes": 5.0}
{"step": 247754, "dataset_size": 123877.0, "train_return": -458.5687350034714, "train_length": 500.0, "train_episodes": 284.0}
{"step": 248712}
{"step": 248712, "eval_return": -332.9932671865448, "eval_length": 406.2, "eval_episodes": 5.0}
{"step": 248754, "dataset_size": 124377.0, "train_return": -115.57374813221395, "train_length": 500.0, "train_episodes": 285.0}
{"step": 249736}
{"step": 249736, "eval_return": -266.5667531430721, "eval_length": 274.2, "eval_episodes": 5.0}
{"step": 249754, "dataset_size": 124877.0, "train_return": -531.5440216064453, "train_length": 500.0, "train_episodes": 286.0}
{"step": 250754, "dataset_size": 125377.0, "train_return": -114.4266971051693, "train_length": 500.0, "train_episodes": 287.0}
{"step": 250760}
{"step": 250760, "eval_return": 1729.1603723838925, "eval_length": 356.0, "eval_episodes": 5.0}
{"step": 251754, "dataset_size": 125877.0, "train_return": -27.10853683948517, "train_length": 500.0, "train_episodes": 288.0}
{"step": 251784}
{"step": 251784, "eval_return": -266.97303569316864, "eval_length": 416.4, "eval_episodes": 5.0}
{"step": 252754, "dataset_size": 126377.0, "train_return": -288.15722574852407, "train_length": 500.0, "train_episodes": 289.0}
{"step": 252808}
{"step": 252808, "eval_return": -262.6522836597636, "eval_length": 416.6, "eval_episodes": 5.0}
{"step": 253478, "dataset_size": 126739.0, "train_return": -345.6817238330841, "train_length": 362.0, "train_episodes": 290.0}
{"step": 253832}
{"step": 253832, "eval_return": 1727.506443271041, "eval_length": 361.8, "eval_episodes": 5.0}
{"step": 254478, "dataset_size": 127239.0, "train_return": -539.4356047809124, "train_length": 500.0, "train_episodes": 291.0}
{"step": 254856}
{"step": 254856, "eval_return": 1764.8759529799222, "eval_length": 385.8, "eval_episodes": 5.0}
{"step": 255000, "model_loss": 2.4783239364624023, "model_grad_norm": 5.905701160430908, "player_loss": 0.21900756657123566, "reward_loss": 0.5827009677886963, "cont_loss": 5.398580469773151e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.794269561767578, "rep_loss": 2.794269561767578, "kl": 2.7118020057678223, "prior_ent": 42.094242095947266, "post_ent": 39.38107681274414, "normed_target_mean": 0.4093789756298065, "normed_target_std": 0.28570184111595154, "normed_target_min": -0.16688992083072662, "normed_target_max": 1.1744598150253296, "EMA_005": -76.00614929199219, "EMA_095": -8.695207595825195, "value_mean": -48.17814636230469, "value_std": 18.713191986083984, "value_min": -83.37603759765625, "value_max": -2.281256914138794, "target_mean": -48.44380187988281, "target_std": 19.233144760131836, "target_min": -87.23521423339844, "target_max": 3.070082426071167, "imag_reward_mean": -0.748124897480011, "imag_reward_std": 0.6452713012695312, "imag_reward_min": -1.8798179626464844, "imag_reward_max": 12.079294204711914, "imag_action_mean": 0.021942138671875, "imag_action_std": 0.83154296875, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.4503065347671509, "actor_loss": 0.003518050303682685, "actor_grad_norm": 0.05659472569823265, "value_loss": 1.3113927841186523, "value_grad_norm": 1.508352518081665, "update_count": 31350.0, "fps": 14.143230468224347}
{"step": 255086, "dataset_size": 127543.0, "train_return": -213.99429094791412, "train_length": 304.0, "train_episodes": 292.0}
{"step": 255880}
{"step": 255880, "eval_return": 1803.5401123270392, "eval_length": 391.8, "eval_episodes": 5.0}
{"step": 256086, "dataset_size": 128043.0, "train_return": -87.69295765110292, "train_length": 500.0, "train_episodes": 293.0}
{"step": 256614, "dataset_size": 128307.0, "train_return": -35.97930300235748, "train_length": 264.0, "train_episodes": 294.0}
{"step": 256904}
{"step": 256904, "eval_return": -287.76670213341714, "eval_length": 326.6, "eval_episodes": 5.0}
{"step": 257614, "dataset_size": 128807.0, "train_return": -578.7826330661774, "train_length": 500.0, "train_episodes": 295.0}
{"step": 257688, "dataset_size": 128844.0, "train_return": 9989.775425553322, "train_length": 37.0, "train_episodes": 296.0}
{"step": 257928}
{"step": 257928, "eval_return": 1637.0524434179067, "eval_length": 387.0, "eval_episodes": 5.0}
{"step": 258688, "dataset_size": 129344.0, "train_return": -126.74349108990282, "train_length": 500.0, "train_episodes": 297.0}
{"step": 258952}
{"step": 258952, "eval_return": -253.51688908338548, "eval_length": 352.0, "eval_episodes": 5.0}
{"step": 259072, "dataset_size": 129536.0, "train_return": 9799.788581311703, "train_length": 192.0, "train_episodes": 298.0}
{"step": 259976}
{"step": 259976, "eval_return": -176.61914809010923, "eval_length": 431.8, "eval_episodes": 5.0}
{"step": 260072, "dataset_size": 130036.0, "train_return": -607.7926599085331, "train_length": 500.0, "train_episodes": 299.0}
{"step": 261000}
{"step": 261000, "eval_return": -123.71944566890598, "eval_length": 420.4, "eval_episodes": 5.0}
{"step": 261072, "dataset_size": 130536.0, "train_return": -498.74845534563065, "train_length": 500.0, "train_episodes": 300.0}
{"step": 262024}
{"step": 262024, "eval_return": -345.1207187533379, "eval_length": 464.6, "eval_episodes": 5.0}
{"step": 262072, "dataset_size": 131036.0, "train_return": -588.8231959342957, "train_length": 500.0, "train_episodes": 301.0}
{"step": 263048}
{"step": 263048, "eval_return": -251.93974054008723, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 263072, "dataset_size": 131536.0, "train_return": -494.5440437197685, "train_length": 500.0, "train_episodes": 302.0}
{"step": 263936, "dataset_size": 131968.0, "train_return": -443.5885515809059, "train_length": 432.0, "train_episodes": 303.0}
{"step": 264042, "dataset_size": 132021.0, "train_return": 9980.016139507294, "train_length": 53.0, "train_episodes": 304.0}
{"step": 264072}
{"step": 264072, "eval_return": -231.39112357124685, "eval_length": 428.8, "eval_episodes": 5.0}
{"step": 264568, "dataset_size": 132284.0, "train_return": -186.60634285211563, "train_length": 263.0, "train_episodes": 305.0}
{"step": 265000, "model_loss": 2.4793243408203125, "model_grad_norm": 5.843085765838623, "player_loss": 0.22011449933052063, "reward_loss": 0.5777877569198608, "cont_loss": 9.207361290464178e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.802217721939087, "rep_loss": 2.802217721939087, "kl": 2.7199041843414307, "prior_ent": 42.14188766479492, "post_ent": 39.421417236328125, "normed_target_mean": 0.41066914796829224, "normed_target_std": 0.28622329235076904, "normed_target_min": -0.17175105214118958, "normed_target_max": 1.1708152294158936, "EMA_005": -77.52042388916016, "EMA_095": -7.7714056968688965, "value_mean": -48.643733978271484, "value_std": 19.546789169311523, "value_min": -86.2922592163086, "value_max": -1.6770191192626953, "target_mean": -48.877235412597656, "target_std": 19.96396255493164, "target_min": -89.50067901611328, "target_max": 4.113994598388672, "imag_reward_mean": -0.7391568422317505, "imag_reward_std": 0.6098970770835876, "imag_reward_min": -1.8841056823730469, "imag_reward_max": 9.733222007751465, "imag_action_mean": 0.040679931640625, "imag_action_std": 0.8310546875, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.629381537437439, "actor_loss": 0.002854368882253766, "actor_grad_norm": 0.05499737709760666, "value_loss": 1.263892412185669, "value_grad_norm": Infinity, "update_count": 32600.0, "fps": 4.1575970133483535}
{"step": 265096}
{"step": 265096, "eval_return": -160.5387999139726, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 265568, "dataset_size": 132784.0, "train_return": -225.26357913017273, "train_length": 500.0, "train_episodes": 306.0}
{"step": 266120}
{"step": 266120, "eval_return": -226.9253551784903, "eval_length": 464.0, "eval_episodes": 5.0}
{"step": 266568, "dataset_size": 133284.0, "train_return": -572.1912260055542, "train_length": 500.0, "train_episodes": 307.0}
{"step": 266772, "dataset_size": 133386.0, "train_return": -134.9845688343048, "train_length": 102.0, "train_episodes": 308.0}
{"step": 267144}
{"step": 267144, "eval_return": -172.92558023631574, "eval_length": 396.2, "eval_episodes": 5.0}
{"step": 267772, "dataset_size": 133886.0, "train_return": -105.30845760554075, "train_length": 500.0, "train_episodes": 309.0}
{"step": 267814, "dataset_size": 133907.0, "train_return": -16.77283489704132, "train_length": 21.0, "train_episodes": 310.0}
{"step": 268168}
{"step": 268168, "eval_return": 1779.0979870796205, "eval_length": 233.8, "eval_episodes": 5.0}
{"step": 268814, "dataset_size": 134407.0, "train_return": -239.20191085338593, "train_length": 500.0, "train_episodes": 311.0}
{"step": 269192}
{"step": 269192, "eval_return": -84.82311122589745, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 269814, "dataset_size": 134907.0, "train_return": -141.40909592807293, "train_length": 500.0, "train_episodes": 312.0}
{"step": 270216}
{"step": 270216, "eval_return": 1797.5996169626712, "eval_length": 252.2, "eval_episodes": 5.0}
{"step": 270814, "dataset_size": 135407.0, "train_return": -483.0273579135537, "train_length": 500.0, "train_episodes": 313.0}
{"step": 271240}
{"step": 271240, "eval_return": 1764.5357085376977, "eval_length": 323.6, "eval_episodes": 5.0}
{"step": 271560, "dataset_size": 135780.0, "train_return": -345.7223717570305, "train_length": 373.0, "train_episodes": 314.0}
{"step": 271658, "dataset_size": 135829.0, "train_return": -19.132609009742737, "train_length": 49.0, "train_episodes": 315.0}
{"step": 271810, "dataset_size": 135905.0, "train_return": -21.862534999847412, "train_length": 76.0, "train_episodes": 316.0}
{"step": 272264}
{"step": 272264, "eval_return": -248.0068175777793, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 272810, "dataset_size": 136405.0, "train_return": -104.83668453246355, "train_length": 500.0, "train_episodes": 317.0}
{"step": 273058, "dataset_size": 136529.0, "train_return": -27.047773003578186, "train_length": 124.0, "train_episodes": 318.0}
{"step": 273288}
{"step": 273288, "eval_return": -252.2827149808407, "eval_length": 354.4, "eval_episodes": 5.0}
{"step": 274058, "dataset_size": 137029.0, "train_return": -191.2396362926811, "train_length": 500.0, "train_episodes": 319.0}
{"step": 274312}
{"step": 274312, "eval_return": -289.70909006297586, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 274340, "dataset_size": 137170.0, "train_return": -31.648712396621704, "train_length": 141.0, "train_episodes": 320.0}
{"step": 274518, "dataset_size": 137259.0, "train_return": -10.389591455459595, "train_length": 89.0, "train_episodes": 321.0}
{"step": 275000, "model_loss": 2.4808192253112793, "model_grad_norm": Infinity, "player_loss": 0.21865160763263702, "reward_loss": 0.5757770538330078, "cont_loss": 9.101344039663672e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.8104989528656006, "rep_loss": 2.8104989528656006, "kl": 2.7284374237060547, "prior_ent": 42.35326385498047, "post_ent": 39.62818908691406, "normed_target_mean": 0.40538522601127625, "normed_target_std": 0.28796353936195374, "normed_target_min": -0.18612147867679596, "normed_target_max": 1.1321688890457153, "EMA_005": -77.7970962524414, "EMA_095": -6.8263421058654785, "value_mean": -48.831581115722656, "value_std": 20.05556869506836, "value_min": -88.06917572021484, "value_max": -1.4810773134231567, "target_mean": -49.02548599243164, "target_std": 20.437435150146484, "target_min": -91.00566101074219, "target_max": 2.4924263954162598, "imag_reward_mean": -0.7382658123970032, "imag_reward_std": 0.6353414058685303, "imag_reward_min": -1.8853445053100586, "imag_reward_max": 11.512754440307617, "imag_action_mean": 0.050933837890625, "imag_action_std": 0.8349609375, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.4606750011444092, "actor_loss": 0.0022821284364908934, "actor_grad_norm": 0.05644470080733299, "value_loss": 1.2871978282928467, "value_grad_norm": 1.4616789817810059, "update_count": 33850.0, "fps": 3.909788669161616}
{"step": 275336}
{"step": 275336, "eval_return": -165.26481643915176, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 275518, "dataset_size": 137759.0, "train_return": -161.13132844679058, "train_length": 500.0, "train_episodes": 322.0}
{"step": 275676, "dataset_size": 137838.0, "train_return": -24.81141769886017, "train_length": 79.0, "train_episodes": 323.0}
{"step": 275880, "dataset_size": 137940.0, "train_return": 9918.046769440174, "train_length": 102.0, "train_episodes": 324.0}
{"step": 276360}
{"step": 276360, "eval_return": 1730.3035163938998, "eval_length": 363.0, "eval_episodes": 5.0}
{"step": 276880, "dataset_size": 138440.0, "train_return": -111.37492880376521, "train_length": 500.0, "train_episodes": 325.0}
{"step": 277384}
{"step": 277384, "eval_return": 1845.1769137486815, "eval_length": 334.0, "eval_episodes": 5.0}
{"step": 277880, "dataset_size": 138940.0, "train_return": -39.21260666847229, "train_length": 500.0, "train_episodes": 326.0}
{"step": 278408}
{"step": 278408, "eval_return": 1794.0818432107567, "eval_length": 317.6, "eval_episodes": 5.0}
{"step": 278880, "dataset_size": 139440.0, "train_return": -537.8179372251034, "train_length": 500.0, "train_episodes": 327.0}
{"step": 279432}
{"step": 279432, "eval_return": -296.02996616512536, "eval_length": 420.4, "eval_episodes": 5.0}
{"step": 279880, "dataset_size": 139940.0, "train_return": -202.45055196806788, "train_length": 500.0, "train_episodes": 328.0}
{"step": 280456}
{"step": 280456, "eval_return": -159.4822426915169, "eval_length": 413.4, "eval_episodes": 5.0}
{"step": 280880, "dataset_size": 140440.0, "train_return": -128.67966776061803, "train_length": 500.0, "train_episodes": 329.0}
{"step": 281480}
{"step": 281480, "eval_return": -252.420625731349, "eval_length": 327.4, "eval_episodes": 5.0}
{"step": 281806, "dataset_size": 140903.0, "train_return": 9778.680500626564, "train_length": 463.0, "train_episodes": 330.0}
{"step": 282342, "dataset_size": 141171.0, "train_return": -233.05820593237877, "train_length": 268.0, "train_episodes": 331.0}
{"step": 282504}
{"step": 282504, "eval_return": 1686.9210176497697, "eval_length": 369.6, "eval_episodes": 5.0}
{"step": 283342, "dataset_size": 141671.0, "train_return": -179.5975041463971, "train_length": 500.0, "train_episodes": 332.0}
{"step": 283416, "dataset_size": 141708.0, "train_return": -23.074650764465332, "train_length": 37.0, "train_episodes": 333.0}
{"step": 283490, "dataset_size": 141745.0, "train_return": -21.41066211462021, "train_length": 37.0, "train_episodes": 334.0}
{"step": 283528}
{"step": 283528, "eval_return": 1645.3982211709022, "eval_length": 327.2, "eval_episodes": 5.0}
{"step": 283986, "dataset_size": 141993.0, "train_return": -181.83232897520065, "train_length": 248.0, "train_episodes": 335.0}
{"step": 284552}
{"step": 284552, "eval_return": -401.467820481956, "eval_length": 447.2, "eval_episodes": 5.0}
{"step": 284986, "dataset_size": 142493.0, "train_return": -497.73627945780754, "train_length": 500.0, "train_episodes": 336.0}
{"step": 285000, "model_loss": 2.468289375305176, "model_grad_norm": 5.811956405639648, "player_loss": 0.217117577791214, "reward_loss": 0.570410966873169, "cont_loss": 0.00011595601972658187, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.8010754585266113, "rep_loss": 2.8010754585266113, "kl": 2.7182137966156006, "prior_ent": 42.487911224365234, "post_ent": 39.77680206298828, "normed_target_mean": 0.4143069386482239, "normed_target_std": 0.28737369179725647, "normed_target_min": -0.1952785849571228, "normed_target_max": 1.2080703973770142, "EMA_005": -75.12384033203125, "EMA_095": -6.352635860443115, "value_mean": -46.535362243652344, "value_std": 19.3225154876709, "value_min": -85.55016326904297, "value_max": -1.1834080219268799, "target_mean": -46.633514404296875, "target_std": 19.764293670654297, "target_min": -88.54840087890625, "target_max": 8.037939071655273, "imag_reward_mean": -0.7246689796447754, "imag_reward_std": 0.6821854710578918, "imag_reward_min": -1.8862491846084595, "imag_reward_max": 11.700382232666016, "imag_action_mean": 0.0738525390625, "imag_action_std": 0.82861328125, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.5719343423843384, "actor_loss": 0.0009639429044909775, "actor_grad_norm": 0.05864512920379639, "value_loss": 1.3272511959075928, "value_grad_norm": 1.5156939029693604, "update_count": 35100.0, "fps": 4.019579891940615}
{"step": 285110, "dataset_size": 142555.0, "train_return": -13.740613222122192, "train_length": 62.0, "train_episodes": 337.0}
{"step": 285576}
{"step": 285576, "eval_return": 1956.520731164515, "eval_length": 327.6, "eval_episodes": 5.0}
{"step": 286110, "dataset_size": 143055.0, "train_return": -66.67874753475189, "train_length": 500.0, "train_episodes": 338.0}
{"step": 286600}
{"step": 286600, "eval_return": -187.66632316112518, "eval_length": 440.4, "eval_episodes": 5.0}
{"step": 287110, "dataset_size": 143555.0, "train_return": -214.61836627870798, "train_length": 500.0, "train_episodes": 339.0}
{"step": 287624}
{"step": 287624, "eval_return": 1782.9001351177692, "eval_length": 338.6, "eval_episodes": 5.0}
{"step": 288110, "dataset_size": 144055.0, "train_return": -530.0364769399166, "train_length": 500.0, "train_episodes": 340.0}
{"step": 288648}
{"step": 288648, "eval_return": -204.91428489238024, "eval_length": 272.8, "eval_episodes": 5.0}
{"step": 289110, "dataset_size": 144555.0, "train_return": -443.646396368742, "train_length": 500.0, "train_episodes": 341.0}
{"step": 289238, "dataset_size": 144619.0, "train_return": -63.081743597984314, "train_length": 64.0, "train_episodes": 342.0}
{"step": 289672}
{"step": 289672, "eval_return": -283.7914094492793, "eval_length": 312.4, "eval_episodes": 5.0}
{"step": 289730, "dataset_size": 144865.0, "train_return": -113.58181783556938, "train_length": 246.0, "train_episodes": 343.0}
{"step": 290696}
{"step": 290696, "eval_return": -120.86211659163237, "eval_length": 318.0, "eval_episodes": 5.0}
{"step": 290730, "dataset_size": 145365.0, "train_return": -610.8450164794922, "train_length": 500.0, "train_episodes": 344.0}
{"step": 291720}
{"step": 291720, "eval_return": -163.12540825381876, "eval_length": 356.0, "eval_episodes": 5.0}
{"step": 291730, "dataset_size": 145865.0, "train_return": -33.36605703830719, "train_length": 500.0, "train_episodes": 345.0}
{"step": 291956, "dataset_size": 145978.0, "train_return": -61.98620945215225, "train_length": 113.0, "train_episodes": 346.0}
{"step": 292052, "dataset_size": 146026.0, "train_return": -25.716196358203888, "train_length": 48.0, "train_episodes": 347.0}
{"step": 292744}
{"step": 292744, "eval_return": -218.79667685329915, "eval_length": 338.4, "eval_episodes": 5.0}
{"step": 293052, "dataset_size": 146526.0, "train_return": -557.5980586111546, "train_length": 500.0, "train_episodes": 348.0}
{"step": 293768}
{"step": 293768, "eval_return": -418.7766905874014, "eval_length": 481.2, "eval_episodes": 5.0}
{"step": 294052, "dataset_size": 147026.0, "train_return": -445.3079799711704, "train_length": 500.0, "train_episodes": 349.0}
{"step": 294792}
{"step": 294792, "eval_return": 1829.1728550255298, "eval_length": 212.4, "eval_episodes": 5.0}
{"step": 295000, "model_loss": 2.454012870788574, "model_grad_norm": Infinity, "player_loss": 0.21446610987186432, "reward_loss": 0.5628376007080078, "cont_loss": 0.0001204215077450499, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.794313907623291, "rep_loss": 2.794313907623291, "kl": 2.710299253463745, "prior_ent": 42.53246307373047, "post_ent": 39.82753372192383, "normed_target_mean": 0.4149287939071655, "normed_target_std": 0.29005879163742065, "normed_target_min": -0.20261003077030182, "normed_target_max": 1.1995881795883179, "EMA_005": -70.60328674316406, "EMA_095": -5.879909515380859, "value_mean": -43.68989181518555, "value_std": 18.43864631652832, "value_min": -81.09281158447266, "value_max": -0.8393799066543579, "target_mean": -43.743289947509766, "target_std": 18.77581787109375, "target_min": -83.70962524414062, "target_max": 7.0326828956604, "imag_reward_mean": -0.7182243466377258, "imag_reward_std": 0.635658323764801, "imag_reward_min": -1.8726632595062256, "imag_reward_max": 11.019132614135742, "imag_action_mean": 0.062469482421875, "imag_action_std": 0.83203125, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.3424890041351318, "actor_loss": 0.0004215371154714376, "actor_grad_norm": NaN, "value_loss": 1.3560558557510376, "value_grad_norm": Infinity, "update_count": 36350.0, "fps": 4.073486938408055}
{"step": 295014, "dataset_size": 147507.0, "train_return": -466.78863905370235, "train_length": 481.0, "train_episodes": 350.0}
{"step": 295816}
{"step": 295816, "eval_return": -284.0300785526633, "eval_length": 328.8, "eval_episodes": 5.0}
{"step": 296014, "dataset_size": 148007.0, "train_return": -399.7640638053417, "train_length": 500.0, "train_episodes": 351.0}
{"step": 296840}
{"step": 296840, "eval_return": -251.4918362110853, "eval_length": 459.2, "eval_episodes": 5.0}
{"step": 297014, "dataset_size": 148507.0, "train_return": -524.452801913023, "train_length": 500.0, "train_episodes": 352.0}
{"step": 297864}
{"step": 297864, "eval_return": -177.17398968040942, "eval_length": 412.2, "eval_episodes": 5.0}
{"step": 297894, "dataset_size": 148947.0, "train_return": 9552.649297952652, "train_length": 440.0, "train_episodes": 353.0}
{"step": 298888}
{"step": 298888, "eval_return": -301.0581471681595, "eval_length": 415.2, "eval_episodes": 5.0}
{"step": 298894, "dataset_size": 149447.0, "train_return": -326.3679320216179, "train_length": 500.0, "train_episodes": 354.0}
{"step": 299894, "dataset_size": 149947.0, "train_return": -22.6762832403183, "train_length": 500.0, "train_episodes": 355.0}
{"step": 299912}
{"step": 299912, "eval_return": -157.07373173758387, "eval_length": 409.2, "eval_episodes": 5.0}
{"step": 300894, "dataset_size": 150447.0, "train_return": -470.03671941161156, "train_length": 500.0, "train_episodes": 356.0}
{"step": 300936}
{"step": 300936, "eval_return": -207.7661874525249, "eval_length": 351.6, "eval_episodes": 5.0}
{"step": 301474, "dataset_size": 150737.0, "train_return": -154.4483754336834, "train_length": 290.0, "train_episodes": 357.0}
{"step": 301960}
{"step": 301960, "eval_return": -162.5989911288023, "eval_length": 385.0, "eval_episodes": 5.0}
{"step": 302474, "dataset_size": 151237.0, "train_return": -28.399122953414917, "train_length": 500.0, "train_episodes": 358.0}
{"step": 302984}
{"step": 302984, "eval_return": -259.6394101459533, "eval_length": 370.2, "eval_episodes": 5.0}
{"step": 303474, "dataset_size": 151737.0, "train_return": -32.05541169643402, "train_length": 500.0, "train_episodes": 359.0}
{"step": 304008}
{"step": 304008, "eval_return": -475.3466728359461, "eval_length": 469.6, "eval_episodes": 5.0}
{"step": 304110, "dataset_size": 152055.0, "train_return": -306.1001743376255, "train_length": 318.0, "train_episodes": 360.0}
{"step": 305000, "model_loss": 2.468168020248413, "model_grad_norm": Infinity, "player_loss": 0.21464034914970398, "reward_loss": 0.5674216151237488, "cont_loss": 7.922938675619662e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.810044050216675, "rep_loss": 2.810044050216675, "kl": 2.7275729179382324, "prior_ent": 42.811073303222656, "post_ent": 40.098106384277344, "normed_target_mean": 0.4141005873680115, "normed_target_std": 0.29547786712646484, "normed_target_min": -0.2098960131406784, "normed_target_max": 1.1983978748321533, "EMA_005": -67.0186996459961, "EMA_095": -4.8726067543029785, "value_mean": -41.197845458984375, "value_std": 18.033878326416016, "value_min": -77.75375366210938, "value_max": -0.6137750744819641, "target_mean": -41.282493591308594, "target_std": 18.364843368530273, "target_min": -80.05990600585938, "target_max": 7.419429779052734, "imag_reward_mean": -0.7284652590751648, "imag_reward_std": 0.6718964576721191, "imag_reward_min": -1.8769394159317017, "imag_reward_max": 13.102662086486816, "imag_action_mean": 0.0888671875, "imag_action_std": 0.83154296875, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.0691927671432495, "actor_loss": 0.0010355047415941954, "actor_grad_norm": Infinity, "value_loss": 1.3586536645889282, "value_grad_norm": 1.5547804832458496, "update_count": 37600.0, "fps": 4.033667134747119}
{"step": 305032}
{"step": 305032, "eval_return": 1727.7192557238043, "eval_length": 392.4, "eval_episodes": 5.0}
{"step": 305110, "dataset_size": 152555.0, "train_return": -64.23665857315063, "train_length": 500.0, "train_episodes": 361.0}
{"step": 306056}
{"step": 306056, "eval_return": -252.284694314003, "eval_length": 361.4, "eval_episodes": 5.0}
{"step": 306110, "dataset_size": 153055.0, "train_return": -13.662620663642883, "train_length": 500.0, "train_episodes": 362.0}
{"step": 307080}
{"step": 307080, "eval_return": -335.2370179980993, "eval_length": 371.8, "eval_episodes": 5.0}
{"step": 307110, "dataset_size": 153555.0, "train_return": -28.239887416362762, "train_length": 500.0, "train_episodes": 363.0}
{"step": 308038, "dataset_size": 154019.0, "train_return": -211.544708609581, "train_length": 464.0, "train_episodes": 364.0}
{"step": 308104}
{"step": 308104, "eval_return": -226.64251595288516, "eval_length": 409.2, "eval_episodes": 5.0}
{"step": 308882, "dataset_size": 154441.0, "train_return": -59.46563744544983, "train_length": 422.0, "train_episodes": 365.0}
{"step": 309128}
{"step": 309128, "eval_return": 1694.91714104563, "eval_length": 370.8, "eval_episodes": 5.0}
{"step": 309882, "dataset_size": 154941.0, "train_return": -441.2245537638664, "train_length": 500.0, "train_episodes": 366.0}
{"step": 310062, "dataset_size": 155031.0, "train_return": -63.619526386260986, "train_length": 90.0, "train_episodes": 367.0}
{"step": 310152}
{"step": 310152, "eval_return": -269.6964213043451, "eval_length": 370.4, "eval_episodes": 5.0}
{"step": 311062, "dataset_size": 155531.0, "train_return": -210.47692215442657, "train_length": 500.0, "train_episodes": 368.0}
{"step": 311176}
{"step": 311176, "eval_return": 1788.8252103567124, "eval_length": 294.2, "eval_episodes": 5.0}
{"step": 312062, "dataset_size": 156031.0, "train_return": -404.51211047172546, "train_length": 500.0, "train_episodes": 369.0}
{"step": 312200}
{"step": 312200, "eval_return": -449.58609943389894, "eval_length": 481.8, "eval_episodes": 5.0}
{"step": 312888, "dataset_size": 156444.0, "train_return": 9918.54150545597, "train_length": 413.0, "train_episodes": 370.0}
{"step": 313224}
{"step": 313224, "eval_return": -84.03690485358239, "eval_length": 417.4, "eval_episodes": 5.0}
{"step": 313888, "dataset_size": 156944.0, "train_return": -525.4697735607624, "train_length": 500.0, "train_episodes": 371.0}
{"step": 314248}
{"step": 314248, "eval_return": -276.022299669683, "eval_length": 413.2, "eval_episodes": 5.0}
{"step": 314888, "dataset_size": 157444.0, "train_return": -392.3344965572469, "train_length": 500.0, "train_episodes": 372.0}
{"step": 315000, "model_loss": 2.481074571609497, "model_grad_norm": 5.890716075897217, "player_loss": 0.2175837904214859, "reward_loss": 0.5629761815071106, "cont_loss": 0.00010484181984793395, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.8340160846710205, "rep_loss": 2.8340160846710205, "kl": 2.752861738204956, "prior_ent": 43.10441970825195, "post_ent": 40.367069244384766, "normed_target_mean": 0.4129369556903839, "normed_target_std": 0.29796889424324036, "normed_target_min": -0.2177582085132599, "normed_target_max": 1.30306875705719, "EMA_005": -62.82379913330078, "EMA_095": -2.9018304347991943, "value_mean": -38.074058532714844, "value_std": 17.455411911010742, "value_min": -74.16698455810547, "value_max": -0.24807573854923248, "target_mean": -38.07673645019531, "target_std": 17.855932235717773, "target_min": -75.86058807373047, "target_max": 15.192087173461914, "imag_reward_mean": -0.7101334929466248, "imag_reward_std": 0.8262592554092407, "imag_reward_min": -1.8743964433670044, "imag_reward_max": 24.19124984741211, "imag_action_mean": 0.07354736328125, "imag_action_std": 0.82763671875, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.5292136669158936, "actor_loss": -0.0003988630196545273, "actor_grad_norm": 0.05754023417830467, "value_loss": 1.354500412940979, "value_grad_norm": 1.4789557456970215, "update_count": 38850.0, "fps": 4.2101054384614045}
{"step": 315190, "dataset_size": 157595.0, "train_return": -128.2644607424736, "train_length": 151.0, "train_episodes": 373.0}
{"step": 315272}
{"step": 315272, "eval_return": -254.2732511341572, "eval_length": 468.0, "eval_episodes": 5.0}
{"step": 315516, "dataset_size": 157758.0, "train_return": -61.35698616504669, "train_length": 163.0, "train_episodes": 374.0}
{"step": 316296}
{"step": 316296, "eval_return": -51.06307429075241, "eval_length": 241.0, "eval_episodes": 5.0}
{"step": 316516, "dataset_size": 158258.0, "train_return": -58.8405796289444, "train_length": 500.0, "train_episodes": 375.0}
{"step": 317320}
{"step": 317320, "eval_return": -327.40273696780207, "eval_length": 395.2, "eval_episodes": 5.0}
{"step": 317516, "dataset_size": 158758.0, "train_return": -127.6543401479721, "train_length": 500.0, "train_episodes": 376.0}
{"step": 318340, "dataset_size": 159170.0, "train_return": -277.5901931524277, "train_length": 412.0, "train_episodes": 377.0}
{"step": 318344}
{"step": 318344, "eval_return": -224.71457483172418, "eval_length": 400.0, "eval_episodes": 5.0}
{"step": 318984, "dataset_size": 159492.0, "train_return": -201.76007625460625, "train_length": 322.0, "train_episodes": 378.0}
{"step": 319368}
{"step": 319368, "eval_return": -87.09682574272156, "eval_length": 283.2, "eval_episodes": 5.0}
{"step": 319502, "dataset_size": 159751.0, "train_return": -277.6377243697643, "train_length": 259.0, "train_episodes": 379.0}
{"step": 320050, "dataset_size": 160025.0, "train_return": -332.6761812567711, "train_length": 274.0, "train_episodes": 380.0}
{"step": 320392}
{"step": 320392, "eval_return": -170.88746923804283, "eval_length": 382.4, "eval_episodes": 5.0}
{"step": 321050, "dataset_size": 160525.0, "train_return": -28.925091981887817, "train_length": 500.0, "train_episodes": 381.0}
{"step": 321416}
{"step": 321416, "eval_return": -119.00771435499192, "eval_length": 412.4, "eval_episodes": 5.0}
{"step": 322050, "dataset_size": 161025.0, "train_return": -84.40735244750977, "train_length": 500.0, "train_episodes": 382.0}
{"step": 322440}
{"step": 322440, "eval_return": 1572.090587374568, "eval_length": 384.2, "eval_episodes": 5.0}
{"step": 323050, "dataset_size": 161525.0, "train_return": -485.43356734514236, "train_length": 500.0, "train_episodes": 383.0}
{"step": 323464}
{"step": 323464, "eval_return": -157.38331377506256, "eval_length": 398.6, "eval_episodes": 5.0}
{"step": 324050, "dataset_size": 162025.0, "train_return": -72.19696122407913, "train_length": 500.0, "train_episodes": 384.0}
{"step": 324186, "dataset_size": 162093.0, "train_return": -29.493379950523376, "train_length": 68.0, "train_episodes": 385.0}
{"step": 324336, "dataset_size": 162168.0, "train_return": 9971.685338139534, "train_length": 75.0, "train_episodes": 386.0}
{"step": 324488}
{"step": 324488, "eval_return": 1915.8765951037408, "eval_length": 139.6, "eval_episodes": 5.0}
{"step": 325000, "model_loss": 2.474292278289795, "model_grad_norm": Infinity, "player_loss": 0.21813249588012695, "reward_loss": 0.5535075664520264, "cont_loss": 8.54629251989536e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.837611198425293, "rep_loss": 2.837611198425293, "kl": 2.757289171218872, "prior_ent": 43.46786117553711, "post_ent": 40.727386474609375, "normed_target_mean": 0.4177159070968628, "normed_target_std": 0.3006983995437622, "normed_target_min": -0.22685573995113373, "normed_target_max": 1.1648821830749512, "EMA_005": -57.72346115112305, "EMA_095": -2.2693536281585693, "value_mean": -34.571372985839844, "value_std": 16.388744354248047, "value_min": -68.68350219726562, "value_max": -0.0690879225730896, "target_mean": -34.56081771850586, "target_std": 16.67361831665039, "target_min": -70.2933578491211, "target_max": 6.866816997528076, "imag_reward_mean": -0.6983604431152344, "imag_reward_std": 0.6642276644706726, "imag_reward_min": -1.863499641418457, "imag_reward_max": 13.217225074768066, "imag_action_mean": 0.08978271484375, "imag_action_std": 0.8291015625, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.3493099212646484, "actor_loss": -0.0006146732484921813, "actor_grad_norm": NaN, "value_loss": 1.3939735889434814, "value_grad_norm": Infinity, "update_count": 40100.0, "fps": 14.40505201655098}
{"step": 325336, "dataset_size": 162668.0, "train_return": -52.309164226055145, "train_length": 500.0, "train_episodes": 387.0}
{"step": 325512}
{"step": 325512, "eval_return": -26.462428474426268, "eval_length": 204.8, "eval_episodes": 5.0}
{"step": 325628, "dataset_size": 162814.0, "train_return": -59.64635646343231, "train_length": 146.0, "train_episodes": 388.0}
{"step": 325734, "dataset_size": 162867.0, "train_return": -26.77233785390854, "train_length": 53.0, "train_episodes": 389.0}
{"step": 326420, "dataset_size": 163210.0, "train_return": -275.42431885004044, "train_length": 343.0, "train_episodes": 390.0}
{"step": 326536}
{"step": 326536, "eval_return": -346.77293944358826, "eval_length": 347.0, "eval_episodes": 5.0}
{"step": 327420, "dataset_size": 163710.0, "train_return": -29.832821011543274, "train_length": 500.0, "train_episodes": 391.0}
{"step": 327560}
{"step": 327560, "eval_return": -312.2692140981555, "eval_length": 410.6, "eval_episodes": 5.0}
{"step": 327754, "dataset_size": 163877.0, "train_return": -90.55504024028778, "train_length": 167.0, "train_episodes": 392.0}
{"step": 327870, "dataset_size": 163935.0, "train_return": -33.664778769016266, "train_length": 58.0, "train_episodes": 393.0}
{"step": 328584}
{"step": 328584, "eval_return": -252.5153957732022, "eval_length": 378.8, "eval_episodes": 5.0}
{"step": 328870, "dataset_size": 164435.0, "train_return": -647.856365352869, "train_length": 500.0, "train_episodes": 394.0}
{"step": 329608}
{"step": 329608, "eval_return": -117.15894109606742, "eval_length": 269.0, "eval_episodes": 5.0}
{"step": 329870, "dataset_size": 164935.0, "train_return": -760.9527988880873, "train_length": 500.0, "train_episodes": 395.0}
{"step": 330632}
{"step": 330632, "eval_return": -461.074284529686, "eval_length": 452.8, "eval_episodes": 5.0}
{"step": 330870, "dataset_size": 165435.0, "train_return": -131.25968535989523, "train_length": 500.0, "train_episodes": 396.0}
{"step": 331040, "dataset_size": 165520.0, "train_return": -25.27827274799347, "train_length": 85.0, "train_episodes": 397.0}
{"step": 331272, "dataset_size": 165636.0, "train_return": -104.91311419010162, "train_length": 116.0, "train_episodes": 398.0}
{"step": 331500, "dataset_size": 165750.0, "train_return": -112.85807681083679, "train_length": 114.0, "train_episodes": 399.0}
{"step": 331656}
{"step": 331656, "eval_return": -83.47851860523224, "eval_length": 425.2, "eval_episodes": 5.0}
{"step": 332500, "dataset_size": 166250.0, "train_return": -29.6170254945755, "train_length": 500.0, "train_episodes": 400.0}
{"step": 332680}
{"step": 332680, "eval_return": -179.67610235214232, "eval_length": 319.2, "eval_episodes": 5.0}
{"step": 333360, "dataset_size": 166680.0, "train_return": -454.70246547460556, "train_length": 430.0, "train_episodes": 401.0}
{"step": 333704}
{"step": 333704, "eval_return": -99.3065998852253, "eval_length": 256.4, "eval_episodes": 5.0}
{"step": 334360, "dataset_size": 167180.0, "train_return": -641.0921886265278, "train_length": 500.0, "train_episodes": 402.0}
{"step": 334728}
{"step": 334728, "eval_return": -283.8807485200465, "eval_length": 417.0, "eval_episodes": 5.0}
{"step": 335000, "model_loss": 2.467503547668457, "model_grad_norm": 5.707516193389893, "player_loss": 0.21777810156345367, "reward_loss": 0.5487610101699829, "cont_loss": 0.0001383586786687374, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.834709882736206, "rep_loss": 2.834709882736206, "kl": 2.7537882328033447, "prior_ent": 43.641754150390625, "post_ent": 40.906063079833984, "normed_target_mean": 0.41926777362823486, "normed_target_std": 0.30421364307403564, "normed_target_min": -0.23369662463665009, "normed_target_max": 1.1734826564788818, "EMA_005": -54.18258285522461, "EMA_095": -1.5340087413787842, "value_mean": -32.018436431884766, "value_std": 15.721633911132812, "value_min": -64.7786865234375, "value_max": 0.04905036464333534, "target_mean": -32.1077766418457, "target_std": 16.0175838470459, "target_min": -66.48682403564453, "target_max": 7.595251560211182, "imag_reward_mean": -0.7007789611816406, "imag_reward_std": 0.6525772213935852, "imag_reward_min": -1.868818998336792, "imag_reward_max": 12.39885425567627, "imag_action_mean": 0.08538818359375, "imag_action_std": 0.8310546875, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.257277011871338, "actor_loss": 0.0012955272104591131, "actor_grad_norm": NaN, "value_loss": 1.4521466493606567, "value_grad_norm": Infinity, "update_count": 41350.0, "fps": 14.468572601711296}
{"step": 335360, "dataset_size": 167680.0, "train_return": -163.02480024844408, "train_length": 500.0, "train_episodes": 403.0}
{"step": 335752}
{"step": 335752, "eval_return": 1659.420830910653, "eval_length": 345.2, "eval_episodes": 5.0}
{"step": 336360, "dataset_size": 168180.0, "train_return": -125.02575290808454, "train_length": 500.0, "train_episodes": 404.0}
{"step": 336776}
{"step": 336776, "eval_return": -446.73554319664834, "eval_length": 437.6, "eval_episodes": 5.0}
{"step": 337360, "dataset_size": 168680.0, "train_return": -207.0376034975052, "train_length": 500.0, "train_episodes": 405.0}
{"step": 337800}
{"step": 337800, "eval_return": 1760.778384011984, "eval_length": 379.8, "eval_episodes": 5.0}
{"step": 338360, "dataset_size": 169180.0, "train_return": -177.51770324073732, "train_length": 500.0, "train_episodes": 406.0}
{"step": 338626, "dataset_size": 169313.0, "train_return": -122.90923178195953, "train_length": 133.0, "train_episodes": 407.0}
{"step": 338824}
{"step": 338824, "eval_return": 1892.4846432715653, "eval_length": 277.0, "eval_episodes": 5.0}
{"step": 339088, "dataset_size": 169544.0, "train_return": -258.0262787938118, "train_length": 231.0, "train_episodes": 408.0}
{"step": 339848}
{"step": 339848, "eval_return": 1647.085637921095, "eval_length": 410.4, "eval_episodes": 5.0}
{"step": 340088, "dataset_size": 170044.0, "train_return": -493.38665418326855, "train_length": 500.0, "train_episodes": 409.0}
{"step": 340872}
{"step": 340872, "eval_return": 1833.3416238687932, "eval_length": 324.8, "eval_episodes": 5.0}
{"step": 341088, "dataset_size": 170544.0, "train_return": -457.55515933036804, "train_length": 500.0, "train_episodes": 410.0}
{"step": 341194, "dataset_size": 170597.0, "train_return": -26.38719642162323, "train_length": 53.0, "train_episodes": 411.0}
{"step": 341896}
{"step": 341896, "eval_return": 1666.085550287366, "eval_length": 301.4, "eval_episodes": 5.0}
{"step": 342194, "dataset_size": 171097.0, "train_return": -513.7156033664942, "train_length": 500.0, "train_episodes": 412.0}
{"step": 342920}
{"step": 342920, "eval_return": -144.93034619260578, "eval_length": 428.4, "eval_episodes": 5.0}
{"step": 343194, "dataset_size": 171597.0, "train_return": -374.22250791825354, "train_length": 500.0, "train_episodes": 413.0}
{"step": 343944}
{"step": 343944, "eval_return": -191.81880375742912, "eval_length": 353.6, "eval_episodes": 5.0}
{"step": 344194, "dataset_size": 172097.0, "train_return": -186.41462953016162, "train_length": 500.0, "train_episodes": 414.0}
{"step": 344968}
{"step": 344968, "eval_return": -337.6685388885438, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 345000, "model_loss": 2.4535880088806152, "model_grad_norm": 5.640036106109619, "player_loss": 0.213342547416687, "reward_loss": 0.5459762811660767, "cont_loss": 6.074541306588799e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.8236804008483887, "rep_loss": 2.8236804008483887, "kl": 2.7421224117279053, "prior_ent": 43.661739349365234, "post_ent": 40.936256408691406, "normed_target_mean": 0.4364452064037323, "normed_target_std": 0.3028659522533417, "normed_target_min": -0.2396477609872818, "normed_target_max": 1.1501175165176392, "EMA_005": -55.66773223876953, "EMA_095": -1.6185779571533203, "value_mean": -31.938562393188477, "value_std": 16.075590133666992, "value_min": -66.36634063720703, "value_max": 0.12427819520235062, "target_mean": -32.07525634765625, "target_std": 16.36977767944336, "target_min": -68.62310028076172, "target_max": 6.484680652618408, "imag_reward_mean": -0.70332932472229, "imag_reward_std": 0.6609482169151306, "imag_reward_min": -1.880518913269043, "imag_reward_max": 11.642267227172852, "imag_action_mean": 0.07452392578125, "imag_action_std": 0.83203125, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.3179044723510742, "actor_loss": 0.0021120167803019285, "actor_grad_norm": 0.06113654747605324, "value_loss": 1.407455325126648, "value_grad_norm": 1.6028598546981812, "update_count": 42600.0, "fps": 14.20132163109386}
{"step": 345194, "dataset_size": 172597.0, "train_return": -408.1683269930072, "train_length": 500.0, "train_episodes": 415.0}
{"step": 345528, "dataset_size": 172764.0, "train_return": -161.008962392807, "train_length": 167.0, "train_episodes": 416.0}
{"step": 345992}
{"step": 345992, "eval_return": 1867.8626750588417, "eval_length": 127.8, "eval_episodes": 5.0}
{"step": 346022, "dataset_size": 173011.0, "train_return": -284.35667473077774, "train_length": 247.0, "train_episodes": 417.0}
{"step": 347016}
{"step": 347016, "eval_return": -358.7458602764411, "eval_length": 395.8, "eval_episodes": 5.0}
{"step": 347022, "dataset_size": 173511.0, "train_return": -580.4918602705002, "train_length": 500.0, "train_episodes": 418.0}
{"step": 348022, "dataset_size": 174011.0, "train_return": -221.16381432674825, "train_length": 500.0, "train_episodes": 419.0}
{"step": 348040}
{"step": 348040, "eval_return": -292.31760108470917, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 349022, "dataset_size": 174511.0, "train_return": -471.83284452557564, "train_length": 500.0, "train_episodes": 420.0}
{"step": 349064}
{"step": 349064, "eval_return": 1782.8672281499953, "eval_length": 305.6, "eval_episodes": 5.0}
{"step": 350022, "dataset_size": 175011.0, "train_return": -133.88777964375913, "train_length": 500.0, "train_episodes": 421.0}
{"step": 350088}
{"step": 350088, "eval_return": 1871.4311594304163, "eval_length": 395.8, "eval_episodes": 5.0}
{"step": 351022, "dataset_size": 175511.0, "train_return": -137.299009680748, "train_length": 500.0, "train_episodes": 422.0}
{"step": 351112}
{"step": 351112, "eval_return": -209.72726224958896, "eval_length": 363.0, "eval_episodes": 5.0}
{"step": 352022, "dataset_size": 176011.0, "train_return": -697.8038559257984, "train_length": 500.0, "train_episodes": 423.0}
{"step": 352136}
{"step": 352136, "eval_return": -109.52064073607326, "eval_length": 272.4, "eval_episodes": 5.0}
{"step": 352788, "dataset_size": 176394.0, "train_return": -89.20177513360977, "train_length": 383.0, "train_episodes": 424.0}
{"step": 353160}
{"step": 353160, "eval_return": -220.08886856110766, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 353788, "dataset_size": 176894.0, "train_return": -646.490022957325, "train_length": 500.0, "train_episodes": 425.0}
{"step": 354092, "dataset_size": 177046.0, "train_return": 9790.235635638237, "train_length": 152.0, "train_episodes": 426.0}
{"step": 354184}
{"step": 354184, "eval_return": -139.40460003670304, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 355000, "model_loss": 2.458601713180542, "model_grad_norm": Infinity, "player_loss": 0.2121521681547165, "reward_loss": 0.5476796627044678, "cont_loss": 5.9692447393899783e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.831183671951294, "rep_loss": 2.831183671951294, "kl": 2.7505500316619873, "prior_ent": 43.92818832397461, "post_ent": 41.198036193847656, "normed_target_mean": 0.4401688575744629, "normed_target_std": 0.30243125557899475, "normed_target_min": -0.25641128420829773, "normed_target_max": 1.2126946449279785, "EMA_005": -56.374305725097656, "EMA_095": -1.84016752243042, "value_mean": -32.20130157470703, "value_std": 16.138647079467773, "value_min": -67.863037109375, "value_max": 0.185430109500885, "target_mean": -32.36792755126953, "target_std": 16.493093490600586, "target_min": -70.35682678222656, "target_max": 9.704856872558594, "imag_reward_mean": -0.7071648240089417, "imag_reward_std": 0.6699163913726807, "imag_reward_min": -1.887933611869812, "imag_reward_max": 12.057354927062988, "imag_action_mean": 0.08477783203125, "imag_action_std": 0.82958984375, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.3770979642868042, "actor_loss": 0.0026337560266256332, "actor_grad_norm": 0.06377319246530533, "value_loss": 1.4785648584365845, "value_grad_norm": Infinity, "update_count": 43850.0, "fps": 4.790368534480801}
{"step": 355092, "dataset_size": 177546.0, "train_return": -125.97840297594666, "train_length": 500.0, "train_episodes": 427.0}
{"step": 355208}
{"step": 355208, "eval_return": -345.36396027728915, "eval_length": 420.8, "eval_episodes": 5.0}
{"step": 356092, "dataset_size": 178046.0, "train_return": -155.63134472072124, "train_length": 500.0, "train_episodes": 428.0}
{"step": 356232}
{"step": 356232, "eval_return": 1710.2040077805518, "eval_length": 354.0, "eval_episodes": 5.0}
{"step": 357092, "dataset_size": 178546.0, "train_return": -819.840155184269, "train_length": 500.0, "train_episodes": 429.0}
{"step": 357256}
{"step": 357256, "eval_return": -247.65080544576048, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 358092, "dataset_size": 179046.0, "train_return": -488.1480298936367, "train_length": 500.0, "train_episodes": 430.0}
{"step": 358280}
{"step": 358280, "eval_return": -153.62039940813557, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 359092, "dataset_size": 179546.0, "train_return": -386.12501406669617, "train_length": 500.0, "train_episodes": 431.0}
{"step": 359304}
{"step": 359304, "eval_return": -185.21689588055014, "eval_length": 352.8, "eval_episodes": 5.0}
{"step": 359596, "dataset_size": 179798.0, "train_return": -281.4379076361656, "train_length": 252.0, "train_episodes": 432.0}
{"step": 360328}
{"step": 360328, "eval_return": 1792.25565007627, "eval_length": 282.6, "eval_episodes": 5.0}
{"step": 360596, "dataset_size": 180298.0, "train_return": -487.17094472050667, "train_length": 500.0, "train_episodes": 433.0}
{"step": 361352}
{"step": 361352, "eval_return": -438.50344578400257, "eval_length": 473.2, "eval_episodes": 5.0}
{"step": 361596, "dataset_size": 180798.0, "train_return": -60.50933355093002, "train_length": 500.0, "train_episodes": 434.0}
{"step": 362376}
{"step": 362376, "eval_return": 1867.0929340481757, "eval_length": 265.8, "eval_episodes": 5.0}
{"step": 362596, "dataset_size": 181298.0, "train_return": -47.76615834236145, "train_length": 500.0, "train_episodes": 435.0}
{"step": 363082, "dataset_size": 181541.0, "train_return": 9753.767753273249, "train_length": 243.0, "train_episodes": 436.0}
{"step": 363314, "dataset_size": 181657.0, "train_return": -107.82647180557251, "train_length": 116.0, "train_episodes": 437.0}
{"step": 363400}
{"step": 363400, "eval_return": -119.39989244937897, "eval_length": 316.2, "eval_episodes": 5.0}
{"step": 364314, "dataset_size": 182157.0, "train_return": -124.5675846748054, "train_length": 500.0, "train_episodes": 438.0}
{"step": 364424}
{"step": 364424, "eval_return": 1811.958904608339, "eval_length": 342.6, "eval_episodes": 5.0}
{"step": 364710, "dataset_size": 182355.0, "train_return": -58.274728775024414, "train_length": 198.0, "train_episodes": 439.0}
{"step": 365000, "model_loss": 2.4539897441864014, "model_grad_norm": Infinity, "player_loss": 0.2109968066215515, "reward_loss": 0.5481352210044861, "cont_loss": 0.00012732093455269933, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.824549913406372, "rep_loss": 2.824549913406372, "kl": 2.7426397800445557, "prior_ent": 44.09995651245117, "post_ent": 41.37852478027344, "normed_target_mean": 0.4335760772228241, "normed_target_std": 0.30416494607925415, "normed_target_min": -0.24921518564224243, "normed_target_max": 1.283973217010498, "EMA_005": -55.23353576660156, "EMA_095": -1.617059350013733, "value_mean": -31.843833923339844, "value_std": 15.878401756286621, "value_min": -66.14226531982422, "value_max": 0.25194212794303894, "target_mean": -31.985130310058594, "target_std": 16.30875587463379, "target_min": -68.59439849853516, "target_max": 13.588493347167969, "imag_reward_mean": -0.695390522480011, "imag_reward_std": 0.8052816390991211, "imag_reward_min": -1.9022921323776245, "imag_reward_max": 20.294092178344727, "imag_action_mean": 0.08441162109375, "imag_action_std": 0.83203125, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.1394838094711304, "actor_loss": 0.0023056298960000277, "actor_grad_norm": 0.06479161232709885, "value_loss": 1.4363197088241577, "value_grad_norm": 1.6982468366622925, "update_count": 45100.0, "fps": 3.965827287330383}
{"step": 365448}
{"step": 365448, "eval_return": -336.0338204830885, "eval_length": 474.2, "eval_episodes": 5.0}
{"step": 365710, "dataset_size": 182855.0, "train_return": -94.62203109264374, "train_length": 500.0, "train_episodes": 440.0}
{"step": 366472}
{"step": 366472, "eval_return": 1746.8250937774778, "eval_length": 410.2, "eval_episodes": 5.0}
{"step": 366710, "dataset_size": 183355.0, "train_return": -655.2726809978485, "train_length": 500.0, "train_episodes": 441.0}
{"step": 367496}
{"step": 367496, "eval_return": -373.3626408278942, "eval_length": 419.4, "eval_episodes": 5.0}
{"step": 367710, "dataset_size": 183855.0, "train_return": -620.3671225011349, "train_length": 500.0, "train_episodes": 442.0}
{"step": 367808, "dataset_size": 183904.0, "train_return": -29.972250819206238, "train_length": 49.0, "train_episodes": 443.0}
{"step": 368520}
{"step": 368520, "eval_return": 1608.3499352261424, "eval_length": 426.2, "eval_episodes": 5.0}
{"step": 368808, "dataset_size": 184404.0, "train_return": -715.7712240219116, "train_length": 500.0, "train_episodes": 444.0}
{"step": 369544}
{"step": 369544, "eval_return": -312.1627639502287, "eval_length": 402.2, "eval_episodes": 5.0}
{"step": 369808, "dataset_size": 184904.0, "train_return": -732.1328374370933, "train_length": 500.0, "train_episodes": 445.0}
{"step": 370568}
{"step": 370568, "eval_return": -222.14769750535487, "eval_length": 359.4, "eval_episodes": 5.0}
{"step": 370808, "dataset_size": 185404.0, "train_return": -486.51161147654057, "train_length": 500.0, "train_episodes": 446.0}
{"step": 371484, "dataset_size": 185742.0, "train_return": -297.06133937835693, "train_length": 338.0, "train_episodes": 447.0}
{"step": 371592}
{"step": 371592, "eval_return": -152.25688929595054, "eval_length": 387.6, "eval_episodes": 5.0}
{"step": 371686, "dataset_size": 185843.0, "train_return": -73.86241334676743, "train_length": 101.0, "train_episodes": 448.0}
{"step": 372288, "dataset_size": 186144.0, "train_return": -298.63010942935944, "train_length": 301.0, "train_episodes": 449.0}
{"step": 372616}
{"step": 372616, "eval_return": 1788.8738339498639, "eval_length": 345.6, "eval_episodes": 5.0}
{"step": 373288, "dataset_size": 186644.0, "train_return": -105.48583411518484, "train_length": 500.0, "train_episodes": 450.0}
{"step": 373640}
{"step": 373640, "eval_return": -327.12598706409335, "eval_length": 447.8, "eval_episodes": 5.0}
{"step": 374288, "dataset_size": 187144.0, "train_return": -890.4962040185928, "train_length": 500.0, "train_episodes": 451.0}
{"step": 374664}
{"step": 374664, "eval_return": 1693.8267741370946, "eval_length": 366.2, "eval_episodes": 5.0}
{"step": 375000, "model_loss": 2.4564831256866455, "model_grad_norm": 5.602853298187256, "player_loss": 0.2109091728925705, "reward_loss": 0.5514416694641113, "cont_loss": 8.337391045643017e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.8234150409698486, "rep_loss": 2.8234150409698486, "kl": 2.7402892112731934, "prior_ent": 44.105709075927734, "post_ent": 41.38711166381836, "normed_target_mean": 0.42198047041893005, "normed_target_std": 0.31117889285087585, "normed_target_min": -0.23874838650226593, "normed_target_max": 1.4693759679794312, "EMA_005": -54.63846206665039, "EMA_095": -1.536892056465149, "value_mean": -32.040611267089844, "value_std": 15.931035995483398, "value_min": -64.67730712890625, "value_max": 0.3467957079410553, "target_mean": -32.229129791259766, "target_std": 16.525835037231445, "target_min": -67.31864929199219, "target_max": 23.35992431640625, "imag_reward_mean": -0.6980019807815552, "imag_reward_std": 0.9996110200881958, "imag_reward_min": -1.9038697481155396, "imag_reward_max": 33.01469421386719, "imag_action_mean": 0.07708740234375, "imag_action_std": 0.83056640625, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 0.9852336049079895, "actor_loss": 0.00324759678915143, "actor_grad_norm": NaN, "value_loss": 1.4413282871246338, "value_grad_norm": Infinity, "update_count": 46350.0, "fps": 3.910554781315043}
{"step": 375288, "dataset_size": 187644.0, "train_return": -207.5645734341815, "train_length": 500.0, "train_episodes": 452.0}
{"step": 375688}
{"step": 375688, "eval_return": -299.3513895854354, "eval_length": 405.8, "eval_episodes": 5.0}
{"step": 376288, "dataset_size": 188144.0, "train_return": -591.0310338139534, "train_length": 500.0, "train_episodes": 453.0}
{"step": 376712}
{"step": 376712, "eval_return": -181.46327463984488, "eval_length": 269.6, "eval_episodes": 5.0}
{"step": 377288, "dataset_size": 188644.0, "train_return": -132.15716588124633, "train_length": 500.0, "train_episodes": 454.0}
{"step": 377680, "dataset_size": 188840.0, "train_return": -231.75434964895248, "train_length": 196.0, "train_episodes": 455.0}
{"step": 377736}
{"step": 377736, "eval_return": 1723.5725651085377, "eval_length": 455.6, "eval_episodes": 5.0}
{"step": 378680, "dataset_size": 189340.0, "train_return": -310.7984319627285, "train_length": 500.0, "train_episodes": 456.0}
{"step": 378760}
{"step": 378760, "eval_return": -279.3937441796064, "eval_length": 340.6, "eval_episodes": 5.0}
{"step": 379680, "dataset_size": 189840.0, "train_return": -23.27014994621277, "train_length": 500.0, "train_episodes": 457.0}
{"step": 379784}
{"step": 379784, "eval_return": -163.19882827550174, "eval_length": 293.4, "eval_episodes": 5.0}
{"step": 380680, "dataset_size": 190340.0, "train_return": -483.7873483002186, "train_length": 500.0, "train_episodes": 458.0}
{"step": 380796, "dataset_size": 190398.0, "train_return": 9981.106163263321, "train_length": 58.0, "train_episodes": 459.0}
{"step": 380808}
{"step": 380808, "eval_return": -279.9952869169414, "eval_length": 450.8, "eval_episodes": 5.0}
{"step": 381796, "dataset_size": 190898.0, "train_return": -459.20721885561943, "train_length": 500.0, "train_episodes": 460.0}
{"step": 381832}
{"step": 381832, "eval_return": 1768.5308321520686, "eval_length": 359.0, "eval_episodes": 5.0}
{"step": 382796, "dataset_size": 191398.0, "train_return": -80.86295482516289, "train_length": 500.0, "train_episodes": 461.0}
{"step": 382856}
{"step": 382856, "eval_return": 1728.377810563147, "eval_length": 411.4, "eval_episodes": 5.0}
{"step": 383796, "dataset_size": 191898.0, "train_return": -127.09935051202774, "train_length": 500.0, "train_episodes": 462.0}
{"step": 383880}
{"step": 383880, "eval_return": -135.63135305978358, "eval_length": 356.2, "eval_episodes": 5.0}
{"step": 383970, "dataset_size": 191985.0, "train_return": -41.138180792331696, "train_length": 87.0, "train_episodes": 463.0}
{"step": 384830, "dataset_size": 192415.0, "train_return": -336.93159398436546, "train_length": 430.0, "train_episodes": 464.0}
{"step": 384904}
{"step": 384904, "eval_return": -217.9642407462001, "eval_length": 310.8, "eval_episodes": 5.0}
{"step": 385000, "model_loss": 2.461329698562622, "model_grad_norm": 5.610518932342529, "player_loss": 0.21141113340854645, "reward_loss": 0.5491520762443542, "cont_loss": 7.965780241647735e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.8344781398773193, "rep_loss": 2.8344781398773193, "kl": 2.7526299953460693, "prior_ent": 44.0999641418457, "post_ent": 41.367454528808594, "normed_target_mean": 0.4454401731491089, "normed_target_std": 0.30827096104621887, "normed_target_min": -0.251761794090271, "normed_target_max": 1.3234196901321411, "EMA_005": -58.84242630004883, "EMA_095": -1.4057058095932007, "value_mean": -33.04167938232422, "value_std": 17.11392593383789, "value_min": -70.17644500732422, "value_max": 0.40315404534339905, "target_mean": -33.252952575683594, "target_std": 17.706249237060547, "target_min": -73.3056869506836, "target_max": 17.238895416259766, "imag_reward_mean": -0.7013033628463745, "imag_reward_std": 0.9853596687316895, "imag_reward_min": -1.9293218851089478, "imag_reward_max": 28.958269119262695, "imag_action_mean": 0.06329345703125, "imag_action_std": 0.8291015625, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.0205371379852295, "actor_loss": 0.0034181426744908094, "actor_grad_norm": 0.0691775307059288, "value_loss": 1.5311458110809326, "value_grad_norm": Infinity, "update_count": 47600.0, "fps": 11.532010275485085}
{"step": 385830, "dataset_size": 192915.0, "train_return": -175.67497605085373, "train_length": 500.0, "train_episodes": 465.0}
{"step": 385928}
{"step": 385928, "eval_return": -165.47734346985817, "eval_length": 454.0, "eval_episodes": 5.0}
{"step": 386830, "dataset_size": 193415.0, "train_return": -662.6673245951533, "train_length": 500.0, "train_episodes": 466.0}
{"step": 386952}
{"step": 386952, "eval_return": -245.06454472262413, "eval_length": 323.6, "eval_episodes": 5.0}
{"step": 387726, "dataset_size": 193863.0, "train_return": -400.5051824450493, "train_length": 448.0, "train_episodes": 467.0}
{"step": 387976}
{"step": 387976, "eval_return": -391.9272598385811, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 388726, "dataset_size": 194363.0, "train_return": -175.57142988964915, "train_length": 500.0, "train_episodes": 468.0}
{"step": 389000}
{"step": 389000, "eval_return": -219.71708937287332, "eval_length": 253.0, "eval_episodes": 5.0}
{"step": 389052, "dataset_size": 194526.0, "train_return": -16.55570077896118, "train_length": 163.0, "train_episodes": 469.0}
{"step": 390024}
{"step": 390024, "eval_return": 1616.6594290554524, "eval_length": 497.4, "eval_episodes": 5.0}
{"step": 390052, "dataset_size": 195026.0, "train_return": -628.2952550649643, "train_length": 500.0, "train_episodes": 470.0}
{"step": 391048}
{"step": 391048, "eval_return": -210.20939595238306, "eval_length": 466.6, "eval_episodes": 5.0}
{"step": 391052, "dataset_size": 195526.0, "train_return": -335.6802339553833, "train_length": 500.0, "train_episodes": 471.0}
{"step": 391818, "dataset_size": 195909.0, "train_return": -463.35251647233963, "train_length": 383.0, "train_episodes": 472.0}
{"step": 392072}
{"step": 392072, "eval_return": -74.34591151094064, "eval_length": 267.0, "eval_episodes": 5.0}
{"step": 392818, "dataset_size": 196409.0, "train_return": -253.4158609835431, "train_length": 500.0, "train_episodes": 473.0}
{"step": 393096}
{"step": 393096, "eval_return": -422.3373887658119, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 393818, "dataset_size": 196909.0, "train_return": -569.5410771071911, "train_length": 500.0, "train_episodes": 474.0}
{"step": 394120}
{"step": 394120, "eval_return": -376.67952702641486, "eval_length": 352.6, "eval_episodes": 5.0}
{"step": 394818, "dataset_size": 197409.0, "train_return": -539.3335762023926, "train_length": 500.0, "train_episodes": 475.0}
{"step": 395000, "model_loss": 2.456686019897461, "model_grad_norm": 5.589083194732666, "player_loss": 0.2102949023246765, "reward_loss": 0.5456799864768982, "cont_loss": 8.2998005382251e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.8343799114227295, "rep_loss": 2.8343799114227295, "kl": 2.7521965503692627, "prior_ent": 44.148929595947266, "post_ent": 41.42225646972656, "normed_target_mean": 0.45175981521606445, "normed_target_std": 0.31284990906715393, "normed_target_min": -0.26605331897735596, "normed_target_max": 1.5700058937072754, "EMA_005": -58.92084884643555, "EMA_095": -1.3226892948150635, "value_mean": -32.73929214477539, "value_std": 17.236730575561523, "value_min": -71.28633880615234, "value_max": 0.44215548038482666, "target_mean": -32.90033721923828, "target_std": 18.017532348632812, "target_min": -74.24407196044922, "target_max": 31.414587020874023, "imag_reward_mean": -0.6952747702598572, "imag_reward_std": 1.040366291999817, "imag_reward_min": -1.9277902841567993, "imag_reward_max": 35.052398681640625, "imag_action_mean": 0.067626953125, "imag_action_std": 0.82568359375, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.1873587369918823, "actor_loss": 0.0024475818499922752, "actor_grad_norm": NaN, "value_loss": 1.545964241027832, "value_grad_norm": Infinity, "update_count": 48850.0, "fps": 14.072247069662254}
{"step": 395144}
{"step": 395144, "eval_return": 1636.825860452652, "eval_length": 366.0, "eval_episodes": 5.0}
{"step": 395818, "dataset_size": 197909.0, "train_return": -384.7516657114029, "train_length": 500.0, "train_episodes": 476.0}
{"step": 395938, "dataset_size": 197969.0, "train_return": -25.8954975605011, "train_length": 60.0, "train_episodes": 477.0}
{"step": 396168}
{"step": 396168, "eval_return": -179.945106010139, "eval_length": 377.2, "eval_episodes": 5.0}
{"step": 396938, "dataset_size": 198469.0, "train_return": -30.77325451374054, "train_length": 500.0, "train_episodes": 478.0}
{"step": 397192}
{"step": 397192, "eval_return": -421.32374674379827, "eval_length": 456.2, "eval_episodes": 5.0}
{"step": 397938, "dataset_size": 198969.0, "train_return": -16.37253427505493, "train_length": 500.0, "train_episodes": 479.0}
{"step": 398216}
{"step": 398216, "eval_return": -252.8011828780174, "eval_length": 339.2, "eval_episodes": 5.0}
{"step": 398938, "dataset_size": 199469.0, "train_return": -63.09070962667465, "train_length": 500.0, "train_episodes": 480.0}
{"step": 399240}
{"step": 399240, "eval_return": -108.7881833575666, "eval_length": 358.0, "eval_episodes": 5.0}
{"step": 399416, "dataset_size": 199708.0, "train_return": -222.3101772069931, "train_length": 239.0, "train_episodes": 481.0}
{"step": 399556, "dataset_size": 199778.0, "train_return": -10.693308234214783, "train_length": 70.0, "train_episodes": 482.0}
{"step": 400264}
{"step": 400264, "eval_return": 1804.4700306922198, "eval_length": 299.0, "eval_episodes": 5.0}
{"step": 400556, "dataset_size": 200278.0, "train_return": -546.3981974124908, "train_length": 500.0, "train_episodes": 483.0}
{"step": 401232, "dataset_size": 200616.0, "train_return": -334.9422819018364, "train_length": 338.0, "train_episodes": 484.0}
{"step": 401288}
{"step": 401288, "eval_return": -144.53165756613015, "eval_length": 233.0, "eval_episodes": 5.0}
{"step": 402232, "dataset_size": 201116.0, "train_return": -579.5287716388702, "train_length": 500.0, "train_episodes": 485.0}
{"step": 402312}
{"step": 402312, "eval_return": -183.30695842131973, "eval_length": 263.2, "eval_episodes": 5.0}
{"step": 402922, "dataset_size": 201461.0, "train_return": -362.8972424566746, "train_length": 345.0, "train_episodes": 486.0}
{"step": 403286, "dataset_size": 201643.0, "train_return": -285.1989710330963, "train_length": 182.0, "train_episodes": 487.0}
{"step": 403336}
{"step": 403336, "eval_return": 1874.825993853854, "eval_length": 327.6, "eval_episodes": 5.0}
{"step": 404286, "dataset_size": 202143.0, "train_return": -355.0716312741861, "train_length": 500.0, "train_episodes": 488.0}
{"step": 404360}
{"step": 404360, "eval_return": -345.99781607985494, "eval_length": 416.2, "eval_episodes": 5.0}
{"step": 404372, "dataset_size": 202186.0, "train_return": 9972.50266778469, "train_length": 43.0, "train_episodes": 489.0}
{"step": 405000, "model_loss": 2.454216718673706, "model_grad_norm": Infinity, "player_loss": 0.21054567396640778, "reward_loss": 0.5415514707565308, "cont_loss": 3.578194809961133e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.8368072509765625, "rep_loss": 2.8368072509765625, "kl": 2.7549898624420166, "prior_ent": 44.22211456298828, "post_ent": 41.49262619018555, "normed_target_mean": 0.45616406202316284, "normed_target_std": 0.30382040143013, "normed_target_min": -0.2718474566936493, "normed_target_max": 1.2477041482925415, "EMA_005": -58.456886291503906, "EMA_095": -1.246355652809143, "value_mean": -32.19401168823242, "value_std": 16.940156936645508, "value_min": -71.35433959960938, "value_max": 0.46145445108413696, "target_mean": -32.35946273803711, "target_std": 17.383102416992188, "target_min": -74.0088119506836, "target_max": 12.926807403564453, "imag_reward_mean": -0.6971569657325745, "imag_reward_std": 0.917960524559021, "imag_reward_min": -1.9150117635726929, "imag_reward_max": 26.959274291992188, "imag_action_mean": 0.055755615234375, "imag_action_std": 0.8251953125, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.2015331983566284, "actor_loss": 0.002522509079426527, "actor_grad_norm": 0.06978427618741989, "value_loss": 1.5679548978805542, "value_grad_norm": 1.8677877187728882, "update_count": 50100.0, "fps": 14.347164320173528}
{"step": 405112, "dataset_size": 202556.0, "train_return": -304.26756793260574, "train_length": 370.0, "train_episodes": 490.0}
{"step": 405384}
{"step": 405384, "eval_return": -290.6992034316063, "eval_length": 397.4, "eval_episodes": 5.0}
{"step": 405454, "dataset_size": 202727.0, "train_return": -68.5100485086441, "train_length": 171.0, "train_episodes": 491.0}
{"step": 406408}
{"step": 406408, "eval_return": -79.78982437252998, "eval_length": 283.0, "eval_episodes": 5.0}
{"step": 406454, "dataset_size": 203227.0, "train_return": -444.2650893777609, "train_length": 500.0, "train_episodes": 492.0}
{"step": 406560, "dataset_size": 203280.0, "train_return": -25.266141057014465, "train_length": 53.0, "train_episodes": 493.0}
{"step": 407432}
{"step": 407432, "eval_return": -214.78046642541887, "eval_length": 216.8, "eval_episodes": 5.0}
{"step": 407560, "dataset_size": 203780.0, "train_return": -485.4572282731533, "train_length": 500.0, "train_episodes": 494.0}
{"step": 408098, "dataset_size": 204049.0, "train_return": -25.046674489974976, "train_length": 269.0, "train_episodes": 495.0}
{"step": 408456}
{"step": 408456, "eval_return": -234.04542288184166, "eval_length": 410.2, "eval_episodes": 5.0}
{"step": 409098, "dataset_size": 204549.0, "train_return": -44.20856535434723, "train_length": 500.0, "train_episodes": 496.0}
{"step": 409480}
{"step": 409480, "eval_return": 3912.2790374934675, "eval_length": 166.4, "eval_episodes": 5.0}
{"step": 410098, "dataset_size": 205049.0, "train_return": -556.2688800394535, "train_length": 500.0, "train_episodes": 497.0}
{"step": 410504}
{"step": 410504, "eval_return": 1641.396024954319, "eval_length": 421.0, "eval_episodes": 5.0}
{"step": 411098, "dataset_size": 205549.0, "train_return": -14.735910892486572, "train_length": 500.0, "train_episodes": 498.0}
{"step": 411370, "dataset_size": 205685.0, "train_return": -50.099737882614136, "train_length": 136.0, "train_episodes": 499.0}
{"step": 411528}
{"step": 411528, "eval_return": 1836.5424717664719, "eval_length": 327.0, "eval_episodes": 5.0}
{"step": 412058, "dataset_size": 206029.0, "train_return": 9664.668021023273, "train_length": 344.0, "train_episodes": 500.0}
{"step": 412552}
{"step": 412552, "eval_return": 1890.5558234993368, "eval_length": 254.6, "eval_episodes": 5.0}
{"step": 412962, "dataset_size": 206481.0, "train_return": -196.05339181423187, "train_length": 452.0, "train_episodes": 501.0}
{"step": 413576}
{"step": 413576, "eval_return": -358.8586731344461, "eval_length": 330.4, "eval_episodes": 5.0}
{"step": 413606, "dataset_size": 206803.0, "train_return": -44.42829692363739, "train_length": 322.0, "train_episodes": 502.0}
{"step": 413988, "dataset_size": 206994.0, "train_return": -177.16589909791946, "train_length": 191.0, "train_episodes": 503.0}
{"step": 414310, "dataset_size": 207155.0, "train_return": -134.01654905080795, "train_length": 161.0, "train_episodes": 504.0}
{"step": 414600}
{"step": 414600, "eval_return": 1924.1552157878875, "eval_length": 174.6, "eval_episodes": 5.0}
{"step": 415000, "model_loss": 2.4588098526000977, "model_grad_norm": 5.645119667053223, "player_loss": 0.2108459770679474, "reward_loss": 0.5407772660255432, "cont_loss": 9.888792556012049e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.8451452255249023, "rep_loss": 2.8451452255249023, "kl": 2.7640185356140137, "prior_ent": 44.25895690917969, "post_ent": 41.51951599121094, "normed_target_mean": 0.45662441849708557, "normed_target_std": 0.3088182210922241, "normed_target_min": -0.2718814015388489, "normed_target_max": 1.443541169166565, "EMA_005": -58.61159896850586, "EMA_095": -1.0471432209014893, "value_mean": -32.1456298828125, "value_std": 17.148193359375, "value_min": -71.48871612548828, "value_max": 0.4995819330215454, "target_mean": -32.32526779174805, "target_std": 17.776493072509766, "target_min": -74.26284790039062, "target_max": 24.500410079956055, "imag_reward_mean": -0.6900221705436707, "imag_reward_std": 1.2905653715133667, "imag_reward_min": -1.918199062347412, "imag_reward_max": 50.94336700439453, "imag_action_mean": 0.045623779296875, "imag_action_std": 0.82568359375, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.2169476747512817, "actor_loss": 0.0027688704431056976, "actor_grad_norm": 0.06910369545221329, "value_loss": 1.5509752035140991, "value_grad_norm": 1.8438478708267212, "update_count": 51350.0, "fps": 14.978116900301664}
{"step": 415310, "dataset_size": 207655.0, "train_return": -682.5118970870972, "train_length": 500.0, "train_episodes": 505.0}
{"step": 415624}
{"step": 415624, "eval_return": -288.32879749536517, "eval_length": 306.8, "eval_episodes": 5.0}
{"step": 416310, "dataset_size": 208155.0, "train_return": -266.28018176555634, "train_length": 500.0, "train_episodes": 506.0}
{"step": 416648}
{"step": 416648, "eval_return": -366.23973570168016, "eval_length": 415.8, "eval_episodes": 5.0}
{"step": 417268, "dataset_size": 208634.0, "train_return": -490.456012070179, "train_length": 479.0, "train_episodes": 507.0}
{"step": 417672}
{"step": 417672, "eval_return": 1718.6508188724517, "eval_length": 343.6, "eval_episodes": 5.0}
{"step": 418268, "dataset_size": 209134.0, "train_return": -37.52427673339844, "train_length": 500.0, "train_episodes": 508.0}
{"step": 418696}
{"step": 418696, "eval_return": -471.1740016192198, "eval_length": 387.0, "eval_episodes": 5.0}
{"step": 419268, "dataset_size": 209634.0, "train_return": -26.116680026054382, "train_length": 500.0, "train_episodes": 509.0}
{"step": 419720}
{"step": 419720, "eval_return": 1773.896471631527, "eval_length": 307.2, "eval_episodes": 5.0}
{"step": 420268, "dataset_size": 210134.0, "train_return": -274.55522925406694, "train_length": 500.0, "train_episodes": 510.0}
{"step": 420744}
{"step": 420744, "eval_return": -404.7078784674406, "eval_length": 424.0, "eval_episodes": 5.0}
{"step": 421268, "dataset_size": 210634.0, "train_return": -382.9441395699978, "train_length": 500.0, "train_episodes": 511.0}
{"step": 421696, "dataset_size": 210848.0, "train_return": 9768.891069889069, "train_length": 214.0, "train_episodes": 512.0}
{"step": 421768}
{"step": 421768, "eval_return": -496.7306572020054, "eval_length": 477.6, "eval_episodes": 5.0}
{"step": 422290, "dataset_size": 211145.0, "train_return": -279.431432723999, "train_length": 297.0, "train_episodes": 513.0}
{"step": 422792}
{"step": 422792, "eval_return": -375.81672224998476, "eval_length": 448.0, "eval_episodes": 5.0}
{"step": 423290, "dataset_size": 211645.0, "train_return": -594.0334376692772, "train_length": 500.0, "train_episodes": 514.0}
{"step": 423816}
{"step": 423816, "eval_return": -270.49929320812225, "eval_length": 370.0, "eval_episodes": 5.0}
{"step": 424290, "dataset_size": 212145.0, "train_return": -52.41460847854614, "train_length": 500.0, "train_episodes": 515.0}
{"step": 424452, "dataset_size": 212226.0, "train_return": -19.344570994377136, "train_length": 81.0, "train_episodes": 516.0}
{"step": 424840}
{"step": 424840, "eval_return": -425.6583848923445, "eval_length": 409.2, "eval_episodes": 5.0}
{"step": 425000, "model_loss": 2.457880735397339, "model_grad_norm": 5.531437397003174, "player_loss": 0.2116817682981491, "reward_loss": 0.5358828902244568, "cont_loss": 7.422677299473435e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.850402593612671, "rep_loss": 2.850402593612671, "kl": 2.768817663192749, "prior_ent": 44.26295471191406, "post_ent": 41.518798828125, "normed_target_mean": 0.46050527691841125, "normed_target_std": 0.3124968409538269, "normed_target_min": -0.27906832098960876, "normed_target_max": 1.712949275970459, "EMA_005": -58.75239944458008, "EMA_095": -0.7370488047599792, "value_mean": -31.865699768066406, "value_std": 17.367900848388672, "value_min": -72.1666259765625, "value_max": 0.5248711109161377, "target_mean": -32.035743713378906, "target_std": 18.129215240478516, "target_min": -74.9425277709961, "target_max": 40.544071197509766, "imag_reward_mean": -0.6829382181167603, "imag_reward_std": 1.5085477828979492, "imag_reward_min": -1.9280699491500854, "imag_reward_max": 66.72845458984375, "imag_action_mean": 0.0423583984375, "imag_action_std": 0.82666015625, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.1843279600143433, "actor_loss": 0.002595541998744011, "actor_grad_norm": NaN, "value_loss": 1.5564771890640259, "value_grad_norm": Infinity, "update_count": 52600.0, "fps": 13.932924536298218}
{"step": 425452, "dataset_size": 212726.0, "train_return": -660.6155710220337, "train_length": 500.0, "train_episodes": 517.0}
{"step": 425864}
{"step": 425864, "eval_return": 1718.802616751194, "eval_length": 365.6, "eval_episodes": 5.0}
{"step": 426452, "dataset_size": 213226.0, "train_return": -550.6471411138773, "train_length": 500.0, "train_episodes": 518.0}
{"step": 426888}
{"step": 426888, "eval_return": -315.1107916027307, "eval_length": 442.2, "eval_episodes": 5.0}
{"step": 427452, "dataset_size": 213726.0, "train_return": -592.98850274086, "train_length": 500.0, "train_episodes": 519.0}
{"step": 427816, "dataset_size": 213908.0, "train_return": 9979.487040400505, "train_length": 182.0, "train_episodes": 520.0}
{"step": 427912}
{"step": 427912, "eval_return": -276.48059149086475, "eval_length": 320.4, "eval_episodes": 5.0}
{"step": 428816, "dataset_size": 214408.0, "train_return": -22.077158093452454, "train_length": 500.0, "train_episodes": 521.0}
{"step": 428936}
{"step": 428936, "eval_return": -162.02352336645126, "eval_length": 436.4, "eval_episodes": 5.0}
{"step": 429054, "dataset_size": 214527.0, "train_return": -35.67449074983597, "train_length": 119.0, "train_episodes": 522.0}
{"step": 429960}
{"step": 429960, "eval_return": -179.7976235240698, "eval_length": 261.0, "eval_episodes": 5.0}
{"step": 430054, "dataset_size": 215027.0, "train_return": -552.1738846898079, "train_length": 500.0, "train_episodes": 523.0}
{"step": 430362, "dataset_size": 215181.0, "train_return": -128.17721816897392, "train_length": 154.0, "train_episodes": 524.0}
{"step": 430598, "dataset_size": 215299.0, "train_return": -74.35687679052353, "train_length": 118.0, "train_episodes": 525.0}
{"step": 430722, "dataset_size": 215361.0, "train_return": -22.751433193683624, "train_length": 62.0, "train_episodes": 526.0}
{"step": 430984}
{"step": 430984, "eval_return": -426.26121988892555, "eval_length": 390.0, "eval_episodes": 5.0}
{"step": 431110, "dataset_size": 215555.0, "train_return": -45.14917182922363, "train_length": 194.0, "train_episodes": 527.0}
{"step": 432008}
{"step": 432008, "eval_return": -203.52061048150063, "eval_length": 251.2, "eval_episodes": 5.0}
{"step": 432110, "dataset_size": 216055.0, "train_return": -253.03014746308327, "train_length": 500.0, "train_episodes": 528.0}
{"step": 433032}
{"step": 433032, "eval_return": -284.65105099081995, "eval_length": 319.8, "eval_episodes": 5.0}
{"step": 433110, "dataset_size": 216555.0, "train_return": -22.33212971687317, "train_length": 500.0, "train_episodes": 529.0}
{"step": 434056}
{"step": 434056, "eval_return": -329.3948552906513, "eval_length": 342.4, "eval_episodes": 5.0}
{"step": 434110, "dataset_size": 217055.0, "train_return": -383.3001755475998, "train_length": 500.0, "train_episodes": 530.0}
{"step": 434194, "dataset_size": 217097.0, "train_return": -14.783480286598206, "train_length": 42.0, "train_episodes": 531.0}
{"step": 434334, "dataset_size": 217167.0, "train_return": -78.50125008821487, "train_length": 70.0, "train_episodes": 532.0}
{"step": 435000, "model_loss": 2.462942123413086, "model_grad_norm": Infinity, "player_loss": 0.21073120832443237, "reward_loss": 0.5384629368782043, "cont_loss": 5.854673872818239e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.856149673461914, "rep_loss": 2.856149673461914, "kl": 2.7749111652374268, "prior_ent": 44.39679718017578, "post_ent": 41.64931869506836, "normed_target_mean": 0.45912113785743713, "normed_target_std": 0.3123558461666107, "normed_target_min": -0.28510648012161255, "normed_target_max": 1.6181219816207886, "EMA_005": -58.6216926574707, "EMA_095": -0.6564894318580627, "value_mean": -31.874961853027344, "value_std": 17.33074378967285, "value_min": -72.39814758300781, "value_max": 0.5883955359458923, "target_mean": -32.00970458984375, "target_std": 18.107511520385742, "target_min": -75.14710998535156, "target_max": 35.23217010498047, "imag_reward_mean": -0.683314859867096, "imag_reward_std": 1.6606004238128662, "imag_reward_min": -1.9202543497085571, "imag_reward_max": 78.47114562988281, "imag_action_mean": 0.044403076171875, "imag_action_std": 0.8291015625, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 0.9763066172599792, "actor_loss": 0.002048908267170191, "actor_grad_norm": NaN, "value_loss": 1.5493751764297485, "value_grad_norm": 1.8921867609024048, "update_count": 53850.0, "fps": 14.793328612369772}
{"step": 435080}
{"step": 435080, "eval_return": 1706.7083961889148, "eval_length": 327.6, "eval_episodes": 5.0}
{"step": 435216, "dataset_size": 217608.0, "train_return": -440.6128080487251, "train_length": 441.0, "train_episodes": 533.0}
{"step": 436104}
{"step": 436104, "eval_return": -203.53242900967598, "eval_length": 357.6, "eval_episodes": 5.0}
{"step": 436216, "dataset_size": 218108.0, "train_return": -493.84643802046776, "train_length": 500.0, "train_episodes": 534.0}
{"step": 437128}
{"step": 437128, "eval_return": 1807.9236569821835, "eval_length": 288.0, "eval_episodes": 5.0}
{"step": 437216, "dataset_size": 218608.0, "train_return": -401.8332117050886, "train_length": 500.0, "train_episodes": 535.0}
{"step": 437286, "dataset_size": 218643.0, "train_return": -21.965035915374756, "train_length": 35.0, "train_episodes": 536.0}
{"step": 437658, "dataset_size": 218829.0, "train_return": -240.3941614627838, "train_length": 186.0, "train_episodes": 537.0}
{"step": 438152}
{"step": 438152, "eval_return": 3826.1854674354195, "eval_length": 291.4, "eval_episodes": 5.0}
{"step": 438658, "dataset_size": 219329.0, "train_return": -541.1727434396744, "train_length": 500.0, "train_episodes": 538.0}
{"step": 439174, "dataset_size": 219587.0, "train_return": -320.6491071879864, "train_length": 258.0, "train_episodes": 539.0}
{"step": 439176}
{"step": 439176, "eval_return": -279.45426470190284, "eval_length": 324.0, "eval_episodes": 5.0}
{"step": 440174, "dataset_size": 220087.0, "train_return": -20.635825991630554, "train_length": 500.0, "train_episodes": 540.0}
{"step": 440200}
{"step": 440200, "eval_return": -232.41670523285865, "eval_length": 391.4, "eval_episodes": 5.0}
{"step": 440674, "dataset_size": 220337.0, "train_return": -39.93172425031662, "train_length": 250.0, "train_episodes": 541.0}
{"step": 441224}
{"step": 441224, "eval_return": -235.11327259242535, "eval_length": 274.8, "eval_episodes": 5.0}
{"step": 441674, "dataset_size": 220837.0, "train_return": -180.87586802244186, "train_length": 500.0, "train_episodes": 542.0}
{"step": 442248}
{"step": 442248, "eval_return": -310.64812274575235, "eval_length": 406.2, "eval_episodes": 5.0}
{"step": 442674, "dataset_size": 221337.0, "train_return": -398.16290268301964, "train_length": 500.0, "train_episodes": 543.0}
{"step": 443272}
{"step": 443272, "eval_return": 1909.9782817542552, "eval_length": 281.0, "eval_episodes": 5.0}
{"step": 443674, "dataset_size": 221837.0, "train_return": -178.44787573814392, "train_length": 500.0, "train_episodes": 544.0}
{"step": 443954, "dataset_size": 221977.0, "train_return": -68.53336727619171, "train_length": 140.0, "train_episodes": 545.0}
{"step": 444296}
{"step": 444296, "eval_return": 1950.3667212426662, "eval_length": 262.2, "eval_episodes": 5.0}
{"step": 444954, "dataset_size": 222477.0, "train_return": -597.7318890690804, "train_length": 500.0, "train_episodes": 546.0}
{"step": 445000, "model_loss": 2.4630496501922607, "model_grad_norm": 5.563643932342529, "player_loss": 0.20878945291042328, "reward_loss": 0.5431050658226013, "cont_loss": 9.352969209430739e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.8517682552337646, "rep_loss": 2.8517682552337646, "kl": 2.7715790271759033, "prior_ent": 44.58216094970703, "post_ent": 41.841487884521484, "normed_target_mean": 0.45758548378944397, "normed_target_std": 0.31443139910697937, "normed_target_min": -0.29107269644737244, "normed_target_max": 1.8604636192321777, "EMA_005": -57.4959831237793, "EMA_095": -0.7301025986671448, "value_mean": -31.381071090698242, "value_std": 16.87187385559082, "value_min": -71.56598663330078, "value_max": 0.5804691314697266, "target_mean": -31.519750595092773, "target_std": 17.85064125061035, "target_min": -74.01803588867188, "target_max": 48.2039909362793, "imag_reward_mean": -0.685880720615387, "imag_reward_std": 1.6122961044311523, "imag_reward_min": -1.9241529703140259, "imag_reward_max": 74.2109146118164, "imag_action_mean": 0.051300048828125, "imag_action_std": 0.828125, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 0.9693418741226196, "actor_loss": 0.0022191330790519714, "actor_grad_norm": 0.06497597694396973, "value_loss": 1.5476881265640259, "value_grad_norm": 1.8542612791061401, "update_count": 55100.0, "fps": 14.707817959146915}
{"step": 445320}
{"step": 445320, "eval_return": -75.79034621715546, "eval_length": 274.4, "eval_episodes": 5.0}
{"step": 445954, "dataset_size": 222977.0, "train_return": -31.370728731155396, "train_length": 500.0, "train_episodes": 547.0}
{"step": 446344}
{"step": 446344, "eval_return": -108.59368778765202, "eval_length": 331.8, "eval_episodes": 5.0}
{"step": 446954, "dataset_size": 223477.0, "train_return": -680.9873225688934, "train_length": 500.0, "train_episodes": 548.0}
{"step": 447024, "dataset_size": 223512.0, "train_return": -24.628349900245667, "train_length": 35.0, "train_episodes": 549.0}
{"step": 447368}
{"step": 447368, "eval_return": -256.8922770082951, "eval_length": 366.2, "eval_episodes": 5.0}
{"step": 448024, "dataset_size": 224012.0, "train_return": -433.6068883985281, "train_length": 500.0, "train_episodes": 550.0}
{"step": 448392}
{"step": 448392, "eval_return": 3844.8043055057524, "eval_length": 230.0, "eval_episodes": 5.0}
{"step": 449024, "dataset_size": 224512.0, "train_return": -218.30623655067757, "train_length": 500.0, "train_episodes": 551.0}
{"step": 449416}
{"step": 449416, "eval_return": -225.1261489853263, "eval_length": 408.4, "eval_episodes": 5.0}
{"step": 449628, "dataset_size": 224814.0, "train_return": 9717.261452823877, "train_length": 302.0, "train_episodes": 552.0}
{"step": 450440}
{"step": 450440, "eval_return": -230.91913062185048, "eval_length": 448.2, "eval_episodes": 5.0}
{"step": 450628, "dataset_size": 225314.0, "train_return": -84.72674345970154, "train_length": 500.0, "train_episodes": 553.0}
{"step": 450794, "dataset_size": 225397.0, "train_return": -83.00128936767578, "train_length": 83.0, "train_episodes": 554.0}
{"step": 451464}
{"step": 451464, "eval_return": 1789.4499402686954, "eval_length": 311.0, "eval_episodes": 5.0}
{"step": 451480, "dataset_size": 225740.0, "train_return": -76.41251349449158, "train_length": 343.0, "train_episodes": 555.0}
{"step": 451724, "dataset_size": 225862.0, "train_return": -28.52358829975128, "train_length": 122.0, "train_episodes": 556.0}
{"step": 452488}
{"step": 452488, "eval_return": -382.79419257044793, "eval_length": 458.0, "eval_episodes": 5.0}
{"step": 452724, "dataset_size": 226362.0, "train_return": -307.628522336483, "train_length": 500.0, "train_episodes": 557.0}
{"step": 453512}
{"step": 453512, "eval_return": 1775.9598898015915, "eval_length": 413.6, "eval_episodes": 5.0}
{"step": 453522, "dataset_size": 226761.0, "train_return": -439.11122252605855, "train_length": 399.0, "train_episodes": 558.0}
{"step": 453676, "dataset_size": 226838.0, "train_return": -108.92870807647705, "train_length": 77.0, "train_episodes": 559.0}
{"step": 454536}
{"step": 454536, "eval_return": 1762.9849725857378, "eval_length": 400.2, "eval_episodes": 5.0}
{"step": 454676, "dataset_size": 227338.0, "train_return": -44.06522750854492, "train_length": 500.0, "train_episodes": 560.0}
{"step": 454746, "dataset_size": 227373.0, "train_return": -13.54426097869873, "train_length": 35.0, "train_episodes": 561.0}
{"step": 455000, "model_loss": 2.4576992988586426, "model_grad_norm": 5.481673717498779, "player_loss": 0.21000701189041138, "reward_loss": 0.5310547351837158, "cont_loss": 7.747809286229312e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.860934019088745, "rep_loss": 2.860934019088745, "kl": 2.780322313308716, "prior_ent": 44.66133117675781, "post_ent": 41.91425704956055, "normed_target_mean": 0.4724137783050537, "normed_target_std": 0.3182350695133209, "normed_target_min": -0.2904438376426697, "normed_target_max": 1.731419563293457, "EMA_005": -57.933170318603516, "EMA_095": -0.6452616453170776, "value_mean": -30.736469268798828, "value_std": 17.366025924682617, "value_min": -71.90274810791016, "value_max": 0.6110649704933167, "target_mean": -30.869796752929688, "target_std": 18.231706619262695, "target_min": -74.57525634765625, "target_max": 41.253562927246094, "imag_reward_mean": -0.6789747476577759, "imag_reward_std": 1.7832390069961548, "imag_reward_min": -1.9233132600784302, "imag_reward_max": 83.49227142333984, "imag_action_mean": 0.045623779296875, "imag_action_std": 0.82763671875, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 0.9593753218650818, "actor_loss": 0.002075007651001215, "actor_grad_norm": 0.06865277141332626, "value_loss": 1.5907570123672485, "value_grad_norm": Infinity, "update_count": 56350.0, "fps": 14.140106466212401}
{"step": 455560}
{"step": 455560, "eval_return": -236.74515761733056, "eval_length": 307.4, "eval_episodes": 5.0}
{"step": 455746, "dataset_size": 227873.0, "train_return": -174.80766075849533, "train_length": 500.0, "train_episodes": 562.0}
{"step": 456584}
{"step": 456584, "eval_return": -233.52112631201743, "eval_length": 347.6, "eval_episodes": 5.0}
{"step": 456746, "dataset_size": 228373.0, "train_return": -191.44659484922886, "train_length": 500.0, "train_episodes": 563.0}
{"step": 457608}
{"step": 457608, "eval_return": -262.28078770712017, "eval_length": 460.0, "eval_episodes": 5.0}
{"step": 457746, "dataset_size": 228873.0, "train_return": -226.95798597484827, "train_length": 500.0, "train_episodes": 564.0}
{"step": 458482, "dataset_size": 229241.0, "train_return": -244.10544395446777, "train_length": 368.0, "train_episodes": 565.0}
{"step": 458632}
{"step": 458632, "eval_return": -171.35948439091445, "eval_length": 418.4, "eval_episodes": 5.0}
{"step": 459482, "dataset_size": 229741.0, "train_return": -24.742288172245026, "train_length": 500.0, "train_episodes": 566.0}
{"step": 459656}
{"step": 459656, "eval_return": -274.34702136069535, "eval_length": 365.2, "eval_episodes": 5.0}
{"step": 460482, "dataset_size": 230241.0, "train_return": -81.48221266269684, "train_length": 500.0, "train_episodes": 567.0}
{"step": 460680}
{"step": 460680, "eval_return": -316.4282484844327, "eval_length": 413.0, "eval_episodes": 5.0}
{"step": 461482, "dataset_size": 230741.0, "train_return": -495.3747995495796, "train_length": 500.0, "train_episodes": 568.0}
{"step": 461704}
{"step": 461704, "eval_return": -146.66141119897367, "eval_length": 330.2, "eval_episodes": 5.0}
{"step": 462482, "dataset_size": 231241.0, "train_return": -693.0332618951797, "train_length": 500.0, "train_episodes": 569.0}
{"step": 462728}
{"step": 462728, "eval_return": -188.38520404696465, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 463482, "dataset_size": 231741.0, "train_return": -550.0599048435688, "train_length": 500.0, "train_episodes": 570.0}
{"step": 463752}
{"step": 463752, "eval_return": -245.84338368177413, "eval_length": 339.0, "eval_episodes": 5.0}
{"step": 464482, "dataset_size": 232241.0, "train_return": -159.41075851023197, "train_length": 500.0, "train_episodes": 571.0}
{"step": 464776}
{"step": 464776, "eval_return": 1826.896997398138, "eval_length": 273.6, "eval_episodes": 5.0}
{"step": 465000, "model_loss": 2.453115701675415, "model_grad_norm": Infinity, "player_loss": 0.20973648130893707, "reward_loss": 0.5266472697257996, "cont_loss": 6.736964132869616e-05, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.8611087799072266, "rep_loss": 2.8611087799072266, "kl": 2.780714988708496, "prior_ent": 44.73373794555664, "post_ent": 41.9849739074707, "normed_target_mean": 0.4836597740650177, "normed_target_std": 0.3199600577354431, "normed_target_min": -0.30235689878463745, "normed_target_max": 1.7370296716690063, "EMA_005": -57.219051361083984, "EMA_095": -0.638817310333252, "value_mean": -29.724918365478516, "value_std": 17.190868377685547, "value_min": -71.48505401611328, "value_max": 0.6018646359443665, "target_mean": -29.854000091552734, "target_std": 18.10395050048828, "target_min": -74.32173919677734, "target_max": 41.150306701660156, "imag_reward_mean": -0.6582958698272705, "imag_reward_std": 2.2379307746887207, "imag_reward_min": -1.9155126810073853, "imag_reward_max": 112.77102661132812, "imag_action_mean": 0.0312347412109375, "imag_action_std": 0.826171875, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.0438923835754395, "actor_loss": 0.0020300941541790962, "actor_grad_norm": NaN, "value_loss": 1.606017827987671, "value_grad_norm": 2.0202035903930664, "update_count": 57600.0, "fps": 13.88175035505423}
{"step": 465482, "dataset_size": 232741.0, "train_return": -215.47175538539886, "train_length": 500.0, "train_episodes": 572.0}
{"step": 465690, "dataset_size": 232845.0, "train_return": 9975.058393776417, "train_length": 104.0, "train_episodes": 573.0}
{"step": 465800}
{"step": 465800, "eval_return": -176.39955035075545, "eval_length": 406.4, "eval_episodes": 5.0}
{"step": 466690, "dataset_size": 233345.0, "train_return": -478.66197395324707, "train_length": 500.0, "train_episodes": 574.0}
{"step": 466824}
{"step": 466824, "eval_return": 3804.28510017395, "eval_length": 313.4, "eval_episodes": 5.0}
{"step": 466978, "dataset_size": 233489.0, "train_return": -90.9871638417244, "train_length": 144.0, "train_episodes": 575.0}
{"step": 467848}
{"step": 467848, "eval_return": -241.63798081343992, "eval_length": 361.8, "eval_episodes": 5.0}
{"step": 467978, "dataset_size": 233989.0, "train_return": -131.91195123456419, "train_length": 500.0, "train_episodes": 576.0}
{"step": 468184, "dataset_size": 234092.0, "train_return": 9882.251711070538, "train_length": 103.0, "train_episodes": 577.0}
{"step": 468872}
{"step": 468872, "eval_return": -252.73639552891254, "eval_length": 335.4, "eval_episodes": 5.0}
{"step": 469184, "dataset_size": 234592.0, "train_return": -24.29839336872101, "train_length": 500.0, "train_episodes": 578.0}
{"step": 469896}
{"step": 469896, "eval_return": -219.90424170158803, "eval_length": 427.6, "eval_episodes": 5.0}
{"step": 470104, "dataset_size": 235052.0, "train_return": 9518.329320371151, "train_length": 460.0, "train_episodes": 579.0}
{"step": 470920}
{"step": 470920, "eval_return": 1961.9831202447415, "eval_length": 143.0, "eval_episodes": 5.0}
{"step": 471104, "dataset_size": 235552.0, "train_return": -338.62000051140785, "train_length": 500.0, "train_episodes": 580.0}
{"step": 471338, "dataset_size": 235669.0, "train_return": -101.35064363479614, "train_length": 117.0, "train_episodes": 581.0}
{"step": 471944}
{"step": 471944, "eval_return": 3881.660099565983, "eval_length": 276.2, "eval_episodes": 5.0}
{"step": 471952, "dataset_size": 235976.0, "train_return": -23.658034443855286, "train_length": 307.0, "train_episodes": 582.0}
{"step": 472022, "dataset_size": 236011.0, "train_return": -35.84425592422485, "train_length": 35.0, "train_episodes": 583.0}
{"step": 472528, "dataset_size": 236264.0, "train_return": -239.57168835401535, "train_length": 253.0, "train_episodes": 584.0}
{"step": 472930, "dataset_size": 236465.0, "train_return": 9827.605024456978, "train_length": 201.0, "train_episodes": 585.0}
{"step": 472968}
{"step": 472968, "eval_return": -142.57815201580524, "eval_length": 333.8, "eval_episodes": 5.0}
{"step": 473930, "dataset_size": 236965.0, "train_return": -419.2109947167337, "train_length": 500.0, "train_episodes": 586.0}
{"step": 473992}
{"step": 473992, "eval_return": -225.59597004130484, "eval_length": 500.0, "eval_episodes": 5.0}
{"step": 474930, "dataset_size": 237465.0, "train_return": -459.75246727466583, "train_length": 500.0, "train_episodes": 587.0}
{"step": 475000, "model_loss": 2.447006940841675, "model_grad_norm": Infinity, "player_loss": 0.20890334248542786, "reward_loss": 0.521335780620575, "cont_loss": 0.0001223357394337654, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.861076831817627, "rep_loss": 2.861076831817627, "kl": 2.7806243896484375, "prior_ent": 44.73589324951172, "post_ent": 41.98630142211914, "normed_target_mean": 0.4868125915527344, "normed_target_std": 0.3315545320510864, "normed_target_min": -0.3016679286956787, "normed_target_max": 2.269033908843994, "EMA_005": -57.44047546386719, "EMA_095": -0.29445594549179077, "value_mean": -29.48518180847168, "value_std": 17.464839935302734, "value_min": -71.84632873535156, "value_max": 0.6698434352874756, "target_mean": -29.621225357055664, "target_std": 18.9482364654541, "target_min": -74.6811752319336, "target_max": 72.247802734375, "imag_reward_mean": -0.6656079292297363, "imag_reward_std": 2.0052366256713867, "imag_reward_min": -1.917367935180664, "imag_reward_max": 98.91614532470703, "imag_action_mean": 0.032135009765625, "imag_action_std": 0.8251953125, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.1107642650604248, "actor_loss": 0.0021576781291514635, "actor_grad_norm": 0.0712885707616806, "value_loss": 1.5974304676055908, "value_grad_norm": Infinity, "update_count": 58850.0, "fps": 14.654740782319568}
{"step": 475012, "dataset_size": 237506.0, "train_return": 9978.419241547585, "train_length": 41.0, "train_episodes": 588.0}
{"step": 475016}
{"step": 475016, "eval_return": -172.18619050830603, "eval_length": 241.4, "eval_episodes": 5.0}
{"step": 475710, "dataset_size": 237855.0, "train_return": -248.94917809963226, "train_length": 349.0, "train_episodes": 589.0}
{"step": 475860, "dataset_size": 237930.0, "train_return": 9956.40825331211, "train_length": 75.0, "train_episodes": 590.0}
{"step": 476040}
{"step": 476040, "eval_return": 3800.6589645624163, "eval_length": 274.8, "eval_episodes": 5.0}
{"step": 476544, "dataset_size": 238272.0, "train_return": -302.6686051785946, "train_length": 342.0, "train_episodes": 591.0}
{"step": 477064}
{"step": 477064, "eval_return": -276.70200552940366, "eval_length": 381.6, "eval_episodes": 5.0}
{"step": 477544, "dataset_size": 238772.0, "train_return": -569.8764400137588, "train_length": 500.0, "train_episodes": 592.0}
{"step": 478088}
{"step": 478088, "eval_return": -177.34054434001445, "eval_length": 332.4, "eval_episodes": 5.0}
{"step": 478134, "dataset_size": 239067.0, "train_return": -100.61583027243614, "train_length": 295.0, "train_episodes": 593.0}
{"step": 479112}
{"step": 479112, "eval_return": -127.24280510693788, "eval_length": 324.8, "eval_episodes": 5.0}
{"step": 479134, "dataset_size": 239567.0, "train_return": -167.3362714704126, "train_length": 500.0, "train_episodes": 594.0}
{"step": 480134, "dataset_size": 240067.0, "train_return": -20.843444108963013, "train_length": 500.0, "train_episodes": 595.0}
{"step": 480136}
{"step": 480136, "eval_return": 1701.6456280887128, "eval_length": 364.8, "eval_episodes": 5.0}
{"step": 481134, "dataset_size": 240567.0, "train_return": -24.887956261634827, "train_length": 500.0, "train_episodes": 596.0}
{"step": 481160}
{"step": 481160, "eval_return": 1786.321947044134, "eval_length": 334.6, "eval_episodes": 5.0}
{"step": 481342, "dataset_size": 240671.0, "train_return": -112.92447966337204, "train_length": 104.0, "train_episodes": 597.0}
{"step": 481872, "dataset_size": 240936.0, "train_return": -222.2776145040989, "train_length": 265.0, "train_episodes": 598.0}
{"step": 481990, "dataset_size": 240995.0, "train_return": -32.002039074897766, "train_length": 59.0, "train_episodes": 599.0}
{"step": 482134, "dataset_size": 241067.0, "train_return": -13.682015657424927, "train_length": 72.0, "train_episodes": 600.0}
{"step": 482184}
{"step": 482184, "eval_return": -336.9807328015566, "eval_length": 362.6, "eval_episodes": 5.0}
{"step": 482216, "dataset_size": 241108.0, "train_return": -20.531232833862305, "train_length": 41.0, "train_episodes": 601.0}
{"step": 483208}
{"step": 483208, "eval_return": 3843.6767601191996, "eval_length": 192.2, "eval_episodes": 5.0}
{"step": 483216, "dataset_size": 241608.0, "train_return": -622.7240547835827, "train_length": 500.0, "train_episodes": 602.0}
{"step": 483414, "dataset_size": 241707.0, "train_return": -20.636229872703552, "train_length": 99.0, "train_episodes": 603.0}
{"step": 484232}
{"step": 484232, "eval_return": 3892.6192614078523, "eval_length": 320.0, "eval_episodes": 5.0}
{"step": 484414, "dataset_size": 242207.0, "train_return": -694.473552852869, "train_length": 500.0, "train_episodes": 604.0}
{"step": 484852, "dataset_size": 242426.0, "train_return": -191.44108593463898, "train_length": 219.0, "train_episodes": 605.0}
{"step": 485000, "model_loss": 2.4568698406219482, "model_grad_norm": 5.470602035522461, "player_loss": 0.20755219459533691, "reward_loss": 0.5264683961868286, "cont_loss": 0.00010316171392332762, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.871243715286255, "rep_loss": 2.871243715286255, "kl": 2.7925872802734375, "prior_ent": 45.00227737426758, "post_ent": 42.24721145629883, "normed_target_mean": 0.47587212920188904, "normed_target_std": 0.3385716378688812, "normed_target_min": -0.29474112391471863, "normed_target_max": 2.6042697429656982, "EMA_005": -58.13226318359375, "EMA_095": -0.29135844111442566, "value_mean": -30.433656692504883, "value_std": 17.621328353881836, "value_min": -72.27837371826172, "value_max": 0.7265379428863525, "target_mean": -30.607025146484375, "target_std": 19.577159881591797, "target_min": -75.17997741699219, "target_max": 92.0962142944336, "imag_reward_mean": -0.6572282314300537, "imag_reward_std": 2.5014891624450684, "imag_reward_min": -1.9282439947128296, "imag_reward_max": 126.31312561035156, "imag_action_mean": 0.0306549072265625, "imag_action_std": 0.8251953125, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.1010191440582275, "actor_loss": 0.002880225656554103, "actor_grad_norm": 0.0714416578412056, "value_loss": 1.5891103744506836, "value_grad_norm": 2.0479180812835693, "update_count": 60100.0, "fps": 13.862690382014035}
{"step": 485118, "dataset_size": 242559.0, "train_return": -83.96466410160065, "train_length": 133.0, "train_episodes": 606.0}
{"step": 485256}
{"step": 485256, "eval_return": -124.8505869820714, "eval_length": 331.8, "eval_episodes": 5.0}
{"step": 485292, "dataset_size": 242646.0, "train_return": -37.60631209611893, "train_length": 87.0, "train_episodes": 607.0}
{"step": 485894, "dataset_size": 242947.0, "train_return": -275.10337395966053, "train_length": 301.0, "train_episodes": 608.0}
{"step": 486280}
{"step": 486280, "eval_return": -395.60355657339096, "eval_length": 438.4, "eval_episodes": 5.0}
{"step": 486894, "dataset_size": 243447.0, "train_return": -208.54915109090507, "train_length": 500.0, "train_episodes": 609.0}
{"step": 487036, "dataset_size": 243518.0, "train_return": 9973.623759031296, "train_length": 71.0, "train_episodes": 610.0}
{"step": 487304}
{"step": 487304, "eval_return": -202.8916219472885, "eval_length": 328.4, "eval_episodes": 5.0}
{"step": 488036, "dataset_size": 244018.0, "train_return": -111.18471685913391, "train_length": 500.0, "train_episodes": 611.0}
{"step": 488328}
{"step": 488328, "eval_return": 1942.7004383161664, "eval_length": 199.8, "eval_episodes": 5.0}
{"step": 489012, "dataset_size": 244506.0, "train_return": -181.2772697340697, "train_length": 488.0, "train_episodes": 612.0}
{"step": 489084, "dataset_size": 244542.0, "train_return": 9974.308739423752, "train_length": 36.0, "train_episodes": 613.0}
{"step": 489280, "dataset_size": 244640.0, "train_return": -44.870712876319885, "train_length": 98.0, "train_episodes": 614.0}
{"step": 489352}
{"step": 489352, "eval_return": -324.83054326027633, "eval_length": 387.6, "eval_episodes": 5.0}
{"step": 489412, "dataset_size": 244706.0, "train_return": -18.8888601064682, "train_length": 66.0, "train_episodes": 615.0}
{"step": 490376}
{"step": 490376, "eval_return": -302.9910566985607, "eval_length": 414.4, "eval_episodes": 5.0}
{"step": 490412, "dataset_size": 245206.0, "train_return": -250.12035802286118, "train_length": 500.0, "train_episodes": 616.0}
{"step": 490604, "dataset_size": 245302.0, "train_return": -28.489238917827606, "train_length": 96.0, "train_episodes": 617.0}
{"step": 490896, "dataset_size": 245448.0, "train_return": -152.7799208164215, "train_length": 146.0, "train_episodes": 618.0}
{"step": 491400}
{"step": 491400, "eval_return": -70.13323177434503, "eval_length": 224.4, "eval_episodes": 5.0}
{"step": 491408, "dataset_size": 245704.0, "train_return": -48.73361647129059, "train_length": 256.0, "train_episodes": 619.0}
{"step": 492408, "dataset_size": 246204.0, "train_return": -38.139389634132385, "train_length": 500.0, "train_episodes": 620.0}
{"step": 492424}
{"step": 492424, "eval_return": 1953.594298028946, "eval_length": 183.2, "eval_episodes": 5.0}
{"step": 492552, "dataset_size": 246276.0, "train_return": -14.8790864944458, "train_length": 72.0, "train_episodes": 621.0}
{"step": 493448}
{"step": 493448, "eval_return": -233.99879432991148, "eval_length": 394.2, "eval_episodes": 5.0}
{"step": 493552, "dataset_size": 246776.0, "train_return": -40.66466063261032, "train_length": 500.0, "train_episodes": 622.0}
{"step": 494472}
{"step": 494472, "eval_return": -222.60129277408123, "eval_length": 314.2, "eval_episodes": 5.0}
{"step": 494552, "dataset_size": 247276.0, "train_return": -696.8183389306068, "train_length": 500.0, "train_episodes": 623.0}
{"step": 494852, "dataset_size": 247426.0, "train_return": -34.08867412805557, "train_length": 150.0, "train_episodes": 624.0}
{"step": 494948, "dataset_size": 247474.0, "train_return": 9975.292208135128, "train_length": 48.0, "train_episodes": 625.0}
{"step": 495000, "model_loss": 2.444683313369751, "model_grad_norm": Infinity, "player_loss": 0.20628659427165985, "reward_loss": 0.5223901867866516, "cont_loss": 0.00013898665201850235, "kl_free": 1.0, "dyn_scale": 0.5, "rep_scale": 0.09999999999999999, "dyn_loss": 2.8597798347473145, "rep_loss": 2.8597798347473145, "kl": 2.7814531326293945, "prior_ent": 45.35736846923828, "post_ent": 42.6151008605957, "normed_target_mean": 0.4807814359664917, "normed_target_std": 0.36441487073898315, "normed_target_min": -0.2866075336933136, "normed_target_max": 3.862281560897827, "EMA_005": -60.22227478027344, "EMA_095": -0.26736199855804443, "value_mean": -31.31772232055664, "value_std": 18.383501052856445, "value_min": -74.28641510009766, "value_max": 0.8129743933677673, "target_mean": -31.393474578857422, "target_std": 21.85126495361328, "target_min": -77.4057846069336, "target_max": 171.4934539794922, "imag_reward_mean": -0.6102720499038696, "imag_reward_std": 4.141600131988525, "imag_reward_min": -1.920782446861267, "imag_reward_max": 222.48985290527344, "imag_action_mean": 0.025054931640625, "imag_action_std": 0.8251953125, "imag_action_min": -1.0, "imag_action_max": 1.0, "actor_entropy": 1.1212929487228394, "actor_loss": 0.0013541505904868245, "actor_grad_norm": NaN, "value_loss": 1.6012076139450073, "value_grad_norm": Infinity, "update_count": 61350.0, "fps": 14.380744184962648}
{"step": 495320, "dataset_size": 247660.0, "train_return": -129.08914017677307, "train_length": 186.0, "train_episodes": 626.0}
{"step": 495434, "dataset_size": 247717.0, "train_return": -22.318609714508057, "train_length": 57.0, "train_episodes": 627.0}
{"step": 495496}
{"step": 495496, "eval_return": -105.68042155783624, "eval_length": 340.2, "eval_episodes": 5.0}
{"step": 495754, "dataset_size": 247877.0, "train_return": 9811.249348402023, "train_length": 160.0, "train_episodes": 628.0}
{"step": 495868, "dataset_size": 247934.0, "train_return": -36.89094561338425, "train_length": 57.0, "train_episodes": 629.0}
{"step": 496120, "dataset_size": 248060.0, "train_return": 9975.262754440308, "train_length": 126.0, "train_episodes": 630.0}
{"step": 496520}
{"step": 496520, "eval_return": -65.91369570124661, "eval_length": 259.2, "eval_episodes": 5.0}
{"step": 497120, "dataset_size": 248560.0, "train_return": -472.46931105852127, "train_length": 500.0, "train_episodes": 631.0}
{"step": 497246, "dataset_size": 248623.0, "train_return": 9979.798087596893, "train_length": 63.0, "train_episodes": 632.0}
{"step": 497544}
{"step": 497544, "eval_return": -135.28599105281756, "eval_length": 340.4, "eval_episodes": 5.0}
{"step": 498246, "dataset_size": 249123.0, "train_return": -610.0102437734604, "train_length": 500.0, "train_episodes": 633.0}
{"step": 498568}
{"step": 498568, "eval_return": 1850.2841887414456, "eval_length": 259.8, "eval_episodes": 5.0}
{"step": 498604, "dataset_size": 249302.0, "train_return": -144.6829554438591, "train_length": 179.0, "train_episodes": 634.0}
{"step": 499592}
{"step": 499592, "eval_return": 3773.137906160392, "eval_length": 265.2, "eval_episodes": 5.0}
{"step": 499604, "dataset_size": 249802.0, "train_return": -217.04339921474457, "train_length": 500.0, "train_episodes": 635.0}
{"step": 500026, "dataset_size": 250013.0, "train_return": -209.85623878240585, "train_length": 211.0, "train_episodes": 636.0}
{"step": 500616}
{"step": 500616, "eval_return": -93.36396549344063, "eval_length": 329.6, "eval_episodes": 5.0}
{"step": 501026, "dataset_size": 250513.0, "train_return": -537.2743731439114, "train_length": 500.0, "train_episodes": 637.0}
